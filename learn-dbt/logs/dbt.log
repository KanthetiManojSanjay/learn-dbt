2021-09-22 10:32:04.413147 (MainThread): Running with dbt=0.19.0
2021-09-22 10:32:04.747203 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 10:32:04.748383 (MainThread): Tracking: tracking
2021-09-22 10:32:04.760708 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10706adc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10707d820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10707d7c0>]}
2021-09-22 10:32:04.786876 (MainThread): Partial parsing not enabled
2021-09-22 10:32:04.788704 (MainThread): Parsing macros/etc.sql
2021-09-22 10:32:04.793000 (MainThread): Parsing macros/catalog.sql
2021-09-22 10:32:04.801436 (MainThread): Parsing macros/adapters.sql
2021-09-22 10:32:04.824662 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 10:32:04.828473 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 10:32:04.832126 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 10:32:04.843804 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 10:32:04.848580 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 10:32:04.861849 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 10:32:04.866000 (MainThread): Parsing macros/core.sql
2021-09-22 10:32:04.870935 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 10:32:04.880666 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 10:32:04.883089 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 10:32:04.933439 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 10:32:04.978109 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 10:32:05.005801 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 10:32:05.008240 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 10:32:05.015650 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 10:32:05.032646 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 10:32:05.040302 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 10:32:05.046845 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 10:32:05.051828 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 10:32:05.053084 (MainThread): Parsing macros/etc/query.sql
2021-09-22 10:32:05.054683 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 10:32:05.056796 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 10:32:05.066343 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 10:32:05.068772 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 10:32:05.070889 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 10:32:05.114110 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 10:32:05.116229 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 10:32:05.118017 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 10:32:05.120020 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 10:32:05.128702 (MainThread): Partial parsing not enabled
2021-09-22 10:32:05.168661 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 10:32:05.190585 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 10:32:05.376487 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0da52fc2-21f0-4cb9-9704-09a7533c0dc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073745b0>]}
2021-09-22 10:32:05.412822 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 10:32:05.413624 (MainThread): 
2021-09-22 10:32:05.414021 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 10:32:05.416726 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 10:32:05.416921 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 10:32:06.937641 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 10:32:06.937893 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 10:32:06.944402 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 10:32:06.945372 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 59887), raddr=('142.250.182.138', 443)>
2021-09-22 10:32:06.945558 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 59888), raddr=('142.250.182.106', 443)>
2021-09-22 10:32:08.433460 (MainThread): 16:02:08 | Concurrency: 1 threads (target='dev')
2021-09-22 10:32:08.433761 (MainThread): 16:02:08 | 
2021-09-22 10:32:08.437173 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 10:32:08.438936 (Thread-1): 16:02:08 | 1 of 2 START table model test.my_first_dbt_model..................... [RUN]
2021-09-22 10:32:08.439281 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 10:32:08.439414 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 10:32:08.462785 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 10:32:08.463505 (Thread-1): finished collecting timing info
2021-09-22 10:32:08.509353 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 10:32:08.510055 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 10:32:08.515571 (Thread-1): On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */


  create or replace table `unique-arbor-326717`.`test`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-09-22 10:32:13.305128 (Thread-1): finished collecting timing info
2021-09-22 10:32:13.306060 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0da52fc2-21f0-4cb9-9704-09a7533c0dc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074d46d0>]}
2021-09-22 10:32:13.307293 (Thread-1): 16:02:13 | 1 of 2 OK created table model test.my_first_dbt_model................ [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 4.87s]
2021-09-22 10:32:13.307447 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 10:32:13.308050 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 10:32:13.309270 (Thread-1): 16:02:13 | 2 of 2 START view model test.my_second_dbt_model..................... [RUN]
2021-09-22 10:32:13.309574 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 10:32:13.309693 (Thread-1): Compiling model.dbt_project.my_second_dbt_model
2021-09-22 10:32:13.318415 (Thread-1): Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 10:32:13.318866 (Thread-1): finished collecting timing info
2021-09-22 10:32:13.342875 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 10:32:13.343327 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 10:32:13.349067 (Thread-1): On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
where id = 1;


2021-09-22 10:32:15.866146 (Thread-1): finished collecting timing info
2021-09-22 10:32:15.866876 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0da52fc2-21f0-4cb9-9704-09a7533c0dc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10728ca90>]}
2021-09-22 10:32:15.868099 (Thread-1): 16:02:15 | 2 of 2 OK created view model test.my_second_dbt_model................ [OK in 2.56s]
2021-09-22 10:32:15.868249 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 10:32:15.869366 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 10:32:15.869694 (MainThread): 16:02:15 | 
2021-09-22 10:32:15.869925 (MainThread): 16:02:15 | Finished running 1 table model, 1 view model in 10.46s.
2021-09-22 10:32:15.870115 (MainThread): Connection 'master' was properly closed.
2021-09-22 10:32:15.870210 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 10:32:15.911488 (MainThread): 
2021-09-22 10:32:15.911645 (MainThread): Completed successfully
2021-09-22 10:32:15.911759 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-09-22 10:32:15.911927 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10728ca90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073f6520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073cebe0>]}
2021-09-22 10:32:15.912114 (MainThread): Flushing usage events
2021-09-22 11:10:48.084309 (MainThread): Running with dbt=0.19.0
2021-09-22 11:10:48.439298 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 11:10:48.440885 (MainThread): Tracking: tracking
2021-09-22 11:10:48.451438 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3e9ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3fc760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3fc700>]}
2021-09-22 11:10:48.477798 (MainThread): Partial parsing not enabled
2021-09-22 11:10:48.479299 (MainThread): Parsing macros/etc.sql
2021-09-22 11:10:48.483090 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:10:48.491136 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:10:48.511342 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:10:48.514662 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:10:48.518195 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:10:48.529303 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:10:48.534985 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:10:48.549590 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:10:48.553185 (MainThread): Parsing macros/core.sql
2021-09-22 11:10:48.557771 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:10:48.566837 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:10:48.569150 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:10:48.618621 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:10:48.662622 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:10:48.687652 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:10:48.690005 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:10:48.697082 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:10:48.711408 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:10:48.718464 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:10:48.725383 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:10:48.730316 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:10:48.731380 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:10:48.732653 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:10:48.734458 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:10:48.743942 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:10:48.746062 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:10:48.748101 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:10:48.790898 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:10:48.793122 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:10:48.794826 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:10:48.796631 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:10:48.804065 (MainThread): Partial parsing not enabled
2021-09-22 11:10:48.843747 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:10:48.865498 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:10:49.055438 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'afdc9227-5e60-4c07-849a-2fe880d1e8da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f6b6fa0>]}
2021-09-22 11:10:49.091310 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:10:49.091952 (MainThread): 
2021-09-22 11:10:49.092250 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:10:49.093504 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 11:10:49.093620 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 11:10:50.099723 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 11:10:50.099970 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 11:10:50.106443 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:10:50.128395 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60298), raddr=('142.250.182.74', 443)>
2021-09-22 11:10:50.128738 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60299), raddr=('142.250.182.106', 443)>
2021-09-22 11:10:51.148135 (MainThread): 16:40:51 | Concurrency: 1 threads (target='dev')
2021-09-22 11:10:51.148332 (MainThread): 16:40:51 | 
2021-09-22 11:10:51.150723 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 11:10:51.151110 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:10:51.151266 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 11:10:51.174526 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 11:10:51.175211 (Thread-1): finished collecting timing info
2021-09-22 11:10:51.175855 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 11:10:51.176476 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 11:10:51.178211 (Thread-1): 16:40:51 | 1 of 1 START view model test.my_second_dbt_model..................... [RUN]
2021-09-22 11:10:51.178556 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:10:51.178678 (Thread-1): Compiling model.dbt_project.my_second_dbt_model
2021-09-22 11:10:51.192759 (Thread-1): Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 11:10:51.193238 (Thread-1): finished collecting timing info
2021-09-22 11:10:51.235102 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 11:10:51.235615 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:10:51.241658 (Thread-1): On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
  OPTIONS()
  as with __dbt__CTE__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)-- Use the `ref` function to select from other models

select *
from __dbt__CTE__my_first_dbt_model
where id = 1;


2021-09-22 11:10:53.002594 (Thread-1): finished collecting timing info
2021-09-22 11:10:53.003326 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'afdc9227-5e60-4c07-849a-2fe880d1e8da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f6decd0>]}
2021-09-22 11:10:53.004717 (Thread-1): 16:40:53 | 1 of 1 OK created view model test.my_second_dbt_model................ [OK in 1.82s]
2021-09-22 11:10:53.004868 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 11:10:53.006184 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:10:53.006528 (MainThread): 16:40:53 | 
2021-09-22 11:10:53.006668 (MainThread): 16:40:53 | Finished running 1 view model in 3.91s.
2021-09-22 11:10:53.006775 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:10:53.006863 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 11:10:53.049152 (MainThread): 
2021-09-22 11:10:53.049315 (MainThread): Completed successfully
2021-09-22 11:10:53.049429 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-09-22 11:10:53.049588 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3c5580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f747c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f776580>]}
2021-09-22 11:10:53.049781 (MainThread): Flushing usage events
2021-09-22 11:12:01.785552 (MainThread): Running with dbt=0.19.0
2021-09-22 11:12:01.988447 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 11:12:01.989507 (MainThread): Tracking: tracking
2021-09-22 11:12:01.997579 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094ccd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094dd6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094dd670>]}
2021-09-22 11:12:02.018459 (MainThread): Partial parsing not enabled
2021-09-22 11:12:02.019431 (MainThread): Parsing macros/etc.sql
2021-09-22 11:12:02.022532 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:12:02.028458 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:12:02.048075 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:12:02.050714 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:12:02.053529 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:12:02.063547 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:12:02.067874 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:12:02.080989 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:12:02.083772 (MainThread): Parsing macros/core.sql
2021-09-22 11:12:02.087848 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:12:02.096552 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:12:02.098346 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:12:02.146526 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:12:02.186898 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:12:02.209626 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:12:02.211474 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:12:02.217597 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:12:02.231495 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:12:02.238227 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:12:02.244338 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:12:02.249603 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:12:02.250520 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:12:02.251528 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:12:02.253098 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:12:02.261667 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:12:02.263574 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:12:02.265336 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:12:02.306768 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:12:02.308584 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:12:02.310047 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:12:02.311750 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:12:02.319871 (MainThread): Partial parsing not enabled
2021-09-22 11:12:02.358005 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:12:02.378348 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:12:02.563578 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cdcbab47-3568-482b-9086-4cc6b600ef7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096c7880>]}
2021-09-22 11:12:02.597538 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:12:02.598230 (MainThread): 
2021-09-22 11:12:02.598540 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:12:02.599960 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 11:12:02.600089 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 11:12:03.565618 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 11:12:03.566172 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 11:12:03.572625 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:12:03.593690 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60312), raddr=('142.250.182.74', 443)>
2021-09-22 11:12:03.594011 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60314), raddr=('142.250.182.106', 443)>
2021-09-22 11:12:04.535216 (MainThread): 16:42:04 | Concurrency: 1 threads (target='dev')
2021-09-22 11:12:04.535414 (MainThread): 16:42:04 | 
2021-09-22 11:12:04.538318 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 11:12:04.538684 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:12:04.538849 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 11:12:04.561668 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 11:12:04.562388 (Thread-1): finished collecting timing info
2021-09-22 11:12:04.562997 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 11:12:04.563548 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 11:12:04.564918 (Thread-1): 16:42:04 | 1 of 1 START view model test.my_second_dbt_model..................... [RUN]
2021-09-22 11:12:04.565303 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:12:04.565427 (Thread-1): Compiling model.dbt_project.my_second_dbt_model
2021-09-22 11:12:04.579827 (Thread-1): Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 11:12:04.580354 (Thread-1): finished collecting timing info
2021-09-22 11:12:04.620133 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 11:12:04.620643 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:12:04.626571 (Thread-1): On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
  OPTIONS()
  as with __dbt__CTE__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)-- Use the `ref` function to select from other models

select *
from __dbt__CTE__my_first_dbt_model
where id = 1;


2021-09-22 11:12:06.628635 (Thread-1): finished collecting timing info
2021-09-22 11:12:06.629388 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdcbab47-3568-482b-9086-4cc6b600ef7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109701610>]}
2021-09-22 11:12:06.630933 (Thread-1): 16:42:06 | 1 of 1 OK created view model test.my_second_dbt_model................ [OK in 2.06s]
2021-09-22 11:12:06.631083 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 11:12:06.632119 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:12:06.632417 (MainThread): 16:42:06 | 
2021-09-22 11:12:06.632550 (MainThread): 16:42:06 | Finished running 1 view model in 4.03s.
2021-09-22 11:12:06.632662 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:12:06.632746 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 11:12:06.671478 (MainThread): 
2021-09-22 11:12:06.671637 (MainThread): Completed successfully
2021-09-22 11:12:06.671751 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-09-22 11:12:06.671913 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109545c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109917cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10982cc10>]}
2021-09-22 11:12:06.672095 (MainThread): Flushing usage events
2021-09-22 11:15:25.903049 (MainThread): Running with dbt=0.19.0
2021-09-22 11:15:26.119208 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 11:15:26.120215 (MainThread): Tracking: tracking
2021-09-22 11:15:26.130581 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b18c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b2b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b2b5b0>]}
2021-09-22 11:15:26.154854 (MainThread): Partial parsing not enabled
2021-09-22 11:15:26.155982 (MainThread): Parsing macros/etc.sql
2021-09-22 11:15:26.159162 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:15:26.166585 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:15:26.187630 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:15:26.190381 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:15:26.193173 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:15:26.203315 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:15:26.207627 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:15:26.220187 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:15:26.223026 (MainThread): Parsing macros/core.sql
2021-09-22 11:15:26.226815 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:15:26.235943 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:15:26.237708 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:15:26.283599 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:15:26.325451 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:15:26.350078 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:15:26.352220 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:15:26.358706 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:15:26.372886 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:15:26.379967 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:15:26.386047 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:15:26.390799 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:15:26.391709 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:15:26.392761 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:15:26.394439 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:15:26.403704 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:15:26.405608 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:15:26.407216 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:15:26.450440 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:15:26.452275 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:15:26.453744 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:15:26.455373 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:15:26.463817 (MainThread): Partial parsing not enabled
2021-09-22 11:15:26.502788 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:15:26.524644 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:15:26.709273 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bc84a800-cdf2-4626-b441-d4045ac37000', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e89640>]}
2021-09-22 11:15:26.743595 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:15:26.744443 (MainThread): 
2021-09-22 11:15:26.744860 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:15:26.747425 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 11:15:26.747550 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 11:15:27.852424 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 11:15:27.852679 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 11:15:27.859011 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:15:27.860036 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60336), raddr=('142.250.182.74', 443)>
2021-09-22 11:15:27.860227 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60337), raddr=('142.250.182.106', 443)>
2021-09-22 11:15:28.969042 (MainThread): 16:45:28 | Concurrency: 1 threads (target='dev')
2021-09-22 11:15:28.969220 (MainThread): 16:45:28 | 
2021-09-22 11:15:28.971330 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 11:15:28.972377 (Thread-1): 16:45:28 | 1 of 2 START table model test.first_model............................ [RUN]
2021-09-22 11:15:28.972637 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:15:28.972771 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 11:15:28.993083 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 11:15:28.993789 (Thread-1): finished collecting timing info
2021-09-22 11:15:29.041155 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 11:15:29.041678 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:15:29.047094 (Thread-1): On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */


  create or replace table `unique-arbor-326717`.`test`.`first_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-09-22 11:15:32.853490 (Thread-1): finished collecting timing info
2021-09-22 11:15:32.855250 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc84a800-cdf2-4626-b441-d4045ac37000', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ea7430>]}
2021-09-22 11:15:32.856532 (Thread-1): 16:45:32 | 1 of 2 OK created table model test.first_model....................... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 3.88s]
2021-09-22 11:15:32.856687 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 11:15:32.857131 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 11:15:32.858238 (Thread-1): 16:45:32 | 2 of 2 START view model test.my_second_dbt_model..................... [RUN]
2021-09-22 11:15:32.858584 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:15:32.858724 (Thread-1): Compiling model.dbt_project.my_second_dbt_model
2021-09-22 11:15:32.867763 (Thread-1): Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 11:15:32.868371 (Thread-1): finished collecting timing info
2021-09-22 11:15:32.894225 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 11:15:32.895016 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:15:32.901003 (Thread-1): On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `unique-arbor-326717`.`test`.`first_model`
where id = 1;


2021-09-22 11:15:34.912132 (Thread-1): finished collecting timing info
2021-09-22 11:15:34.912947 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc84a800-cdf2-4626-b441-d4045ac37000', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dda760>]}
2021-09-22 11:15:34.914197 (Thread-1): 16:45:34 | 2 of 2 OK created view model test.my_second_dbt_model................ [OK in 2.05s]
2021-09-22 11:15:34.914356 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 11:15:34.915354 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:15:34.915661 (MainThread): 16:45:34 | 
2021-09-22 11:15:34.915863 (MainThread): 16:45:34 | Finished running 1 table model, 1 view model in 8.17s.
2021-09-22 11:15:34.915994 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:15:34.916089 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 11:15:34.959929 (MainThread): 
2021-09-22 11:15:34.960089 (MainThread): Completed successfully
2021-09-22 11:15:34.960206 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-09-22 11:15:34.960369 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e58eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e2eb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062b54c0>]}
2021-09-22 11:15:34.960574 (MainThread): Flushing usage events
2021-09-22 11:16:48.459554 (MainThread): Running with dbt=0.19.0
2021-09-22 11:16:48.693312 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 11:16:48.694093 (MainThread): Tracking: tracking
2021-09-22 11:16:48.703906 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b5e4c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b5f8730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b5f86d0>]}
2021-09-22 11:16:48.729037 (MainThread): Partial parsing not enabled
2021-09-22 11:16:48.730192 (MainThread): Parsing macros/etc.sql
2021-09-22 11:16:48.733424 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:16:48.740171 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:16:48.759495 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:16:48.762615 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:16:48.765385 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:16:48.775252 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:16:48.779805 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:16:48.792821 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:16:48.795844 (MainThread): Parsing macros/core.sql
2021-09-22 11:16:48.799670 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:16:48.808547 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:16:48.810303 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:16:48.857479 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:16:48.902346 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:16:48.927231 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:16:48.929685 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:16:48.937146 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:16:48.953856 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:16:48.961837 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:16:48.968432 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:16:48.973371 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:16:48.974306 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:16:48.975347 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:16:48.976955 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:16:48.985829 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:16:48.987825 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:16:48.989500 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:16:49.033462 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:16:49.035368 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:16:49.036868 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:16:49.038549 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:16:49.046668 (MainThread): Partial parsing not enabled
2021-09-22 11:16:49.086748 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:16:49.108810 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:16:49.294572 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e26e5a5f-0ddc-4a37-98a3-cf69116a4324', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b95b3a0>]}
2021-09-22 11:16:49.328379 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:16:49.329260 (MainThread): 
2021-09-22 11:16:49.329615 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:16:49.331929 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 11:16:49.332271 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 11:16:50.891509 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 11:16:50.892418 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-09-22 11:16:52.410984 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_unique-arbor-326717_test_dbt_test".
2021-09-22 11:16:52.411279 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_unique-arbor-326717_test_dbt_test".
2021-09-22 11:16:52.411400 (ThreadPoolExecutor-0_0): Creating schema "unique-arbor-326717.test_dbt_test".
2021-09-22 11:16:52.411539 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-09-22 11:16:52.418042 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:16:52.419084 (ThreadPoolExecutor-0_0): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60353), raddr=('142.250.76.74', 443)>
2021-09-22 11:16:52.419276 (ThreadPoolExecutor-0_0): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60354), raddr=('142.250.182.106', 443)>
2021-09-22 11:16:52.419430 (ThreadPoolExecutor-0_0): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60355), raddr=('142.250.76.74', 443)>
2021-09-22 11:16:52.419564 (ThreadPoolExecutor-0_0): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60356), raddr=('142.250.182.106', 443)>
2021-09-22 11:16:54.268766 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 11:16:54.269038 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 11:16:54.275366 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:16:55.809596 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test_dbt_test".
2021-09-22 11:16:55.810034 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 11:16:55.816912 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:16:55.817510 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60360), raddr=('142.250.76.74', 443)>
2021-09-22 11:16:55.817694 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60361), raddr=('142.250.182.106', 443)>
2021-09-22 11:16:57.326591 (MainThread): 16:46:57 | Concurrency: 1 threads (target='dev')
2021-09-22 11:16:57.326830 (MainThread): 16:46:57 | 
2021-09-22 11:16:57.329386 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 11:16:57.330876 (Thread-1): 16:46:57 | 1 of 2 START table model test_dbt_test.first_model................... [RUN]
2021-09-22 11:16:57.331204 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:16:57.331342 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 11:16:57.354615 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 11:16:57.355126 (Thread-1): finished collecting timing info
2021-09-22 11:16:57.404213 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 11:16:57.404720 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:16:57.410274 (Thread-1): On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */


  create or replace table `unique-arbor-326717`.`test_dbt_test`.`first_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-09-22 11:17:02.367755 (Thread-1): finished collecting timing info
2021-09-22 11:17:02.368656 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e26e5a5f-0ddc-4a37-98a3-cf69116a4324', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba6e1c0>]}
2021-09-22 11:17:02.369877 (Thread-1): 16:47:02 | 1 of 2 OK created table model test_dbt_test.first_model.............. [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 5.04s]
2021-09-22 11:17:02.370034 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 11:17:02.370700 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 11:17:02.372205 (Thread-1): 16:47:02 | 2 of 2 START view model test.my_second_dbt_model..................... [RUN]
2021-09-22 11:17:02.372627 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:17:02.372763 (Thread-1): Compiling model.dbt_project.my_second_dbt_model
2021-09-22 11:17:02.382034 (Thread-1): Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 11:17:02.382540 (Thread-1): finished collecting timing info
2021-09-22 11:17:02.404720 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 11:17:02.405235 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:17:02.410765 (Thread-1): On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `unique-arbor-326717`.`test_dbt_test`.`first_model`
where id = 1;


2021-09-22 11:17:05.432728 (Thread-1): finished collecting timing info
2021-09-22 11:17:05.433460 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e26e5a5f-0ddc-4a37-98a3-cf69116a4324', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b80eac0>]}
2021-09-22 11:17:05.434723 (Thread-1): 16:47:05 | 2 of 2 OK created view model test.my_second_dbt_model................ [OK in 3.06s]
2021-09-22 11:17:05.434876 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 11:17:05.435902 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:17:05.436215 (MainThread): 16:47:05 | 
2021-09-22 11:17:05.436349 (MainThread): 16:47:05 | Finished running 1 table model, 1 view model in 16.11s.
2021-09-22 11:17:05.436461 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:17:05.436544 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 11:17:05.463794 (MainThread): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60362), raddr=('142.250.76.74', 443)>
2021-09-22 11:17:05.464023 (MainThread): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60363), raddr=('142.250.182.106', 443)>
2021-09-22 11:17:05.464173 (MainThread): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60366), raddr=('142.250.182.106', 443)>
2021-09-22 11:17:05.464311 (MainThread): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60365), raddr=('142.250.76.74', 443)>
2021-09-22 11:17:05.481983 (MainThread): 
2021-09-22 11:17:05.482138 (MainThread): Completed successfully
2021-09-22 11:17:05.482251 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-09-22 11:17:05.482409 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10babe8b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b919820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10badfe20>]}
2021-09-22 11:17:05.482588 (MainThread): Flushing usage events
2021-09-22 11:17:30.130285 (MainThread): Running with dbt=0.19.0
2021-09-22 11:17:30.357920 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 11:17:30.359156 (MainThread): Tracking: tracking
2021-09-22 11:17:30.370341 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc5cdc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc6a6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc6a670>]}
2021-09-22 11:17:30.395720 (MainThread): Partial parsing not enabled
2021-09-22 11:17:30.396901 (MainThread): Parsing macros/etc.sql
2021-09-22 11:17:30.400153 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:17:30.407601 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:17:30.431391 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:17:30.434676 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:17:30.437994 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:17:30.448936 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:17:30.453602 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:17:30.468302 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:17:30.471183 (MainThread): Parsing macros/core.sql
2021-09-22 11:17:30.475080 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:17:30.484419 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:17:30.486206 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:17:30.533804 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:17:30.576319 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:17:30.602635 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:17:30.604949 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:17:30.612774 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:17:30.630579 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:17:30.639901 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:17:30.647879 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:17:30.654061 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:17:30.655195 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:17:30.656418 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:17:30.658544 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:17:30.670140 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:17:30.672501 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:17:30.674564 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:17:30.727976 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:17:30.730270 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:17:30.732170 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:17:30.734206 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:17:30.743131 (MainThread): Partial parsing not enabled
2021-09-22 11:17:30.791001 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:17:30.817325 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:17:31.035441 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cc118b7a-7e6b-4f56-85f5-c15715e7dd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df53370>]}
2021-09-22 11:17:31.077128 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:17:31.077924 (MainThread): 
2021-09-22 11:17:31.078226 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:17:31.081695 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 11:17:31.081967 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 11:17:32.671054 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 11:17:32.671340 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-09-22 11:17:34.211612 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60376), raddr=('142.250.76.74', 443)>
2021-09-22 11:17:34.211830 (MainThread): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60377), raddr=('142.250.182.106', 443)>
2021-09-22 11:17:34.216891 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 11:17:34.217163 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 11:17:34.223519 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:17:35.689443 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test_dbt_test".
2021-09-22 11:17:35.689792 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 11:17:35.696556 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:17:37.776776 (MainThread): 16:47:37 | Concurrency: 1 threads (target='dev')
2021-09-22 11:17:37.777000 (MainThread): 16:47:37 | 
2021-09-22 11:17:37.780231 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 11:17:37.781786 (Thread-1): 16:47:37 | 1 of 2 START table model test_dbt_test.first_model................... [RUN]
2021-09-22 11:17:37.782150 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:17:37.782288 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 11:17:37.807750 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 11:17:37.808422 (Thread-1): finished collecting timing info
2021-09-22 11:17:37.836145 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:17:37.842058 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:17:39.965842 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 11:17:39.966425 (Thread-1): On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */


  create or replace table `unique-arbor-326717`.`test_dbt_test`.`first_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-09-22 11:17:43.430547 (Thread-1): finished collecting timing info
2021-09-22 11:17:43.431352 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cc118b7a-7e6b-4f56-85f5-c15715e7dd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e11fca0>]}
2021-09-22 11:17:43.432625 (Thread-1): 16:47:43 | 1 of 2 OK created table model test_dbt_test.first_model.............. [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 5.65s]
2021-09-22 11:17:43.432784 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 11:17:43.433282 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 11:17:43.434438 (Thread-1): 16:47:43 | 2 of 2 START view model test.my_second_dbt_model..................... [RUN]
2021-09-22 11:17:43.434870 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:17:43.434991 (Thread-1): Compiling model.dbt_project.my_second_dbt_model
2021-09-22 11:17:43.444215 (Thread-1): Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 11:17:43.444699 (Thread-1): finished collecting timing info
2021-09-22 11:17:43.467654 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 11:17:43.468179 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:17:43.474101 (Thread-1): On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `unique-arbor-326717`.`test_dbt_test`.`first_model`
where id = 1;


2021-09-22 11:17:46.295581 (Thread-1): finished collecting timing info
2021-09-22 11:17:46.296316 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cc118b7a-7e6b-4f56-85f5-c15715e7dd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e0c4400>]}
2021-09-22 11:17:46.297529 (Thread-1): 16:47:46 | 2 of 2 OK created view model test.my_second_dbt_model................ [OK in 2.86s]
2021-09-22 11:17:46.297683 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 11:17:46.298801 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:17:46.299107 (MainThread): 16:47:46 | 
2021-09-22 11:17:46.299243 (MainThread): 16:47:46 | Finished running 1 table model, 1 view model in 15.22s.
2021-09-22 11:17:46.299354 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:17:46.299438 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 11:17:46.336831 (MainThread): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60381), raddr=('142.250.182.106', 443)>
2021-09-22 11:17:46.337048 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60380), raddr=('142.250.76.74', 443)>
2021-09-22 11:17:46.337181 (MainThread): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60383), raddr=('142.250.182.106', 443)>
2021-09-22 11:17:46.337314 (MainThread): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60382), raddr=('142.250.76.74', 443)>
2021-09-22 11:17:46.337438 (MainThread): unclosed <socket.socket fd=23, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60385), raddr=('142.250.182.106', 443)>
2021-09-22 11:17:46.337566 (MainThread): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60384), raddr=('142.250.76.74', 443)>
2021-09-22 11:17:46.337696 (MainThread): unclosed <socket.socket fd=24, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60386), raddr=('142.250.76.74', 443)>
2021-09-22 11:17:46.337824 (MainThread): unclosed <socket.socket fd=25, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60387), raddr=('142.250.182.106', 443)>
2021-09-22 11:17:46.342395 (MainThread): 
2021-09-22 11:17:46.342526 (MainThread): Completed successfully
2021-09-22 11:17:46.342637 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-09-22 11:17:46.342796 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df26850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df92850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dccdcd0>]}
2021-09-22 11:17:46.342978 (MainThread): Flushing usage events
2021-09-22 11:19:50.214524 (MainThread): Running with dbt=0.19.0
2021-09-22 11:19:50.503998 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 11:19:50.505107 (MainThread): Tracking: tracking
2021-09-22 11:19:50.520612 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf5ec40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf71790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf71730>]}
2021-09-22 11:19:50.554420 (MainThread): Partial parsing not enabled
2021-09-22 11:19:50.556055 (MainThread): Parsing macros/etc.sql
2021-09-22 11:19:50.560312 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:19:50.568939 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:19:50.592500 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:19:50.596304 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:19:50.599914 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:19:50.610732 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:19:50.615579 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:19:50.628760 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:19:50.632271 (MainThread): Parsing macros/core.sql
2021-09-22 11:19:50.636815 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:19:50.645863 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:19:50.648419 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:19:50.695856 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:19:50.738786 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:19:50.763851 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:19:50.766381 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:19:50.773698 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:19:50.788596 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:19:50.795845 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:19:50.803381 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:19:50.808681 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:19:50.809972 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:19:50.811381 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:19:50.813514 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:19:50.824107 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:19:50.826517 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:19:50.828872 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:19:50.873306 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:19:50.875389 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:19:50.877441 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:19:50.879331 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:19:50.887396 (MainThread): Partial parsing not enabled
2021-09-22 11:19:50.926737 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:19:50.950646 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:19:51.159277 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fa098479-0847-46ba-a2ad-2f913a704741', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c256370>]}
2021-09-22 11:19:51.200681 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:19:51.201436 (MainThread): 
2021-09-22 11:19:51.201729 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:19:51.204027 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 11:19:51.204167 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 11:19:52.758361 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics_db".
2021-09-22 11:19:52.758704 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-09-22 11:19:54.234928 (ThreadPoolExecutor-0_0): Retry attempt 1 of 1 after error: BadRequest("GET https://bigquery.googleapis.com/bigquery/v2/projects/analytics_db/datasets?maxResults=10000&prettyPrint=false: Invalid project ID 'analytics_db'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.")
2021-09-22 11:19:54.623450 (ThreadPoolExecutor-0_0): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60403), raddr=('142.250.76.74', 443)>
2021-09-22 11:19:54.623702 (ThreadPoolExecutor-0_0): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60404), raddr=('142.250.182.106', 443)>
2021-09-22 11:19:54.624414 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:19:54.624549 (MainThread): Connection 'list_analytics_db' was properly closed.
2021-09-22 11:19:54.624772 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c105580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2803a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2ecb50>]}
2021-09-22 11:19:54.624999 (MainThread): Flushing usage events
2021-09-22 11:19:55.547485 (MainThread): Encountered an error:
2021-09-22 11:19:55.547706 (MainThread): Database Error
  Invalid project ID 'analytics_db'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
2021-09-22 11:19:55.615482 (MainThread): Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/impl.py", line 200, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/impl.py", line 200, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/Library/Python/3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/Library/Python/3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/Library/Python/3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/Library/Python/3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/analytics_db/datasets?maxResults=10000&prettyPrint=false: Invalid project ID 'analytics_db'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/Library/Python/3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/Library/Python/3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/Library/Python/3.8/site-packages/dbt/task/run.py", line 408, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Library/Python/3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/impl.py", line 202, in list_schemas
    return self.connections._retry_and_handle(
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error
  Invalid project ID 'analytics_db'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.

2021-09-22 11:22:18.939659 (MainThread): Running with dbt=0.19.0
2021-09-22 11:22:19.265591 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 11:22:19.266673 (MainThread): Tracking: tracking
2021-09-22 11:22:19.277190 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111672e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111685820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116857c0>]}
2021-09-22 11:22:19.300039 (MainThread): Partial parsing not enabled
2021-09-22 11:22:19.301351 (MainThread): Parsing macros/etc.sql
2021-09-22 11:22:19.304646 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:22:19.311090 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:22:19.331675 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:22:19.335226 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:22:19.338757 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:22:19.350137 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:22:19.354716 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:22:19.367315 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:22:19.370943 (MainThread): Parsing macros/core.sql
2021-09-22 11:22:19.375658 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:22:19.385713 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:22:19.388134 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:22:19.431812 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:22:19.474618 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:22:19.497830 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:22:19.499806 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:22:19.506165 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:22:19.520137 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:22:19.528100 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:22:19.535926 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:22:19.542307 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:22:19.543569 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:22:19.544948 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:22:19.546939 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:22:19.556792 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:22:19.559051 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:22:19.561020 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:22:19.602814 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:22:19.604778 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:22:19.606463 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:22:19.608563 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:22:19.616245 (MainThread): Partial parsing not enabled
2021-09-22 11:22:19.653826 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:22:19.675972 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:22:19.851373 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f0a3051e-2c14-436c-852f-a81f99c2eeda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111988fd0>]}
2021-09-22 11:22:19.883102 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:22:19.883760 (MainThread): 
2021-09-22 11:22:19.884002 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:22:19.885849 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_ivory-mountain-326811".
2021-09-22 11:22:19.886036 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 11:22:21.743986 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 11:22:21.744339 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-09-22 11:22:23.279958 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_ivory-mountain-326811_test_dbt_test".
2021-09-22 11:22:23.280390 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_ivory-mountain-326811_test_dbt_test".
2021-09-22 11:22:23.280552 (ThreadPoolExecutor-0_0): Creating schema "ivory-mountain-326811.test_dbt_test".
2021-09-22 11:22:23.280710 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-09-22 11:22:23.287812 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:22:23.290038 (ThreadPoolExecutor-0_0): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60426), raddr=('172.217.163.202', 443)>
2021-09-22 11:22:23.290226 (ThreadPoolExecutor-0_0): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60427), raddr=('142.250.182.106', 443)>
2021-09-22 11:22:23.290393 (ThreadPoolExecutor-0_0): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60428), raddr=('172.217.163.202', 443)>
2021-09-22 11:22:23.290538 (ThreadPoolExecutor-0_0): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60429), raddr=('142.250.182.106', 443)>
2021-09-22 11:22:25.165901 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:22:25.166135 (MainThread): Connection 'create_ivory-mountain-326811_test_dbt_test' was properly closed.
2021-09-22 11:22:25.166397 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111819610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111994430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a002e0>]}
2021-09-22 11:22:25.166710 (MainThread): Flushing usage events
2021-09-22 11:22:26.350997 (MainThread): Encountered an error:
2021-09-22 11:22:26.351229 (MainThread): Database Error
  Access Denied: Project ivory-mountain-326811: User does not have bigquery.datasets.create permission in project ivory-mountain-326811.
2021-09-22 11:22:26.403826 (MainThread): Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 512, in fn
    return client.create_dataset(dataset, exists_ok=True)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 506, in create_dataset
    api_response = self._call_api(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.Forbidden: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/ivory-mountain-326811/datasets?prettyPrint=false: Access Denied: Project ivory-mountain-326811: User does not have bigquery.datasets.create permission in project ivory-mountain-326811.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/Library/Python/3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/Library/Python/3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/Library/Python/3.8/site-packages/dbt/task/run.py", line 408, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 538, in create_schemas
    create_future.result()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Library/Python/3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 500, in create_schema
    adapter.create_schema(relation)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/impl.py", line 305, in create_schema
    self.connections.create_dataset(database, schema)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 513, in create_dataset
    self._retry_and_handle(msg='create dataset', conn=conn, fn=fn)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 157, in exception_handler
    self.handle_error(e, message)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error
  Access Denied: Project ivory-mountain-326811: User does not have bigquery.datasets.create permission in project ivory-mountain-326811.

2021-09-22 11:27:14.976178 (MainThread): Running with dbt=0.19.0
2021-09-22 11:27:15.282737 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 11:27:15.283821 (MainThread): Tracking: tracking
2021-09-22 11:27:15.294341 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097acc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097be760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097be700>]}
2021-09-22 11:27:15.320488 (MainThread): Partial parsing not enabled
2021-09-22 11:27:15.322091 (MainThread): Parsing macros/etc.sql
2021-09-22 11:27:15.326012 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:27:15.333779 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:27:15.356859 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:27:15.360353 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:27:15.363382 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:27:15.380813 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:27:15.386377 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:27:15.401841 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:27:15.405231 (MainThread): Parsing macros/core.sql
2021-09-22 11:27:15.409374 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:27:15.418280 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:27:15.420407 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:27:15.467146 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:27:15.510327 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:27:15.535326 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:27:15.537703 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:27:15.545299 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:27:15.560835 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:27:15.568288 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:27:15.575625 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:27:15.580697 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:27:15.581768 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:27:15.583054 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:27:15.584859 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:27:15.594756 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:27:15.597096 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:27:15.599388 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:27:15.641813 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:27:15.644146 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:27:15.645816 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:27:15.647754 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:27:15.655094 (MainThread): Partial parsing not enabled
2021-09-22 11:27:15.693909 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:27:15.708319 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109811ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109950190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10995c4c0>]}
2021-09-22 11:27:15.708591 (MainThread): Flushing usage events
2021-09-22 11:27:17.068246 (MainThread): Connection 'model.dbt_project.my_first_dbt_model' was properly closed.
2021-09-22 11:27:17.068461 (MainThread): Encountered an error:
2021-09-22 11:27:17.068640 (MainThread): Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  unexpected ','
    line 10
      -- , schema='dbt_test'  , database='ivory-mountain-326811'
2021-09-22 11:27:17.107955 (MainThread): Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 523, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/Library/Python/3.8/site-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/Library/Python/3.8/site-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/Library/Python/3.8/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/Library/Python/3.8/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 10, in template
jinja2.exceptions.TemplateSyntaxError: unexpected ','
  line 10
    -- , schema='dbt_test'  , database='ivory-mountain-326811'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/Library/Python/3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/Library/Python/3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 406, in run
    self._runtime_initialize()
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 122, in _runtime_initialize
    super()._runtime_initialize()
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 79, in _runtime_initialize
    self.load_manifest()
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 66, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/Library/Python/3.8/site-packages/dbt/perf_utils.py", line 28, in get_full_manifest
    return load_manifest(
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 854, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 434, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 282, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 232, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 183, in parse_with_cache
    parser.parse_file(block)
  File "/Library/Python/3.8/site-packages/dbt/parser/base.py", line 424, in parse_file
    self.parse_node(file_block)
  File "/Library/Python/3.8/site-packages/dbt/parser/base.py", line 397, in parse_node
    self.render_update(node, config)
  File "/Library/Python/3.8/site-packages/dbt/parser/base.py", line 372, in render_update
    self.render_with_context(node, config)
  File "/Library/Python/3.8/site-packages/dbt/parser/base.py", line 288, in render_with_context
    get_rendered(
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 570, in get_rendered
    template = get_template(
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 523, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 499, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  unexpected ','
    line 10
      -- , schema='dbt_test'  , database='ivory-mountain-326811'

2021-09-22 11:28:26.403607 (MainThread): Running with dbt=0.19.0
2021-09-22 11:28:26.705150 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 11:28:26.706198 (MainThread): Tracking: tracking
2021-09-22 11:28:26.715194 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106817c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10682a790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10682a730>]}
2021-09-22 11:28:26.739066 (MainThread): Partial parsing not enabled
2021-09-22 11:28:26.740372 (MainThread): Parsing macros/etc.sql
2021-09-22 11:28:26.743439 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:28:26.749975 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:28:26.769053 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:28:26.772361 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:28:26.775384 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:28:26.785321 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:28:26.789836 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:28:26.802530 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:28:26.805737 (MainThread): Parsing macros/core.sql
2021-09-22 11:28:26.809912 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:28:26.818741 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:28:26.821042 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:28:26.865848 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:28:26.910127 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:28:26.934032 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:28:26.936593 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:28:26.943751 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:28:26.958589 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:28:26.965447 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:28:26.972472 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:28:26.977573 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:28:26.978629 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:28:26.979757 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:28:26.981524 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:28:26.990227 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:28:26.992239 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:28:26.994323 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:28:27.035022 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:28:27.039138 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:28:27.041907 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:28:27.044361 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:28:27.053065 (MainThread): Partial parsing not enabled
2021-09-22 11:28:27.090957 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:28:27.112928 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:28:27.284659 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_project.example.vars

2021-09-22 11:28:27.287720 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd929b978-1edc-45ff-8b88-8e60ad4c89e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b11370>]}
2021-09-22 11:28:27.321984 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:28:27.322645 (MainThread): 
2021-09-22 11:28:27.322930 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:28:27.325496 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 11:28:27.325666 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 11:28:28.965395 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 11:28:28.965640 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 11:28:28.972113 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:28:28.973110 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60483), raddr=('142.250.182.42', 443)>
2021-09-22 11:28:28.973299 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60484), raddr=('142.250.182.106', 443)>
2021-09-22 11:28:30.442687 (MainThread): 16:58:30 | Concurrency: 1 threads (target='dev')
2021-09-22 11:28:30.442918 (MainThread): 16:58:30 | 
2021-09-22 11:28:30.446043 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 11:28:30.447322 (Thread-1): 16:58:30 | 1 of 2 START table model test.first_model............................ [RUN]
2021-09-22 11:28:30.447652 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:28:30.447794 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 11:28:30.472563 (Thread-1): finished collecting timing info
2021-09-22 11:28:30.473235 (Thread-1): Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 281, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/compile.py", line 32, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/Library/Python/3.8/site-packages/dbt/compilation.py", line 502, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/Library/Python/3.8/site-packages/dbt/compilation.py", line 404, in _compile_node
    compiled_node.compiled_sql = jinja.get_rendered(
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/Library/Python/3.8/site-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/Library/Python/3.8/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/Library/Python/3.8/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 21, in top-level template code
  File "/Library/Python/3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/context/base.py", line 158, in __call__
    return self.get_missing_var(var_name)
  File "/Library/Python/3.8/site-packages/dbt/context/base.py", line 139, in get_missing_var
    raise_compiler_error(msg, self._node)
  File "/Library/Python/3.8/site-packages/dbt/exceptions.py", line 435, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-09-22 11:28:30.513608 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd929b978-1edc-45ff-8b88-8e60ad4c89e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cc86d0>]}
2021-09-22 11:28:30.514780 (Thread-1): 16:58:30 | 1 of 2 ERROR creating table model test.first_model................... [ERROR in 0.07s]
2021-09-22 11:28:30.514919 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 11:28:30.515412 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 11:28:30.515646 (Thread-1): 16:58:30 | 2 of 2 SKIP relation test.my_second_dbt_model........................ [SKIP]
2021-09-22 11:28:30.515780 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 11:28:30.516551 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:28:30.516820 (MainThread): 16:58:30 | 
2021-09-22 11:28:30.516935 (MainThread): 16:58:30 | Finished running 1 table model, 1 view model in 3.19s.
2021-09-22 11:28:30.517033 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:28:30.517108 (MainThread): Connection 'model.dbt_project.my_first_dbt_model' was properly closed.
2021-09-22 11:28:30.555443 (MainThread): 
2021-09-22 11:28:30.555606 (MainThread): Completed with 1 error and 0 warnings:
2021-09-22 11:28:30.555719 (MainThread): 
2021-09-22 11:28:30.555843 (MainThread): Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-09-22 11:28:30.555949 (MainThread):   Required var 'my_first_variable' not found in config:
2021-09-22 11:28:30.556036 (MainThread):   Vars supplied to my_first_dbt_model = {}
2021-09-22 11:28:30.556130 (MainThread):   
2021-09-22 11:28:30.556222 (MainThread):   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-09-22 11:28:30.556294 (MainThread):   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-09-22 11:28:30.556374 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-09-22 11:28:30.556514 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b59fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b663d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c9c190>]}
2021-09-22 11:28:30.556692 (MainThread): Flushing usage events
2021-09-22 11:29:06.829340 (MainThread): Running with dbt=0.19.0
2021-09-22 11:29:07.132704 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 11:29:07.133374 (MainThread): Tracking: tracking
2021-09-22 11:29:07.142366 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111682e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116947f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111694790>]}
2021-09-22 11:29:07.165038 (MainThread): Partial parsing not enabled
2021-09-22 11:29:07.166345 (MainThread): Parsing macros/etc.sql
2021-09-22 11:29:07.169513 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:29:07.175937 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:29:07.194434 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:29:07.197576 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:29:07.200469 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:29:07.210095 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:29:07.215079 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:29:07.228174 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:29:07.231438 (MainThread): Parsing macros/core.sql
2021-09-22 11:29:07.235679 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:29:07.244400 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:29:07.246458 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:29:07.291228 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:29:07.332994 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:29:07.356129 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:29:07.358061 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:29:07.364378 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:29:07.380144 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:29:07.387376 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:29:07.394055 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:29:07.399272 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:29:07.401313 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:29:07.402790 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:29:07.404519 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:29:07.413581 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:29:07.415553 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:29:07.417516 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:29:07.457958 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:29:07.459927 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:29:07.461588 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:29:07.463427 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:29:07.470762 (MainThread): Partial parsing not enabled
2021-09-22 11:29:07.508268 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:29:07.530030 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:29:07.702217 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_project.example.vars

2021-09-22 11:29:07.705226 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '44512773-b064-438e-8227-a363997f6753', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119c2d30>]}
2021-09-22 11:29:07.740882 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:29:07.741572 (MainThread): 
2021-09-22 11:29:07.741851 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:29:07.744247 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 11:29:07.744644 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 11:29:09.312076 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 11:29:09.312322 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 11:29:09.318983 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:29:09.319914 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60496), raddr=('142.250.182.42', 443)>
2021-09-22 11:29:09.320096 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60497), raddr=('142.250.182.106', 443)>
2021-09-22 11:29:09.917989 (MainThread): 16:59:09 | Concurrency: 1 threads (target='dev')
2021-09-22 11:29:09.918218 (MainThread): 16:59:09 | 
2021-09-22 11:29:09.921143 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 11:29:09.922424 (Thread-1): 16:59:09 | 1 of 2 START table model test.first_model............................ [RUN]
2021-09-22 11:29:09.922742 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:29:09.922881 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 11:29:09.947429 (Thread-1): finished collecting timing info
2021-09-22 11:29:09.948094 (Thread-1): Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 281, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/compile.py", line 32, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/Library/Python/3.8/site-packages/dbt/compilation.py", line 502, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/Library/Python/3.8/site-packages/dbt/compilation.py", line 404, in _compile_node
    compiled_node.compiled_sql = jinja.get_rendered(
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/Library/Python/3.8/site-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/Library/Python/3.8/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/Library/Python/3.8/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 21, in top-level template code
  File "/Library/Python/3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/context/base.py", line 158, in __call__
    return self.get_missing_var(var_name)
  File "/Library/Python/3.8/site-packages/dbt/context/base.py", line 139, in get_missing_var
    raise_compiler_error(msg, self._node)
  File "/Library/Python/3.8/site-packages/dbt/exceptions.py", line 435, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-09-22 11:29:09.990089 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '44512773-b064-438e-8227-a363997f6753', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b32700>]}
2021-09-22 11:29:09.991406 (Thread-1): 16:59:09 | 1 of 2 ERROR creating table model test.first_model................... [ERROR in 0.07s]
2021-09-22 11:29:09.991549 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 11:29:09.992025 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 11:29:09.992172 (Thread-1): 16:59:09 | 2 of 2 SKIP relation test.my_second_dbt_model........................ [SKIP]
2021-09-22 11:29:09.992297 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 11:29:09.993162 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:29:09.993436 (MainThread): 16:59:09 | 
2021-09-22 11:29:09.993559 (MainThread): 16:59:09 | Finished running 1 table model, 1 view model in 2.25s.
2021-09-22 11:29:09.993663 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:29:09.993741 (MainThread): Connection 'model.dbt_project.my_first_dbt_model' was properly closed.
2021-09-22 11:29:10.032478 (MainThread): 
2021-09-22 11:29:10.032640 (MainThread): Completed with 1 error and 0 warnings:
2021-09-22 11:29:10.032750 (MainThread): 
2021-09-22 11:29:10.032852 (MainThread): Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-09-22 11:29:10.032943 (MainThread):   Required var 'my_first_variable' not found in config:
2021-09-22 11:29:10.033027 (MainThread):   Vars supplied to my_first_dbt_model = {}
2021-09-22 11:29:10.033109 (MainThread):   
2021-09-22 11:29:10.033189 (MainThread):   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-09-22 11:29:10.033270 (MainThread):   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-09-22 11:29:10.033357 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-09-22 11:29:10.033506 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119ce040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11198e790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b061c0>]}
2021-09-22 11:29:10.033684 (MainThread): Flushing usage events
2021-09-22 11:31:19.714635 (MainThread): Running with dbt=0.19.0
2021-09-22 11:31:20.072763 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 11:31:20.074012 (MainThread): Tracking: tracking
2021-09-22 11:31:20.083091 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113010be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113023730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1130236d0>]}
2021-09-22 11:31:20.106521 (MainThread): Partial parsing not enabled
2021-09-22 11:31:20.107784 (MainThread): Parsing macros/etc.sql
2021-09-22 11:31:20.110973 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:31:20.117580 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:31:20.136718 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:31:20.139857 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:31:20.142977 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:31:20.152867 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:31:20.157262 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:31:20.169708 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:31:20.173269 (MainThread): Parsing macros/core.sql
2021-09-22 11:31:20.177740 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:31:20.186668 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:31:20.188995 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:31:20.234028 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:31:20.276878 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:31:20.301249 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:31:20.303304 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:31:20.310424 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:31:20.325391 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:31:20.332421 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:31:20.339033 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:31:20.344170 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:31:20.345247 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:31:20.346426 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:31:20.348181 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:31:20.356733 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:31:20.358761 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:31:20.360955 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:31:20.401594 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:31:20.403616 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:31:20.405268 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:31:20.407148 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:31:20.414510 (MainThread): Partial parsing not enabled
2021-09-22 11:31:20.452865 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:31:20.474590 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:31:20.646133 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_project.example.vars

2021-09-22 11:31:20.649038 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '800e2552-b8ee-4876-bc92-a9f1a503dec0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132feeb0>]}
2021-09-22 11:31:20.683849 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:31:20.684524 (MainThread): 
2021-09-22 11:31:20.684781 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:31:20.687220 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 11:31:20.687441 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 11:31:22.225390 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 11:31:22.225586 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 11:31:22.230300 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:31:22.231044 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60519), raddr=('142.250.182.42', 443)>
2021-09-22 11:31:22.231183 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60520), raddr=('142.250.182.106', 443)>
2021-09-22 11:31:23.686591 (MainThread): 17:01:23 | Concurrency: 1 threads (target='dev')
2021-09-22 11:31:23.686780 (MainThread): 17:01:23 | 
2021-09-22 11:31:23.689354 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 11:31:23.690516 (Thread-1): 17:01:23 | 1 of 2 START table model test.first_model............................ [RUN]
2021-09-22 11:31:23.690809 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:31:23.690934 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 11:31:23.712758 (Thread-1): finished collecting timing info
2021-09-22 11:31:23.713256 (Thread-1): Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 281, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/compile.py", line 32, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/Library/Python/3.8/site-packages/dbt/compilation.py", line 502, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/Library/Python/3.8/site-packages/dbt/compilation.py", line 404, in _compile_node
    compiled_node.compiled_sql = jinja.get_rendered(
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/Library/Python/3.8/site-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/Library/Python/3.8/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/Library/Python/3.8/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 21, in top-level template code
  File "/Library/Python/3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/context/base.py", line 158, in __call__
    return self.get_missing_var(var_name)
  File "/Library/Python/3.8/site-packages/dbt/context/base.py", line 139, in get_missing_var
    raise_compiler_error(msg, self._node)
  File "/Library/Python/3.8/site-packages/dbt/exceptions.py", line 435, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-09-22 11:31:23.748830 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '800e2552-b8ee-4876-bc92-a9f1a503dec0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11348a8b0>]}
2021-09-22 11:31:23.750071 (Thread-1): 17:01:23 | 1 of 2 ERROR creating table model test.first_model................... [ERROR in 0.06s]
2021-09-22 11:31:23.750210 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 11:31:23.750691 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 11:31:23.750835 (Thread-1): 17:01:23 | 2 of 2 SKIP relation test.my_second_dbt_model........................ [SKIP]
2021-09-22 11:31:23.750957 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 11:31:23.751666 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:31:23.751933 (MainThread): 17:01:23 | 
2021-09-22 11:31:23.752048 (MainThread): 17:01:23 | Finished running 1 table model, 1 view model in 3.07s.
2021-09-22 11:31:23.752145 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:31:23.752218 (MainThread): Connection 'model.dbt_project.my_first_dbt_model' was properly closed.
2021-09-22 11:31:23.793528 (MainThread): 
2021-09-22 11:31:23.793691 (MainThread): Completed with 1 error and 0 warnings:
2021-09-22 11:31:23.793805 (MainThread): 
2021-09-22 11:31:23.793912 (MainThread): Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-09-22 11:31:23.794007 (MainThread):   Required var 'my_first_variable' not found in config:
2021-09-22 11:31:23.794092 (MainThread):   Vars supplied to my_first_dbt_model = {}
2021-09-22 11:31:23.794176 (MainThread):   
2021-09-22 11:31:23.794260 (MainThread):   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-09-22 11:31:23.794342 (MainThread):   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-09-22 11:31:23.794434 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-09-22 11:31:23.794587 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11335cd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113327f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11348ab20>]}
2021-09-22 11:31:23.794775 (MainThread): Flushing usage events
2021-09-22 11:35:11.214730 (MainThread): Running with dbt=0.19.0
2021-09-22 11:35:11.503741 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 11:35:11.504754 (MainThread): Tracking: tracking
2021-09-22 11:35:11.513150 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103fc6e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103fd97f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103fd9790>]}
2021-09-22 11:35:11.535868 (MainThread): Partial parsing not enabled
2021-09-22 11:35:11.537137 (MainThread): Parsing macros/etc.sql
2021-09-22 11:35:11.540291 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:35:11.546908 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:35:11.565699 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:35:11.568623 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:35:11.571555 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:35:11.581345 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:35:11.585933 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:35:11.598367 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:35:11.601688 (MainThread): Parsing macros/core.sql
2021-09-22 11:35:11.605894 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:35:11.614369 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:35:11.616419 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:35:11.659717 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:35:11.703264 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:35:11.725913 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:35:11.727805 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:35:11.733821 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:35:11.747315 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:35:11.755112 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:35:11.762403 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:35:11.767674 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:35:11.768733 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:35:11.769898 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:35:11.771620 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:35:11.779975 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:35:11.782011 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:35:11.784357 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:35:11.824958 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:35:11.826920 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:35:11.828590 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:35:11.830389 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:35:11.837617 (MainThread): Partial parsing not enabled
2021-09-22 11:35:11.880412 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:35:11.902436 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:35:12.082763 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e2ec0ee2-7f9a-4a50-b7c8-697cc7d52686', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104307d30>]}
2021-09-22 11:35:12.115900 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:35:12.116711 (MainThread): 
2021-09-22 11:35:12.117007 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:35:12.119288 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 11:35:12.119406 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 11:35:13.762814 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 11:35:13.763039 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 11:35:13.769003 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:35:13.769864 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60553), raddr=('142.250.205.234', 443)>
2021-09-22 11:35:13.770038 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60554), raddr=('142.250.182.106', 443)>
2021-09-22 11:35:15.291888 (MainThread): 17:05:15 | Concurrency: 1 threads (target='dev')
2021-09-22 11:35:15.292119 (MainThread): 17:05:15 | 
2021-09-22 11:35:15.295213 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 11:35:15.296417 (Thread-1): 17:05:15 | 1 of 2 START table model test.first_model............................ [RUN]
2021-09-22 11:35:15.296723 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:35:15.296861 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 11:35:15.321213 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 11:35:15.322582 (Thread-1): finished collecting timing info
2021-09-22 11:35:15.367466 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 11:35:15.369036 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:35:15.374514 (Thread-1): On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */


  create or replace table `unique-arbor-326717`.`test`.`first_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/


-- , schema='dbt_test'  , database='ivory-mountain-326811'


with source_data as (

    select 1 as id
    union all
    select null as id

)

select * , True as first_variable
from source_data
where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-09-22 11:35:20.079342 (Thread-1): finished collecting timing info
2021-09-22 11:35:20.080224 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e2ec0ee2-7f9a-4a50-b7c8-697cc7d52686', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1043566a0>]}
2021-09-22 11:35:20.081363 (Thread-1): 17:05:20 | 1 of 2 OK created table model test.first_model....................... [CREATE TABLE (1.0 rows, 0.0 Bytes processed) in 4.78s]
2021-09-22 11:35:20.081503 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 11:35:20.082087 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 11:35:20.083268 (Thread-1): 17:05:20 | 2 of 2 START view model test.my_second_dbt_model..................... [RUN]
2021-09-22 11:35:20.083555 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:35:20.083668 (Thread-1): Compiling model.dbt_project.my_second_dbt_model
2021-09-22 11:35:20.091467 (Thread-1): Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 11:35:20.092807 (Thread-1): finished collecting timing info
2021-09-22 11:35:20.118695 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 11:35:20.119210 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:35:20.124757 (Thread-1): On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `unique-arbor-326717`.`test`.`first_model`
where id = 1;


2021-09-22 11:35:23.075957 (Thread-1): finished collecting timing info
2021-09-22 11:35:23.076649 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e2ec0ee2-7f9a-4a50-b7c8-697cc7d52686', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1041a3730>]}
2021-09-22 11:35:23.077796 (Thread-1): 17:05:23 | 2 of 2 OK created view model test.my_second_dbt_model................ [OK in 2.99s]
2021-09-22 11:35:23.077941 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 11:35:23.078890 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:35:23.079189 (MainThread): 17:05:23 | 
2021-09-22 11:35:23.079319 (MainThread): 17:05:23 | Finished running 1 table model, 1 view model in 10.96s.
2021-09-22 11:35:23.079430 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:35:23.079539 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 11:35:23.119546 (MainThread): 
2021-09-22 11:35:23.119710 (MainThread): Completed successfully
2021-09-22 11:35:23.119827 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-09-22 11:35:23.119992 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042b4b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042d3880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c3fa30>]}
2021-09-22 11:35:23.120183 (MainThread): Flushing usage events
2021-09-22 11:46:25.268025 (MainThread): Running with dbt=0.19.0
2021-09-22 11:46:25.596179 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-09-22 11:46:25.598397 (MainThread): Tracking: tracking
2021-09-22 11:46:25.610017 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106814ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106827760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106827700>]}
2021-09-22 11:46:25.636081 (MainThread): Partial parsing not enabled
2021-09-22 11:46:25.637792 (MainThread): Parsing macros/etc.sql
2021-09-22 11:46:25.641626 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:46:25.650459 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:46:25.673167 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:46:25.677744 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:46:25.681938 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:46:25.693912 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:46:25.699164 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:46:25.712877 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:46:25.716784 (MainThread): Parsing macros/core.sql
2021-09-22 11:46:25.721565 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:46:25.730674 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:46:25.733210 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:46:25.783970 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:46:25.825903 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:46:25.849074 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:46:25.851052 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:46:25.857488 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:46:25.871450 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:46:25.878548 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:46:25.885657 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:46:25.891041 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:46:25.892207 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:46:25.893497 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:46:25.895428 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:46:25.904714 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:46:25.907186 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:46:25.909407 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:46:25.960956 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:46:25.963361 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:46:25.965504 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:46:25.967707 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:46:25.977571 (MainThread): Partial parsing not enabled
2021-09-22 11:46:26.023303 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:46:26.045694 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:46:26.274731 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '208f0a4d-37fe-4597-9305-3cb37f6df265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a144f0>]}
2021-09-22 11:46:26.315104 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:46:26.316248 (MainThread): 
2021-09-22 11:46:26.316696 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:46:26.324820 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 11:46:26.324982 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-09-22 11:46:26.331677 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:46:27.980295 (MainThread): 17:16:27 | Concurrency: 1 threads (target='dev')
2021-09-22 11:46:27.980533 (MainThread): 17:16:27 | 
2021-09-22 11:46:27.984218 (Thread-1): Began running node test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 11:46:27.984443 (Thread-1): 17:16:27 | 1 of 4 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-09-22 11:46:27.984765 (Thread-1): Acquiring new bigquery connection "test.dbt_project.not_null_my_first_dbt_model_id".
2021-09-22 11:46:27.984906 (Thread-1): Compiling test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 11:46:28.008234 (Thread-1): Writing injected SQL for node "test.dbt_project.not_null_my_first_dbt_model_id"
2021-09-22 11:46:28.009361 (Thread-1): finished collecting timing info
2021-09-22 11:46:28.009698 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:46:28.016263 (Thread-1): On test.dbt_project.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`first_model`
where id is null



2021-09-22 11:46:31.458492 (Thread-1): finished collecting timing info
2021-09-22 11:46:31.459290 (Thread-1): 17:16:31 | 1 of 4 PASS not_null_my_first_dbt_model_id........................... [PASS in 3.47s]
2021-09-22 11:46:31.459516 (Thread-1): Finished running node test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 11:46:31.459738 (Thread-1): Began running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 11:46:31.459944 (Thread-1): 17:16:31 | 2 of 4 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-09-22 11:46:31.460462 (Thread-1): Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id".
2021-09-22 11:46:31.460625 (Thread-1): Compiling test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 11:46:31.464623 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60909), raddr=('142.250.196.42', 443)>
2021-09-22 11:46:31.464854 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60910), raddr=('142.250.182.74', 443)>
2021-09-22 11:46:31.470956 (Thread-1): Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id"
2021-09-22 11:46:31.471431 (Thread-1): finished collecting timing info
2021-09-22 11:46:31.471726 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:46:31.478001 (Thread-1): On test.dbt_project.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_second_dbt_model`
where id is null



2021-09-22 11:46:35.247128 (Thread-1): finished collecting timing info
2021-09-22 11:46:35.247931 (Thread-1): 17:16:35 | 2 of 4 PASS not_null_my_second_dbt_model_id.......................... [PASS in 3.79s]
2021-09-22 11:46:35.248159 (Thread-1): Finished running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 11:46:35.248520 (Thread-1): Began running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 11:46:35.248955 (Thread-1): 17:16:35 | 3 of 4 START test unique_my_first_dbt_model_id....................... [RUN]
2021-09-22 11:46:35.249381 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id".
2021-09-22 11:46:35.249530 (Thread-1): Compiling test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 11:46:35.259498 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id"
2021-09-22 11:46:35.259986 (Thread-1): finished collecting timing info
2021-09-22 11:46:35.260286 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:46:35.266569 (Thread-1): On test.dbt_project.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`first_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 11:46:38.182594 (Thread-1): finished collecting timing info
2021-09-22 11:46:38.183412 (Thread-1): 17:16:38 | 3 of 4 PASS unique_my_first_dbt_model_id............................. [PASS in 2.93s]
2021-09-22 11:46:38.183650 (Thread-1): Finished running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 11:46:38.183892 (Thread-1): Began running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 11:46:38.184222 (Thread-1): 17:16:38 | 4 of 4 START test unique_my_second_dbt_model_id...................... [RUN]
2021-09-22 11:46:38.184770 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id".
2021-09-22 11:46:38.184932 (Thread-1): Compiling test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 11:46:38.194869 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id"
2021-09-22 11:46:38.195346 (Thread-1): finished collecting timing info
2021-09-22 11:46:38.195651 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:46:38.202122 (Thread-1): On test.dbt_project.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_second_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 11:46:44.667674 (Thread-1): finished collecting timing info
2021-09-22 11:46:44.668355 (Thread-1): 17:16:44 | 4 of 4 PASS unique_my_second_dbt_model_id............................ [PASS in 6.48s]
2021-09-22 11:46:44.668535 (Thread-1): Finished running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 11:46:44.669860 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:46:44.670246 (MainThread): 17:16:44 | 
2021-09-22 11:46:44.670412 (MainThread): 17:16:44 | Finished running 4 tests in 18.35s.
2021-09-22 11:46:44.670558 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:46:44.670664 (MainThread): Connection 'test.dbt_project.unique_my_second_dbt_model_id' was properly closed.
2021-09-22 11:46:44.689941 (MainThread): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60916), raddr=('142.250.196.42', 443)>
2021-09-22 11:46:44.690174 (MainThread): unclosed <socket.socket fd=23, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60917), raddr=('142.250.182.74', 443)>
2021-09-22 11:46:44.713451 (MainThread): 
2021-09-22 11:46:44.713619 (MainThread): Completed successfully
2021-09-22 11:46:44.713793 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-09-22 11:46:44.714040 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b18760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b36d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a25ca0>]}
2021-09-22 11:46:44.714266 (MainThread): Flushing usage events
2021-09-22 11:47:38.880653 (MainThread): Running with dbt=0.19.0
2021-09-22 11:47:39.081301 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-09-22 11:47:39.082011 (MainThread): Tracking: tracking
2021-09-22 11:47:39.089630 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d59dc70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d5ae610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d5ae5b0>]}
2021-09-22 11:47:39.109627 (MainThread): Partial parsing not enabled
2021-09-22 11:47:39.110605 (MainThread): Parsing macros/etc.sql
2021-09-22 11:47:39.113237 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:47:39.119251 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:47:39.137428 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:47:39.139995 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:47:39.142637 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:47:39.152077 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:47:39.156195 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:47:39.168218 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:47:39.170955 (MainThread): Parsing macros/core.sql
2021-09-22 11:47:39.174703 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:47:39.182981 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:47:39.184638 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:47:39.228578 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:47:39.269208 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:47:39.291000 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:47:39.292708 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:47:39.298465 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:47:39.312371 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:47:39.318795 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:47:39.324870 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:47:39.329479 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:47:39.330359 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:47:39.331334 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:47:39.332852 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:47:39.341253 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:47:39.343103 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:47:39.344675 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:47:39.385051 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:47:39.386847 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:47:39.388261 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:47:39.389851 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:47:39.397015 (MainThread): Partial parsing not enabled
2021-09-22 11:47:39.435769 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:47:39.444214 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d615fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d745190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d74e2b0>]}
2021-09-22 11:47:39.444471 (MainThread): Flushing usage events
2021-09-22 11:47:40.665261 (MainThread): Connection 'model.dbt_project.my_first_dbt_model' was properly closed.
2021-09-22 11:47:40.665472 (MainThread): Encountered an error:
2021-09-22 11:47:40.665646 (MainThread): Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  unexpected ','
    line 10
      -- , alias='first_model', schema='dbt_test'  , database='ivory-mountain-326811'
2021-09-22 11:47:40.710926 (MainThread): Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 523, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/Library/Python/3.8/site-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/Library/Python/3.8/site-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/Library/Python/3.8/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/Library/Python/3.8/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 10, in template
jinja2.exceptions.TemplateSyntaxError: unexpected ','
  line 10
    -- , alias='first_model', schema='dbt_test'  , database='ivory-mountain-326811'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/Library/Python/3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/Library/Python/3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 406, in run
    self._runtime_initialize()
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 122, in _runtime_initialize
    super()._runtime_initialize()
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 79, in _runtime_initialize
    self.load_manifest()
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 66, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/Library/Python/3.8/site-packages/dbt/perf_utils.py", line 28, in get_full_manifest
    return load_manifest(
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 854, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 434, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 282, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 232, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 183, in parse_with_cache
    parser.parse_file(block)
  File "/Library/Python/3.8/site-packages/dbt/parser/base.py", line 424, in parse_file
    self.parse_node(file_block)
  File "/Library/Python/3.8/site-packages/dbt/parser/base.py", line 397, in parse_node
    self.render_update(node, config)
  File "/Library/Python/3.8/site-packages/dbt/parser/base.py", line 372, in render_update
    self.render_with_context(node, config)
  File "/Library/Python/3.8/site-packages/dbt/parser/base.py", line 288, in render_with_context
    get_rendered(
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 570, in get_rendered
    template = get_template(
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 523, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 499, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  unexpected ','
    line 10
      -- , alias='first_model', schema='dbt_test'  , database='ivory-mountain-326811'

2021-09-22 11:47:54.495180 (MainThread): Running with dbt=0.19.0
2021-09-22 11:47:54.700338 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-09-22 11:47:54.701057 (MainThread): Tracking: tracking
2021-09-22 11:47:54.708733 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fa8dd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10faa0640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10faa05e0>]}
2021-09-22 11:47:54.728702 (MainThread): Partial parsing not enabled
2021-09-22 11:47:54.729684 (MainThread): Parsing macros/etc.sql
2021-09-22 11:47:54.732501 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:47:54.738471 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:47:54.756826 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:47:54.759446 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:47:54.762131 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:47:54.771736 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:47:54.775928 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:47:54.788083 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:47:54.790727 (MainThread): Parsing macros/core.sql
2021-09-22 11:47:54.794375 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:47:54.802854 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:47:54.804615 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:47:54.847545 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:47:54.887582 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:47:54.910390 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:47:54.912149 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:47:54.917969 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:47:54.930930 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:47:54.937462 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:47:54.943328 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:47:54.948032 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:47:54.948920 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:47:54.949888 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:47:54.951400 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:47:54.959680 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:47:54.961510 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:47:54.963074 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:47:55.003287 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:47:55.005039 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:47:55.006461 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:47:55.008042 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:47:55.015220 (MainThread): Partial parsing not enabled
2021-09-22 11:47:55.052974 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:47:55.073366 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:47:55.250399 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '00f7968b-0a30-45f6-be8e-1b785093a6d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fcc1100>]}
2021-09-22 11:47:55.282223 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:47:55.283001 (MainThread): 
2021-09-22 11:47:55.283470 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:47:55.289855 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 11:47:55.289974 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-09-22 11:47:55.295019 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:47:56.864110 (MainThread): 17:17:56 | Concurrency: 1 threads (target='dev')
2021-09-22 11:47:56.864369 (MainThread): 17:17:56 | 
2021-09-22 11:47:56.867295 (Thread-1): Began running node test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 11:47:56.867502 (Thread-1): 17:17:56 | 1 of 4 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-09-22 11:47:56.867804 (Thread-1): Acquiring new bigquery connection "test.dbt_project.not_null_my_first_dbt_model_id".
2021-09-22 11:47:56.867952 (Thread-1): Compiling test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 11:47:56.890217 (Thread-1): Writing injected SQL for node "test.dbt_project.not_null_my_first_dbt_model_id"
2021-09-22 11:47:56.890780 (Thread-1): finished collecting timing info
2021-09-22 11:47:56.891100 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:47:56.897290 (Thread-1): On test.dbt_project.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
where id is null



2021-09-22 11:47:58.909861 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
where id is null



2021-09-22 11:47:58.910088 (Thread-1): 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/f8710808-3583-4a35-aa11-bd63f81215b8?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US

(job ID: f8710808-3583-4a35-aa11-bd63f81215b8)

                                                                    -----Query Job SQL Follows-----                                                                     

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_first_dbt_model_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `unique-arbor-326717`.`test`.`my_first_dbt_model`
  10:where id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2021-09-22 11:47:58.910310 (Thread-1): finished collecting timing info
2021-09-22 11:47:58.910998 (Thread-1): Runtime Error in test not_null_my_first_dbt_model_id (models/example/schema.yml)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/f8710808-3583-4a35-aa11-bd63f81215b8?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US
  
  (job ID: f8710808-3583-4a35-aa11-bd63f81215b8)
Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.NotFound: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/f8710808-3583-4a35-aa11-bd63f81215b8?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US

(job ID: f8710808-3583-4a35-aa11-bd63f81215b8)

                                                                    -----Query Job SQL Follows-----                                                                     

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_first_dbt_model_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `unique-arbor-326717`.`test`.`my_first_dbt_model`
  10:where id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/test.py", line 85, in execute
    failed_rows = self.execute_schema_test(test)
  File "/Library/Python/3.8/site-packages/dbt/task/test.py", line 62, in execute_schema_test
    res, table = self.adapter.execute(
  File "/Library/Python/3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 181, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_my_first_dbt_model_id (models/example/schema.yml)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/f8710808-3583-4a35-aa11-bd63f81215b8?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US
  
  (job ID: f8710808-3583-4a35-aa11-bd63f81215b8)
2021-09-22 11:47:58.966783 (Thread-1): 17:17:58 | 1 of 4 ERROR not_null_my_first_dbt_model_id.......................... [ERROR in 2.10s]
2021-09-22 11:47:58.966969 (Thread-1): Finished running node test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 11:47:58.967153 (Thread-1): Began running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 11:47:58.967517 (Thread-1): 17:17:58 | 2 of 4 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-09-22 11:47:58.967908 (Thread-1): Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id".
2021-09-22 11:47:58.968046 (Thread-1): Compiling test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 11:47:58.971645 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60932), raddr=('142.250.193.138', 443)>
2021-09-22 11:47:58.971837 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60933), raddr=('142.250.182.74', 443)>
2021-09-22 11:47:58.977573 (Thread-1): Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id"
2021-09-22 11:47:58.978003 (Thread-1): finished collecting timing info
2021-09-22 11:47:58.978271 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:47:58.984033 (Thread-1): On test.dbt_project.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_second_dbt_model`
where id is null



2021-09-22 11:48:02.734741 (Thread-1): finished collecting timing info
2021-09-22 11:48:02.735540 (Thread-1): 17:18:02 | 2 of 4 PASS not_null_my_second_dbt_model_id.......................... [PASS in 3.77s]
2021-09-22 11:48:02.735770 (Thread-1): Finished running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 11:48:02.735991 (Thread-1): Began running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 11:48:02.736202 (Thread-1): 17:18:02 | 3 of 4 START test unique_my_first_dbt_model_id....................... [RUN]
2021-09-22 11:48:02.736735 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id".
2021-09-22 11:48:02.736906 (Thread-1): Compiling test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 11:48:02.748421 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id"
2021-09-22 11:48:02.748943 (Thread-1): finished collecting timing info
2021-09-22 11:48:02.749273 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:48:02.755829 (Thread-1): On test.dbt_project.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_first_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 11:48:04.746614 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_first_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 11:48:04.747839 (Thread-1): 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/dac3f5fc-ad1d-46e1-a2f9-293032e74bc8?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US

(job ID: dac3f5fc-ad1d-46e1-a2f9-293032e74bc8)

                                                                   -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        id
  13:
  14:    from `unique-arbor-326717`.`test`.`my_first_dbt_model`
  15:    where id is not null
  16:    group by id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2021-09-22 11:48:04.748158 (Thread-1): finished collecting timing info
2021-09-22 11:48:04.748898 (Thread-1): Runtime Error in test unique_my_first_dbt_model_id (models/example/schema.yml)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/dac3f5fc-ad1d-46e1-a2f9-293032e74bc8?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US
  
  (job ID: dac3f5fc-ad1d-46e1-a2f9-293032e74bc8)
Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.NotFound: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/dac3f5fc-ad1d-46e1-a2f9-293032e74bc8?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US

(job ID: dac3f5fc-ad1d-46e1-a2f9-293032e74bc8)

                                                                   -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        id
  13:
  14:    from `unique-arbor-326717`.`test`.`my_first_dbt_model`
  15:    where id is not null
  16:    group by id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/test.py", line 85, in execute
    failed_rows = self.execute_schema_test(test)
  File "/Library/Python/3.8/site-packages/dbt/task/test.py", line 62, in execute_schema_test
    res, table = self.adapter.execute(
  File "/Library/Python/3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 181, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test unique_my_first_dbt_model_id (models/example/schema.yml)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/dac3f5fc-ad1d-46e1-a2f9-293032e74bc8?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US
  
  (job ID: dac3f5fc-ad1d-46e1-a2f9-293032e74bc8)
2021-09-22 11:48:04.749891 (Thread-1): 17:18:04 | 3 of 4 ERROR unique_my_first_dbt_model_id............................ [ERROR in 2.01s]
2021-09-22 11:48:04.750069 (Thread-1): Finished running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 11:48:04.750253 (Thread-1): Began running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 11:48:04.750428 (Thread-1): 17:18:04 | 4 of 4 START test unique_my_second_dbt_model_id...................... [RUN]
2021-09-22 11:48:04.750909 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id".
2021-09-22 11:48:04.751071 (Thread-1): Compiling test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 11:48:04.760674 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id"
2021-09-22 11:48:04.761153 (Thread-1): finished collecting timing info
2021-09-22 11:48:04.761447 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:48:04.767848 (Thread-1): On test.dbt_project.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_second_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 11:48:08.534243 (Thread-1): finished collecting timing info
2021-09-22 11:48:08.535087 (Thread-1): 17:18:08 | 4 of 4 PASS unique_my_second_dbt_model_id............................ [PASS in 3.78s]
2021-09-22 11:48:08.535306 (Thread-1): Finished running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 11:48:08.536622 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:48:08.537001 (MainThread): 17:18:08 | 
2021-09-22 11:48:08.537168 (MainThread): 17:18:08 | Finished running 4 tests in 13.25s.
2021-09-22 11:48:08.537339 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:48:08.537461 (MainThread): Connection 'test.dbt_project.unique_my_second_dbt_model_id' was properly closed.
2021-09-22 11:48:08.560456 (MainThread): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60941), raddr=('142.250.193.138', 443)>
2021-09-22 11:48:08.560707 (MainThread): unclosed <socket.socket fd=23, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60942), raddr=('142.250.182.74', 443)>
2021-09-22 11:48:08.583420 (MainThread): 
2021-09-22 11:48:08.583641 (MainThread): Completed with 2 errors and 0 warnings:
2021-09-22 11:48:08.583781 (MainThread): 
2021-09-22 11:48:08.583961 (MainThread): Runtime Error in test not_null_my_first_dbt_model_id (models/example/schema.yml)
2021-09-22 11:48:08.584127 (MainThread):   404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/f8710808-3583-4a35-aa11-bd63f81215b8?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US
2021-09-22 11:48:08.584238 (MainThread):   
2021-09-22 11:48:08.584340 (MainThread):   (job ID: f8710808-3583-4a35-aa11-bd63f81215b8)
2021-09-22 11:48:08.584443 (MainThread): 
2021-09-22 11:48:08.584552 (MainThread): Runtime Error in test unique_my_first_dbt_model_id (models/example/schema.yml)
2021-09-22 11:48:08.584695 (MainThread):   404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/dac3f5fc-ad1d-46e1-a2f9-293032e74bc8?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US
2021-09-22 11:48:08.584798 (MainThread):   
2021-09-22 11:48:08.584944 (MainThread):   (job ID: dac3f5fc-ad1d-46e1-a2f9-293032e74bc8)
2021-09-22 11:48:08.585092 (MainThread): 
Done. PASS=2 WARN=0 ERROR=2 SKIP=0 TOTAL=4
2021-09-22 11:48:08.585274 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fdcef10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd90280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe717f0>]}
2021-09-22 11:48:08.585484 (MainThread): Flushing usage events
2021-09-22 11:48:50.086807 (MainThread): Running with dbt=0.19.0
2021-09-22 11:48:50.394254 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-09-22 11:48:50.395568 (MainThread): Tracking: tracking
2021-09-22 11:48:50.407161 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c44ae80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c45d820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c45d7c0>]}
2021-09-22 11:48:50.434264 (MainThread): Partial parsing not enabled
2021-09-22 11:48:50.435871 (MainThread): Parsing macros/etc.sql
2021-09-22 11:48:50.439822 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:48:50.447578 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:48:50.470448 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:48:50.474108 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:48:50.477829 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:48:50.489103 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:48:50.494027 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:48:50.508237 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:48:50.511865 (MainThread): Parsing macros/core.sql
2021-09-22 11:48:50.516526 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:48:50.526105 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:48:50.528280 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:48:50.576585 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:48:50.620226 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:48:50.645296 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:48:50.647563 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:48:50.654527 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:48:50.669255 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:48:50.676641 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:48:50.684622 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:48:50.690844 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:48:50.692165 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:48:50.693595 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:48:50.695697 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:48:50.705823 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:48:50.708258 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:48:50.710824 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:48:50.755843 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:48:50.757951 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:48:50.759751 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:48:50.761706 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:48:50.770207 (MainThread): Partial parsing not enabled
2021-09-22 11:48:50.809379 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:48:50.831423 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:48:51.019474 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '14de7df8-30a3-4f1e-afe5-a47d42040cd0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c86d400>]}
2021-09-22 11:48:51.056174 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:48:51.056895 (MainThread): 
2021-09-22 11:48:51.057154 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:48:51.064200 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 11:48:51.064465 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-09-22 11:48:51.070874 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:48:52.564784 (MainThread): 17:18:52 | Concurrency: 1 threads (target='dev')
2021-09-22 11:48:52.565038 (MainThread): 17:18:52 | 
2021-09-22 11:48:52.568679 (Thread-1): Began running node test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 11:48:52.568910 (Thread-1): 17:18:52 | 1 of 4 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-09-22 11:48:52.569227 (Thread-1): Acquiring new bigquery connection "test.dbt_project.not_null_my_first_dbt_model_id".
2021-09-22 11:48:52.569374 (Thread-1): Compiling test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 11:48:52.592211 (Thread-1): Writing injected SQL for node "test.dbt_project.not_null_my_first_dbt_model_id"
2021-09-22 11:48:52.592730 (Thread-1): finished collecting timing info
2021-09-22 11:48:52.593028 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:48:52.599179 (Thread-1): On test.dbt_project.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
where id is null



2021-09-22 11:48:54.486279 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
where id is null



2021-09-22 11:48:54.486510 (Thread-1): 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/34721006-a096-4eb6-a1fe-ee4ec0b4d02b?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US

(job ID: 34721006-a096-4eb6-a1fe-ee4ec0b4d02b)

                                                                    -----Query Job SQL Follows-----                                                                     

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_first_dbt_model_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `unique-arbor-326717`.`test`.`my_first_dbt_model`
  10:where id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2021-09-22 11:48:54.486742 (Thread-1): finished collecting timing info
2021-09-22 11:48:54.487428 (Thread-1): Runtime Error in test not_null_my_first_dbt_model_id (models/example/schema.yml)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/34721006-a096-4eb6-a1fe-ee4ec0b4d02b?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US
  
  (job ID: 34721006-a096-4eb6-a1fe-ee4ec0b4d02b)
Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.NotFound: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/34721006-a096-4eb6-a1fe-ee4ec0b4d02b?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US

(job ID: 34721006-a096-4eb6-a1fe-ee4ec0b4d02b)

                                                                    -----Query Job SQL Follows-----                                                                     

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_first_dbt_model_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `unique-arbor-326717`.`test`.`my_first_dbt_model`
  10:where id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/test.py", line 85, in execute
    failed_rows = self.execute_schema_test(test)
  File "/Library/Python/3.8/site-packages/dbt/task/test.py", line 62, in execute_schema_test
    res, table = self.adapter.execute(
  File "/Library/Python/3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 181, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_my_first_dbt_model_id (models/example/schema.yml)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/34721006-a096-4eb6-a1fe-ee4ec0b4d02b?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US
  
  (job ID: 34721006-a096-4eb6-a1fe-ee4ec0b4d02b)
2021-09-22 11:48:54.544847 (Thread-1): 17:18:54 | 1 of 4 ERROR not_null_my_first_dbt_model_id.......................... [ERROR in 1.98s]
2021-09-22 11:48:54.545017 (Thread-1): Finished running node test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 11:48:54.545177 (Thread-1): Began running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 11:48:54.545471 (Thread-1): 17:18:54 | 2 of 4 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-09-22 11:48:54.545807 (Thread-1): Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id".
2021-09-22 11:48:54.545932 (Thread-1): Compiling test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 11:48:54.550154 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60969), raddr=('142.250.193.138', 443)>
2021-09-22 11:48:54.550384 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60970), raddr=('142.250.182.74', 443)>
2021-09-22 11:48:54.556391 (Thread-1): Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id"
2021-09-22 11:48:54.556841 (Thread-1): finished collecting timing info
2021-09-22 11:48:54.557120 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:48:54.563019 (Thread-1): On test.dbt_project.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_second_dbt_model`
where id is null



2021-09-22 11:48:58.014804 (Thread-1): finished collecting timing info
2021-09-22 11:48:58.015626 (Thread-1): 17:18:58 | 2 of 4 PASS not_null_my_second_dbt_model_id.......................... [PASS in 3.47s]
2021-09-22 11:48:58.015855 (Thread-1): Finished running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 11:48:58.016081 (Thread-1): Began running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 11:48:58.016484 (Thread-1): 17:18:58 | 3 of 4 START test unique_my_first_dbt_model_id....................... [RUN]
2021-09-22 11:48:58.016994 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id".
2021-09-22 11:48:58.017150 (Thread-1): Compiling test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 11:48:58.027175 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id"
2021-09-22 11:48:58.027725 (Thread-1): finished collecting timing info
2021-09-22 11:48:58.028089 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:48:58.034900 (Thread-1): On test.dbt_project.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_first_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 11:48:59.943104 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_first_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 11:48:59.943332 (Thread-1): 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/951bbc5c-0b74-42d7-8c8f-37ef165eecd2?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US

(job ID: 951bbc5c-0b74-42d7-8c8f-37ef165eecd2)

                                                                   -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        id
  13:
  14:    from `unique-arbor-326717`.`test`.`my_first_dbt_model`
  15:    where id is not null
  16:    group by id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2021-09-22 11:48:59.943544 (Thread-1): finished collecting timing info
2021-09-22 11:48:59.944225 (Thread-1): Runtime Error in test unique_my_first_dbt_model_id (models/example/schema.yml)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/951bbc5c-0b74-42d7-8c8f-37ef165eecd2?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US
  
  (job ID: 951bbc5c-0b74-42d7-8c8f-37ef165eecd2)
Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.NotFound: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/951bbc5c-0b74-42d7-8c8f-37ef165eecd2?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US

(job ID: 951bbc5c-0b74-42d7-8c8f-37ef165eecd2)

                                                                   -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        id
  13:
  14:    from `unique-arbor-326717`.`test`.`my_first_dbt_model`
  15:    where id is not null
  16:    group by id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/test.py", line 85, in execute
    failed_rows = self.execute_schema_test(test)
  File "/Library/Python/3.8/site-packages/dbt/task/test.py", line 62, in execute_schema_test
    res, table = self.adapter.execute(
  File "/Library/Python/3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 181, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test unique_my_first_dbt_model_id (models/example/schema.yml)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/951bbc5c-0b74-42d7-8c8f-37ef165eecd2?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US
  
  (job ID: 951bbc5c-0b74-42d7-8c8f-37ef165eecd2)
2021-09-22 11:48:59.945216 (Thread-1): 17:18:59 | 3 of 4 ERROR unique_my_first_dbt_model_id............................ [ERROR in 1.93s]
2021-09-22 11:48:59.945389 (Thread-1): Finished running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 11:48:59.945569 (Thread-1): Began running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 11:48:59.945787 (Thread-1): 17:18:59 | 4 of 4 START test unique_my_second_dbt_model_id...................... [RUN]
2021-09-22 11:48:59.946343 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id".
2021-09-22 11:48:59.946503 (Thread-1): Compiling test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 11:48:59.956039 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id"
2021-09-22 11:48:59.956552 (Thread-1): finished collecting timing info
2021-09-22 11:48:59.956837 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:48:59.963147 (Thread-1): On test.dbt_project.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_second_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 11:49:02.993694 (Thread-1): finished collecting timing info
2021-09-22 11:49:02.994504 (Thread-1): 17:19:02 | 4 of 4 PASS unique_my_second_dbt_model_id............................ [PASS in 3.05s]
2021-09-22 11:49:02.994731 (Thread-1): Finished running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 11:49:02.996201 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:49:02.996577 (MainThread): 17:19:02 | 
2021-09-22 11:49:02.996741 (MainThread): 17:19:02 | Finished running 4 tests in 11.94s.
2021-09-22 11:49:02.996877 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:49:02.996981 (MainThread): Connection 'test.dbt_project.unique_my_second_dbt_model_id' was properly closed.
2021-09-22 11:49:03.019236 (MainThread): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60976), raddr=('142.250.193.138', 443)>
2021-09-22 11:49:03.019503 (MainThread): unclosed <socket.socket fd=23, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60977), raddr=('142.250.182.74', 443)>
2021-09-22 11:49:03.041301 (MainThread): 
2021-09-22 11:49:03.041465 (MainThread): Completed with 2 errors and 0 warnings:
2021-09-22 11:49:03.041583 (MainThread): 
2021-09-22 11:49:03.041781 (MainThread): Runtime Error in test not_null_my_first_dbt_model_id (models/example/schema.yml)
2021-09-22 11:49:03.041900 (MainThread):   404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/34721006-a096-4eb6-a1fe-ee4ec0b4d02b?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US
2021-09-22 11:49:03.041999 (MainThread):   
2021-09-22 11:49:03.042091 (MainThread):   (job ID: 34721006-a096-4eb6-a1fe-ee4ec0b4d02b)
2021-09-22 11:49:03.042188 (MainThread): 
2021-09-22 11:49:03.042293 (MainThread): Runtime Error in test unique_my_first_dbt_model_id (models/example/schema.yml)
2021-09-22 11:49:03.042389 (MainThread):   404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/951bbc5c-0b74-42d7-8c8f-37ef165eecd2?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US
2021-09-22 11:49:03.042478 (MainThread):   
2021-09-22 11:49:03.042565 (MainThread):   (job ID: 951bbc5c-0b74-42d7-8c8f-37ef165eecd2)
2021-09-22 11:49:03.042665 (MainThread): 
Done. PASS=2 WARN=0 ERROR=2 SKIP=0 TOTAL=4
2021-09-22 11:49:03.042830 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c896fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c861c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c898460>]}
2021-09-22 11:49:03.043021 (MainThread): Flushing usage events
2021-09-22 11:49:08.388259 (MainThread): Running with dbt=0.19.0
2021-09-22 11:49:08.605032 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-09-22 11:49:08.605814 (MainThread): Tracking: tracking
2021-09-22 11:49:08.613587 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f13220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f26700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f266a0>]}
2021-09-22 11:49:08.639367 (MainThread): Partial parsing not enabled
2021-09-22 11:49:08.640582 (MainThread): Parsing macros/etc.sql
2021-09-22 11:49:08.643828 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:49:08.651304 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:49:08.671539 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:49:08.674392 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:49:08.677191 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:49:08.687416 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:49:08.692046 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:49:08.705338 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:49:08.708170 (MainThread): Parsing macros/core.sql
2021-09-22 11:49:08.712243 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:49:08.721540 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:49:08.723322 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:49:08.772482 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:49:08.815654 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:49:08.840245 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:49:08.842518 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:49:08.849300 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:49:08.863342 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:49:08.870640 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:49:08.876927 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:49:08.882031 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:49:08.882965 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:49:08.883999 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:49:08.885603 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:49:08.894382 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:49:08.897048 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:49:08.899266 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:49:08.942451 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:49:08.944289 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:49:08.945823 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:49:08.947657 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:49:08.955146 (MainThread): Partial parsing not enabled
2021-09-22 11:49:08.994093 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:49:09.015362 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:49:09.204350 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'edf67fad-534b-416a-ac4a-5306e9d29699', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061e2f40>]}
2021-09-22 11:49:09.238569 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:49:09.239326 (MainThread): 
2021-09-22 11:49:09.239599 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:49:09.246426 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 11:49:09.246617 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-09-22 11:49:09.251706 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:49:10.778671 (MainThread): 17:19:10 | Concurrency: 1 threads (target='dev')
2021-09-22 11:49:10.778875 (MainThread): 17:19:10 | 
2021-09-22 11:49:10.782103 (Thread-1): Began running node test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 11:49:10.782377 (Thread-1): 17:19:10 | 1 of 4 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-09-22 11:49:10.782724 (Thread-1): Acquiring new bigquery connection "test.dbt_project.not_null_my_first_dbt_model_id".
2021-09-22 11:49:10.782861 (Thread-1): Compiling test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 11:49:10.805737 (Thread-1): Writing injected SQL for node "test.dbt_project.not_null_my_first_dbt_model_id"
2021-09-22 11:49:10.806318 (Thread-1): finished collecting timing info
2021-09-22 11:49:10.806647 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:49:10.813049 (Thread-1): On test.dbt_project.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
where id is null



2021-09-22 11:49:12.735319 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
where id is null



2021-09-22 11:49:12.735500 (Thread-1): 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/0f353635-7d19-46bf-8865-b4adc6804f60?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US

(job ID: 0f353635-7d19-46bf-8865-b4adc6804f60)

                                                                    -----Query Job SQL Follows-----                                                                     

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_first_dbt_model_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `unique-arbor-326717`.`test`.`my_first_dbt_model`
  10:where id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2021-09-22 11:49:12.735674 (Thread-1): finished collecting timing info
2021-09-22 11:49:12.736339 (Thread-1): Runtime Error in test not_null_my_first_dbt_model_id (models/example/schema.yml)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/0f353635-7d19-46bf-8865-b4adc6804f60?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US
  
  (job ID: 0f353635-7d19-46bf-8865-b4adc6804f60)
Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.NotFound: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/0f353635-7d19-46bf-8865-b4adc6804f60?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US

(job ID: 0f353635-7d19-46bf-8865-b4adc6804f60)

                                                                    -----Query Job SQL Follows-----                                                                     

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_first_dbt_model_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `unique-arbor-326717`.`test`.`my_first_dbt_model`
  10:where id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/test.py", line 85, in execute
    failed_rows = self.execute_schema_test(test)
  File "/Library/Python/3.8/site-packages/dbt/task/test.py", line 62, in execute_schema_test
    res, table = self.adapter.execute(
  File "/Library/Python/3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 181, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_my_first_dbt_model_id (models/example/schema.yml)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/0f353635-7d19-46bf-8865-b4adc6804f60?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US
  
  (job ID: 0f353635-7d19-46bf-8865-b4adc6804f60)
2021-09-22 11:49:12.776168 (Thread-1): 17:19:12 | 1 of 4 ERROR not_null_my_first_dbt_model_id.......................... [ERROR in 1.99s]
2021-09-22 11:49:12.776331 (Thread-1): Finished running node test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 11:49:12.776478 (Thread-1): Began running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 11:49:12.776611 (Thread-1): 17:19:12 | 2 of 4 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-09-22 11:49:12.777107 (Thread-1): Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id".
2021-09-22 11:49:12.777302 (Thread-1): Compiling test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 11:49:12.780943 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60982), raddr=('142.250.193.138', 443)>
2021-09-22 11:49:12.781130 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60983), raddr=('142.250.182.74', 443)>
2021-09-22 11:49:12.786654 (Thread-1): Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id"
2021-09-22 11:49:12.787035 (Thread-1): finished collecting timing info
2021-09-22 11:49:12.787292 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:49:12.792784 (Thread-1): On test.dbt_project.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_second_dbt_model`
where id is null



2021-09-22 11:49:16.509216 (Thread-1): finished collecting timing info
2021-09-22 11:49:16.510013 (Thread-1): 17:19:16 | 2 of 4 PASS not_null_my_second_dbt_model_id.......................... [PASS in 3.73s]
2021-09-22 11:49:16.510238 (Thread-1): Finished running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 11:49:16.510461 (Thread-1): Began running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 11:49:16.510669 (Thread-1): 17:19:16 | 3 of 4 START test unique_my_first_dbt_model_id....................... [RUN]
2021-09-22 11:49:16.511226 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id".
2021-09-22 11:49:16.511388 (Thread-1): Compiling test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 11:49:16.521553 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id"
2021-09-22 11:49:16.522057 (Thread-1): finished collecting timing info
2021-09-22 11:49:16.522358 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:49:16.528663 (Thread-1): On test.dbt_project.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_first_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 11:49:18.405196 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_first_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 11:49:18.405427 (Thread-1): 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/529fc0db-8652-45b0-aab2-5a1598a43962?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US

(job ID: 529fc0db-8652-45b0-aab2-5a1598a43962)

                                                                   -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        id
  13:
  14:    from `unique-arbor-326717`.`test`.`my_first_dbt_model`
  15:    where id is not null
  16:    group by id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2021-09-22 11:49:18.405638 (Thread-1): finished collecting timing info
2021-09-22 11:49:18.406302 (Thread-1): Runtime Error in test unique_my_first_dbt_model_id (models/example/schema.yml)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/529fc0db-8652-45b0-aab2-5a1598a43962?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US
  
  (job ID: 529fc0db-8652-45b0-aab2-5a1598a43962)
Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.NotFound: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/529fc0db-8652-45b0-aab2-5a1598a43962?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US

(job ID: 529fc0db-8652-45b0-aab2-5a1598a43962)

                                                                   -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        id
  13:
  14:    from `unique-arbor-326717`.`test`.`my_first_dbt_model`
  15:    where id is not null
  16:    group by id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/test.py", line 85, in execute
    failed_rows = self.execute_schema_test(test)
  File "/Library/Python/3.8/site-packages/dbt/task/test.py", line 62, in execute_schema_test
    res, table = self.adapter.execute(
  File "/Library/Python/3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 181, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test unique_my_first_dbt_model_id (models/example/schema.yml)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/529fc0db-8652-45b0-aab2-5a1598a43962?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US
  
  (job ID: 529fc0db-8652-45b0-aab2-5a1598a43962)
2021-09-22 11:49:18.407084 (Thread-1): 17:19:18 | 3 of 4 ERROR unique_my_first_dbt_model_id............................ [ERROR in 1.90s]
2021-09-22 11:49:18.407264 (Thread-1): Finished running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 11:49:18.407444 (Thread-1): Began running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 11:49:18.407612 (Thread-1): 17:19:18 | 4 of 4 START test unique_my_second_dbt_model_id...................... [RUN]
2021-09-22 11:49:18.408079 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id".
2021-09-22 11:49:18.408234 (Thread-1): Compiling test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 11:49:18.417959 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id"
2021-09-22 11:49:18.418462 (Thread-1): finished collecting timing info
2021-09-22 11:49:18.418780 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:49:18.425086 (Thread-1): On test.dbt_project.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_second_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 11:49:22.040013 (Thread-1): finished collecting timing info
2021-09-22 11:49:22.040814 (Thread-1): 17:19:22 | 4 of 4 PASS unique_my_second_dbt_model_id............................ [PASS in 3.63s]
2021-09-22 11:49:22.041041 (Thread-1): Finished running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 11:49:22.042439 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:49:22.042807 (MainThread): 17:19:22 | 
2021-09-22 11:49:22.042965 (MainThread): 17:19:22 | Finished running 4 tests in 12.80s.
2021-09-22 11:49:22.043100 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:49:22.043203 (MainThread): Connection 'test.dbt_project.unique_my_second_dbt_model_id' was properly closed.
2021-09-22 11:49:22.065583 (MainThread): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60989), raddr=('142.250.193.138', 443)>
2021-09-22 11:49:22.065841 (MainThread): unclosed <socket.socket fd=23, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60990), raddr=('142.250.182.74', 443)>
2021-09-22 11:49:22.087161 (MainThread): 
2021-09-22 11:49:22.087328 (MainThread): Completed with 2 errors and 0 warnings:
2021-09-22 11:49:22.087444 (MainThread): 
2021-09-22 11:49:22.087553 (MainThread): Runtime Error in test not_null_my_first_dbt_model_id (models/example/schema.yml)
2021-09-22 11:49:22.087650 (MainThread):   404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/0f353635-7d19-46bf-8865-b4adc6804f60?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US
2021-09-22 11:49:22.087741 (MainThread):   
2021-09-22 11:49:22.087827 (MainThread):   (job ID: 0f353635-7d19-46bf-8865-b4adc6804f60)
2021-09-22 11:49:22.087917 (MainThread): 
2021-09-22 11:49:22.088015 (MainThread): Runtime Error in test unique_my_first_dbt_model_id (models/example/schema.yml)
2021-09-22 11:49:22.088122 (MainThread):   404 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/529fc0db-8652-45b0-aab2-5a1598a43962?maxResults=0&location=US&prettyPrint=false: Not found: Table unique-arbor-326717:test.my_first_dbt_model was not found in location US
2021-09-22 11:49:22.088206 (MainThread):   
2021-09-22 11:49:22.088288 (MainThread):   (job ID: 529fc0db-8652-45b0-aab2-5a1598a43962)
2021-09-22 11:49:22.088382 (MainThread): 
Done. PASS=2 WARN=0 ERROR=2 SKIP=0 TOTAL=4
2021-09-22 11:49:22.088534 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106274bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060ece20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062f66d0>]}
2021-09-22 11:49:22.088717 (MainThread): Flushing usage events
2021-09-22 11:49:29.993064 (MainThread): Running with dbt=0.19.0
2021-09-22 11:49:30.216350 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 11:49:30.217056 (MainThread): Tracking: tracking
2021-09-22 11:49:30.224609 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073acbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073bf730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073bf6d0>]}
2021-09-22 11:49:30.249968 (MainThread): Partial parsing not enabled
2021-09-22 11:49:30.251162 (MainThread): Parsing macros/etc.sql
2021-09-22 11:49:30.254367 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:49:30.261598 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:49:30.284339 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:49:30.287554 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:49:30.291179 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:49:30.301661 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:49:30.306249 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:49:30.319161 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:49:30.322126 (MainThread): Parsing macros/core.sql
2021-09-22 11:49:30.325929 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:49:30.335158 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:49:30.337070 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:49:30.385592 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:49:30.428428 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:49:30.453320 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:49:30.455434 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:49:30.462041 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:49:30.476804 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:49:30.483799 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:49:30.490170 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:49:30.495056 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:49:30.496025 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:49:30.497155 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:49:30.499118 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:49:30.508102 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:49:30.510043 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:49:30.511814 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:49:30.557344 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:49:30.559226 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:49:30.560726 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:49:30.562746 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:49:30.571115 (MainThread): Partial parsing not enabled
2021-09-22 11:49:30.610323 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:49:30.632307 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:49:30.818167 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eeecbe7a-dcd2-444b-bf6d-2a4bf0f7711d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10767af70>]}
2021-09-22 11:49:30.853545 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:49:30.854216 (MainThread): 
2021-09-22 11:49:30.854530 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:49:30.856950 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 11:49:30.857135 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 11:49:32.393323 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 11:49:32.393581 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 11:49:32.400101 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:49:32.401217 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60995), raddr=('142.250.193.138', 443)>
2021-09-22 11:49:32.401415 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 60996), raddr=('142.250.182.74', 443)>
2021-09-22 11:49:34.024992 (MainThread): 17:19:34 | Concurrency: 1 threads (target='dev')
2021-09-22 11:49:34.025214 (MainThread): 17:19:34 | 
2021-09-22 11:49:34.027844 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 11:49:34.029870 (Thread-1): 17:19:34 | 1 of 2 START table model test.my_first_dbt_model..................... [RUN]
2021-09-22 11:49:34.030494 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:49:34.030667 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 11:49:34.054734 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 11:49:34.055221 (Thread-1): finished collecting timing info
2021-09-22 11:49:34.100079 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 11:49:34.100593 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:49:34.106067 (Thread-1): On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */


  create or replace table `unique-arbor-326717`.`test`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

 

-- , alias='first_model', schema='dbt_test'  , database='ivory-mountain-326811'


with source_data as (

    select 1 as id
    union all
    select null as id

)

select * 
-- , True as first_variable
from source_data
where id is not null
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-09-22 11:49:38.840806 (Thread-1): finished collecting timing info
2021-09-22 11:49:38.841558 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eeecbe7a-dcd2-444b-bf6d-2a4bf0f7711d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090638b0>]}
2021-09-22 11:49:38.843012 (Thread-1): 17:19:38 | 1 of 2 OK created table model test.my_first_dbt_model................ [CREATE TABLE (1.0 rows, 0.0 Bytes processed) in 4.81s]
2021-09-22 11:49:38.843169 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 11:49:38.843777 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 11:49:38.845036 (Thread-1): 17:19:38 | 2 of 2 START view model test.my_second_dbt_model..................... [RUN]
2021-09-22 11:49:38.845339 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:49:38.845459 (Thread-1): Compiling model.dbt_project.my_second_dbt_model
2021-09-22 11:49:38.854392 (Thread-1): Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 11:49:38.854822 (Thread-1): finished collecting timing info
2021-09-22 11:49:38.878611 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 11:49:38.879124 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:49:38.885133 (Thread-1): On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
where id = 1;


2021-09-22 11:49:41.828293 (Thread-1): finished collecting timing info
2021-09-22 11:49:41.829005 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eeecbe7a-dcd2-444b-bf6d-2a4bf0f7711d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109049f10>]}
2021-09-22 11:49:41.830410 (Thread-1): 17:19:41 | 2 of 2 OK created view model test.my_second_dbt_model................ [OK in 2.98s]
2021-09-22 11:49:41.830602 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 11:49:41.831689 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:49:41.832013 (MainThread): 17:19:41 | 
2021-09-22 11:49:41.832147 (MainThread): 17:19:41 | Finished running 1 table model, 1 view model in 10.98s.
2021-09-22 11:49:41.832259 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:49:41.832343 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 11:49:41.873669 (MainThread): 
2021-09-22 11:49:41.873824 (MainThread): Completed successfully
2021-09-22 11:49:41.873958 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-09-22 11:49:41.874126 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10770c790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107370f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109031100>]}
2021-09-22 11:49:41.874309 (MainThread): Flushing usage events
2021-09-22 11:49:47.068420 (MainThread): Running with dbt=0.19.0
2021-09-22 11:49:47.286786 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-09-22 11:49:47.287606 (MainThread): Tracking: tracking
2021-09-22 11:49:47.295350 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b0e6df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b0f86d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b0f8670>]}
2021-09-22 11:49:47.319933 (MainThread): Partial parsing not enabled
2021-09-22 11:49:47.321089 (MainThread): Parsing macros/etc.sql
2021-09-22 11:49:47.324144 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:49:47.331245 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:49:47.351601 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:49:47.354329 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:49:47.357225 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:49:47.367990 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:49:47.372443 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:49:47.385372 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:49:47.388207 (MainThread): Parsing macros/core.sql
2021-09-22 11:49:47.392023 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:49:47.401049 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:49:47.403065 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:49:47.449918 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:49:47.492029 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:49:47.516062 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:49:47.518067 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:49:47.524284 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:49:47.538480 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:49:47.545343 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:49:47.551741 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:49:47.556778 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:49:47.557847 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:49:47.558881 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:49:47.560519 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:49:47.569895 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:49:47.571896 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:49:47.573600 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:49:47.616923 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:49:47.618788 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:49:47.620312 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:49:47.622128 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:49:47.629651 (MainThread): Partial parsing not enabled
2021-09-22 11:49:47.669385 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:49:47.691148 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:49:47.892719 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fa7fe376-24a8-40e4-a455-93ee812d1653', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b3b5fa0>]}
2021-09-22 11:49:47.927254 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:49:47.927941 (MainThread): 
2021-09-22 11:49:47.928204 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:49:47.935435 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 11:49:47.935578 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-09-22 11:49:47.940584 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:49:49.591698 (MainThread): 17:19:49 | Concurrency: 1 threads (target='dev')
2021-09-22 11:49:49.591926 (MainThread): 17:19:49 | 
2021-09-22 11:49:49.594635 (Thread-1): Began running node test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 11:49:49.594821 (Thread-1): 17:19:49 | 1 of 4 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-09-22 11:49:49.595117 (Thread-1): Acquiring new bigquery connection "test.dbt_project.not_null_my_first_dbt_model_id".
2021-09-22 11:49:49.595260 (Thread-1): Compiling test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 11:49:49.618369 (Thread-1): Writing injected SQL for node "test.dbt_project.not_null_my_first_dbt_model_id"
2021-09-22 11:49:49.618906 (Thread-1): finished collecting timing info
2021-09-22 11:49:49.619211 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:49:49.625518 (Thread-1): On test.dbt_project.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
where id is null



2021-09-22 11:49:53.170192 (Thread-1): finished collecting timing info
2021-09-22 11:49:53.171006 (Thread-1): 17:19:53 | 1 of 4 PASS not_null_my_first_dbt_model_id........................... [PASS in 3.58s]
2021-09-22 11:49:53.171237 (Thread-1): Finished running node test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 11:49:53.171460 (Thread-1): Began running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 11:49:53.171665 (Thread-1): 17:19:53 | 2 of 4 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-09-22 11:49:53.172158 (Thread-1): Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id".
2021-09-22 11:49:53.172330 (Thread-1): Compiling test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 11:49:53.175990 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61007), raddr=('142.250.193.138', 443)>
2021-09-22 11:49:53.176178 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61008), raddr=('142.250.182.74', 443)>
2021-09-22 11:49:53.183001 (Thread-1): Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id"
2021-09-22 11:49:53.183497 (Thread-1): finished collecting timing info
2021-09-22 11:49:53.183804 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:49:53.190117 (Thread-1): On test.dbt_project.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_second_dbt_model`
where id is null



2021-09-22 11:49:56.651343 (Thread-1): finished collecting timing info
2021-09-22 11:49:56.652133 (Thread-1): 17:19:56 | 2 of 4 PASS not_null_my_second_dbt_model_id.......................... [PASS in 3.48s]
2021-09-22 11:49:56.652312 (Thread-1): Finished running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 11:49:56.652487 (Thread-1): Began running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 11:49:56.652646 (Thread-1): 17:19:56 | 3 of 4 START test unique_my_first_dbt_model_id....................... [RUN]
2021-09-22 11:49:56.652958 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id".
2021-09-22 11:49:56.653099 (Thread-1): Compiling test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 11:49:56.656965 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61009), raddr=('142.250.193.138', 443)>
2021-09-22 11:49:56.657151 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61010), raddr=('142.250.182.74', 443)>
2021-09-22 11:49:56.663520 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id"
2021-09-22 11:49:56.664086 (Thread-1): finished collecting timing info
2021-09-22 11:49:56.664431 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:49:56.670784 (Thread-1): On test.dbt_project.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_first_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 11:49:59.962635 (Thread-1): finished collecting timing info
2021-09-22 11:49:59.963452 (Thread-1): 17:19:59 | 3 of 4 PASS unique_my_first_dbt_model_id............................. [PASS in 3.31s]
2021-09-22 11:49:59.963690 (Thread-1): Finished running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 11:49:59.964168 (Thread-1): Began running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 11:49:59.964598 (Thread-1): 17:19:59 | 4 of 4 START test unique_my_second_dbt_model_id...................... [RUN]
2021-09-22 11:49:59.964998 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id".
2021-09-22 11:49:59.965151 (Thread-1): Compiling test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 11:49:59.975154 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id"
2021-09-22 11:49:59.975637 (Thread-1): finished collecting timing info
2021-09-22 11:49:59.975923 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:49:59.982308 (Thread-1): On test.dbt_project.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_second_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 11:50:03.921905 (Thread-1): finished collecting timing info
2021-09-22 11:50:03.922562 (Thread-1): 17:20:03 | 4 of 4 PASS unique_my_second_dbt_model_id............................ [PASS in 3.96s]
2021-09-22 11:50:03.922743 (Thread-1): Finished running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 11:50:03.923915 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:50:03.924289 (MainThread): 17:20:03 | 
2021-09-22 11:50:03.924424 (MainThread): 17:20:03 | Finished running 4 tests in 16.00s.
2021-09-22 11:50:03.924544 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:50:03.924631 (MainThread): Connection 'test.dbt_project.unique_my_second_dbt_model_id' was properly closed.
2021-09-22 11:50:03.943595 (MainThread): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61013), raddr=('142.250.193.138', 443)>
2021-09-22 11:50:03.943848 (MainThread): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61014), raddr=('142.250.182.74', 443)>
2021-09-22 11:50:03.967942 (MainThread): 
2021-09-22 11:50:03.968109 (MainThread): Completed successfully
2021-09-22 11:50:03.968234 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-09-22 11:50:03.968401 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b43d3a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b309ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b475400>]}
2021-09-22 11:50:03.968594 (MainThread): Flushing usage events
2021-09-22 11:50:29.820990 (MainThread): Running with dbt=0.19.0
2021-09-22 11:50:30.040605 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 11:50:30.041400 (MainThread): Tracking: tracking
2021-09-22 11:50:30.049322 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065dee50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065f07f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065f0790>]}
2021-09-22 11:50:30.072879 (MainThread): Partial parsing not enabled
2021-09-22 11:50:30.073881 (MainThread): Parsing macros/etc.sql
2021-09-22 11:50:30.076573 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:50:30.082748 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:50:30.101254 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:50:30.103998 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:50:30.106971 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:50:30.116822 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:50:30.121059 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:50:30.134113 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:50:30.136909 (MainThread): Parsing macros/core.sql
2021-09-22 11:50:30.140578 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:50:30.149289 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:50:30.150978 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:50:30.195894 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:50:30.236745 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:50:30.259700 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:50:30.261515 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:50:30.268593 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:50:30.283423 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:50:30.290355 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:50:30.296583 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:50:30.301978 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:50:30.302894 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:50:30.303892 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:50:30.305794 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:50:30.314836 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:50:30.316776 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:50:30.318414 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:50:30.362164 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:50:30.364312 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:50:30.365916 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:50:30.367608 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:50:30.375548 (MainThread): Partial parsing not enabled
2021-09-22 11:50:30.415009 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:50:30.436451 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:50:30.621475 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '95a0577d-6ba0-4446-b38e-912eba59f45a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10691fbe0>]}
2021-09-22 11:50:30.654812 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:50:30.655785 (MainThread): 
2021-09-22 11:50:30.656147 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:50:30.658447 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 11:50:30.658572 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 11:50:32.296110 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 11:50:32.296382 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 11:50:32.302338 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:50:32.303299 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61021), raddr=('142.250.193.138', 443)>
2021-09-22 11:50:32.303488 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61022), raddr=('142.250.182.74', 443)>
2021-09-22 11:50:33.829331 (MainThread): 17:20:33 | Concurrency: 1 threads (target='dev')
2021-09-22 11:50:33.829618 (MainThread): 17:20:33 | 
2021-09-22 11:50:33.832582 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 11:50:33.833965 (Thread-1): 17:20:33 | 1 of 2 START table model test.my_first_dbt_model..................... [RUN]
2021-09-22 11:50:33.834321 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:50:33.834461 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 11:50:33.858260 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 11:50:33.858758 (Thread-1): finished collecting timing info
2021-09-22 11:50:33.884224 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:50:33.889974 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:50:34.565071 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 11:50:34.565644 (Thread-1): On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */


  create or replace table `unique-arbor-326717`.`test`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

 

-- , alias='first_model', schema='dbt_test'  , database='ivory-mountain-326811'


with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 1 as id


)

select * 
-- , True as first_variable
from source_data
where id is not null
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-09-22 11:50:38.644670 (Thread-1): finished collecting timing info
2021-09-22 11:50:38.645385 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95a0577d-6ba0-4446-b38e-912eba59f45a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10829caf0>]}
2021-09-22 11:50:38.646705 (Thread-1): 17:20:38 | 1 of 2 OK created table model test.my_first_dbt_model................ [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 4.81s]
2021-09-22 11:50:38.646877 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 11:50:38.647484 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 11:50:38.648719 (Thread-1): 17:20:38 | 2 of 2 START view model test.my_second_dbt_model..................... [RUN]
2021-09-22 11:50:38.649037 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:50:38.649234 (Thread-1): Compiling model.dbt_project.my_second_dbt_model
2021-09-22 11:50:38.657904 (Thread-1): Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 11:50:38.658350 (Thread-1): finished collecting timing info
2021-09-22 11:50:38.681386 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 11:50:38.681913 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:50:38.687753 (Thread-1): On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
where id = 1;


2021-09-22 11:50:41.714764 (Thread-1): finished collecting timing info
2021-09-22 11:50:41.715493 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95a0577d-6ba0-4446-b38e-912eba59f45a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108278580>]}
2021-09-22 11:50:41.716738 (Thread-1): 17:20:41 | 2 of 2 OK created view model test.my_second_dbt_model................ [OK in 3.07s]
2021-09-22 11:50:41.716893 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 11:50:41.718025 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:50:41.718368 (MainThread): 17:20:41 | 
2021-09-22 11:50:41.718510 (MainThread): 17:20:41 | Finished running 1 table model, 1 view model in 11.06s.
2021-09-22 11:50:41.718630 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:50:41.718718 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 11:50:41.760449 (MainThread): 
2021-09-22 11:50:41.760620 (MainThread): Completed successfully
2021-09-22 11:50:41.760763 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-09-22 11:50:41.760935 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068afd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068eb880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068cbb50>]}
2021-09-22 11:50:41.761133 (MainThread): Flushing usage events
2021-09-22 11:51:05.508774 (MainThread): Running with dbt=0.19.0
2021-09-22 11:51:05.748237 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-09-22 11:51:05.749038 (MainThread): Tracking: tracking
2021-09-22 11:51:05.758887 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108071cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108084790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108084730>]}
2021-09-22 11:51:05.785355 (MainThread): Partial parsing not enabled
2021-09-22 11:51:05.786619 (MainThread): Parsing macros/etc.sql
2021-09-22 11:51:05.789916 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:51:05.797310 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:51:05.820071 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:51:05.823337 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:51:05.826509 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:51:05.837044 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:51:05.841558 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:51:05.855271 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:51:05.858099 (MainThread): Parsing macros/core.sql
2021-09-22 11:51:05.861997 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:51:05.871437 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:51:05.873228 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:51:05.919714 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:51:05.962198 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:51:05.987198 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:51:05.989332 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:51:05.996037 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:51:06.010273 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:51:06.017201 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:51:06.023510 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:51:06.028484 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:51:06.029442 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:51:06.030518 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:51:06.032302 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:51:06.041273 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:51:06.043232 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:51:06.044943 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:51:06.089006 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:51:06.090920 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:51:06.092489 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:51:06.094304 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:51:06.103102 (MainThread): Partial parsing not enabled
2021-09-22 11:51:06.143437 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:51:06.164940 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:51:06.352674 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f192cbac-2d02-46df-808f-693a632cd76c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10835a3a0>]}
2021-09-22 11:51:06.386776 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:51:06.387491 (MainThread): 
2021-09-22 11:51:06.387759 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:51:06.394406 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 11:51:06.394524 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-09-22 11:51:06.400056 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:51:08.032470 (MainThread): 17:21:08 | Concurrency: 1 threads (target='dev')
2021-09-22 11:51:08.032725 (MainThread): 17:21:08 | 
2021-09-22 11:51:08.035725 (Thread-1): Began running node test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 11:51:08.035958 (Thread-1): 17:21:08 | 1 of 4 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-09-22 11:51:08.036295 (Thread-1): Acquiring new bigquery connection "test.dbt_project.not_null_my_first_dbt_model_id".
2021-09-22 11:51:08.036437 (Thread-1): Compiling test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 11:51:08.059734 (Thread-1): Writing injected SQL for node "test.dbt_project.not_null_my_first_dbt_model_id"
2021-09-22 11:51:08.060294 (Thread-1): finished collecting timing info
2021-09-22 11:51:08.060624 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:51:08.067170 (Thread-1): On test.dbt_project.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
where id is null



2021-09-22 11:51:11.794618 (Thread-1): finished collecting timing info
2021-09-22 11:51:11.795433 (Thread-1): 17:21:11 | 1 of 4 PASS not_null_my_first_dbt_model_id........................... [PASS in 3.76s]
2021-09-22 11:51:11.795665 (Thread-1): Finished running node test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 11:51:11.795883 (Thread-1): Began running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 11:51:11.796342 (Thread-1): 17:21:11 | 2 of 4 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-09-22 11:51:11.796767 (Thread-1): Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id".
2021-09-22 11:51:11.796973 (Thread-1): Compiling test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 11:51:11.800920 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61037), raddr=('142.250.193.138', 443)>
2021-09-22 11:51:11.801155 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61038), raddr=('142.250.182.74', 443)>
2021-09-22 11:51:11.807832 (Thread-1): Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id"
2021-09-22 11:51:11.808299 (Thread-1): finished collecting timing info
2021-09-22 11:51:11.808583 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:51:11.815098 (Thread-1): On test.dbt_project.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_second_dbt_model`
where id is null



2021-09-22 11:51:14.794049 (Thread-1): finished collecting timing info
2021-09-22 11:51:14.795602 (Thread-1): 17:21:14 | 2 of 4 PASS not_null_my_second_dbt_model_id.......................... [PASS in 3.00s]
2021-09-22 11:51:14.795927 (Thread-1): Finished running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 11:51:14.796182 (Thread-1): Began running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 11:51:14.796535 (Thread-1): 17:21:14 | 3 of 4 START test unique_my_first_dbt_model_id....................... [RUN]
2021-09-22 11:51:14.797006 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id".
2021-09-22 11:51:14.797205 (Thread-1): Compiling test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 11:51:14.801852 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61039), raddr=('142.250.193.138', 443)>
2021-09-22 11:51:14.802134 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61040), raddr=('142.250.182.74', 443)>
2021-09-22 11:51:14.808361 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id"
2021-09-22 11:51:14.808845 (Thread-1): finished collecting timing info
2021-09-22 11:51:14.809141 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:51:14.815532 (Thread-1): On test.dbt_project.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_first_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 11:51:18.643878 (Thread-1): finished collecting timing info
2021-09-22 11:51:18.644670 (Thread-1): 17:21:18 | 3 of 4 FAIL 1 unique_my_first_dbt_model_id........................... [FAIL 1 in 3.85s]
2021-09-22 11:51:18.644903 (Thread-1): Finished running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 11:51:18.645078 (Thread-1): Began running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 11:51:18.645243 (Thread-1): 17:21:18 | 4 of 4 START test unique_my_second_dbt_model_id...................... [RUN]
2021-09-22 11:51:18.645760 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id".
2021-09-22 11:51:18.645914 (Thread-1): Compiling test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 11:51:18.655862 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id"
2021-09-22 11:51:18.656352 (Thread-1): finished collecting timing info
2021-09-22 11:51:18.656637 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:51:18.662818 (Thread-1): On test.dbt_project.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_second_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 11:51:22.487908 (Thread-1): finished collecting timing info
2021-09-22 11:51:22.488673 (Thread-1): 17:21:22 | 4 of 4 FAIL 1 unique_my_second_dbt_model_id.......................... [FAIL 1 in 3.84s]
2021-09-22 11:51:22.488856 (Thread-1): Finished running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 11:51:22.490128 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:51:22.490482 (MainThread): 17:21:22 | 
2021-09-22 11:51:22.490638 (MainThread): 17:21:22 | Finished running 4 tests in 16.10s.
2021-09-22 11:51:22.490778 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:51:22.490879 (MainThread): Connection 'test.dbt_project.unique_my_second_dbt_model_id' was properly closed.
2021-09-22 11:51:22.509468 (MainThread): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61055), raddr=('142.250.193.138', 443)>
2021-09-22 11:51:22.509708 (MainThread): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61056), raddr=('142.250.182.74', 443)>
2021-09-22 11:51:22.533057 (MainThread): 
2021-09-22 11:51:22.533224 (MainThread): Completed with 2 errors and 0 warnings:
2021-09-22 11:51:22.533338 (MainThread): 
2021-09-22 11:51:22.533452 (MainThread): Failure in test unique_my_first_dbt_model_id (models/example/schema.yml)
2021-09-22 11:51:22.533553 (MainThread):   Got 1 result, expected 0.
2021-09-22 11:51:22.533684 (MainThread): 
2021-09-22 11:51:22.533812 (MainThread):   compiled SQL at target/compiled/dbt_project/models/example/schema.yml/schema_test/unique_my_first_dbt_model_id.sql
2021-09-22 11:51:22.533921 (MainThread): 
2021-09-22 11:51:22.534028 (MainThread): Failure in test unique_my_second_dbt_model_id (models/example/schema.yml)
2021-09-22 11:51:22.534127 (MainThread):   Got 1 result, expected 0.
2021-09-22 11:51:22.534220 (MainThread): 
2021-09-22 11:51:22.534316 (MainThread):   compiled SQL at target/compiled/dbt_project/models/example/schema.yml/schema_test/unique_my_second_dbt_model_id.sql
2021-09-22 11:51:22.534419 (MainThread): 
Done. PASS=2 WARN=0 ERROR=2 SKIP=0 TOTAL=4
2021-09-22 11:51:22.534579 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10836e820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10826aa00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084435e0>]}
2021-09-22 11:51:22.534769 (MainThread): Flushing usage events
2021-09-22 11:52:25.875828 (MainThread): Running with dbt=0.19.0
2021-09-22 11:52:26.170338 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 11:52:26.171420 (MainThread): Tracking: tracking
2021-09-22 11:52:26.181180 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10883fcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108852790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108852730>]}
2021-09-22 11:52:26.206833 (MainThread): Partial parsing not enabled
2021-09-22 11:52:26.208384 (MainThread): Parsing macros/etc.sql
2021-09-22 11:52:26.212098 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:52:26.220019 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:52:26.240907 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:52:26.244184 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:52:26.247315 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:52:26.258560 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:52:26.263366 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:52:26.278562 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:52:26.282437 (MainThread): Parsing macros/core.sql
2021-09-22 11:52:26.287613 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:52:26.298148 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:52:26.300719 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:52:26.346989 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:52:26.391034 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:52:26.416042 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:52:26.418494 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:52:26.425031 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:52:26.439023 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:52:26.446157 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:52:26.453642 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:52:26.459031 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:52:26.461409 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:52:26.463431 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:52:26.466344 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:52:26.478095 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:52:26.480816 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:52:26.483502 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:52:26.529600 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:52:26.532060 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:52:26.534073 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:52:26.536254 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:52:26.543762 (MainThread): Partial parsing not enabled
2021-09-22 11:52:26.584902 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:52:26.608121 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:52:26.673414 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10881ecd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108a1a940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108a27f10>]}
2021-09-22 11:52:26.673634 (MainThread): Flushing usage events
2021-09-22 11:52:27.578572 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 11:52:27.578787 (MainThread): Encountered an error:
2021-09-22 11:52:27.578950 (MainThread): Compilation Error
  Invalid test config given in models/example/schema.yml:
  	test definition dictionary must have exactly one key, got [('accepted_values', None), ('values', [1, 2]), ('quote', False)] instead (3 keys)
  	@: UnparsedNodeUpdate(original_file_path='model...ne)
2021-09-22 11:52:27.609249 (MainThread): Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/parser/schemas.py", line 402, in _parse_generic_test
    builder = TestBuilder(
  File "/Library/Python/3.8/site-packages/dbt/parser/schema_test_builders.py", line 197, in __init__
    test_name, test_args = self.extract_test_args(test, column_name)
  File "/Library/Python/3.8/site-packages/dbt/parser/schema_test_builders.py", line 246, in extract_test_args
    raise_compiler_error(
  File "/Library/Python/3.8/site-packages/dbt/exceptions.py", line 435, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error
  test definition dictionary must have exactly one key, got [('accepted_values', None), ('values', [1, 2]), ('quote', False)] instead (3 keys)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/Library/Python/3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/Library/Python/3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 406, in run
    self._runtime_initialize()
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 122, in _runtime_initialize
    super()._runtime_initialize()
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 79, in _runtime_initialize
    self.load_manifest()
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 66, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/Library/Python/3.8/site-packages/dbt/perf_utils.py", line 28, in get_full_manifest
    return load_manifest(
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 854, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 434, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 282, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 232, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 183, in parse_with_cache
    parser.parse_file(block)
  File "/Library/Python/3.8/site-packages/dbt/parser/schemas.py", line 595, in parse_file
    self.parse_tests(test_block)
  File "/Library/Python/3.8/site-packages/dbt/parser/schemas.py", line 552, in parse_tests
    self.parse_column_tests(block, column)
  File "/Library/Python/3.8/site-packages/dbt/parser/schemas.py", line 249, in parse_column_tests
    self.parse_test(block, test, column)
  File "/Library/Python/3.8/site-packages/dbt/parser/schemas.py", line 548, in parse_test
    self.parse_node(block)
  File "/Library/Python/3.8/site-packages/dbt/parser/schemas.py", line 494, in parse_node
    node = self._parse_generic_test(
  File "/Library/Python/3.8/site-packages/dbt/parser/schemas.py", line 416, in _parse_generic_test
    raise CompilationException(msg) from exc
dbt.exceptions.CompilationException: Compilation Error
  Invalid test config given in models/example/schema.yml:
  	test definition dictionary must have exactly one key, got [('accepted_values', None), ('values', [1, 2]), ('quote', False)] instead (3 keys)
  	@: UnparsedNodeUpdate(original_file_path='model...ne)

2021-09-22 11:53:10.948293 (MainThread): Running with dbt=0.19.0
2021-09-22 11:53:11.274884 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 11:53:11.276665 (MainThread): Tracking: tracking
2021-09-22 11:53:11.287867 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109077cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10908a790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10908a730>]}
2021-09-22 11:53:11.314835 (MainThread): Partial parsing not enabled
2021-09-22 11:53:11.316467 (MainThread): Parsing macros/etc.sql
2021-09-22 11:53:11.320416 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:53:11.328032 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:53:11.351381 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:53:11.354970 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:53:11.358468 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:53:11.370635 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:53:11.376049 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:53:11.391874 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:53:11.396118 (MainThread): Parsing macros/core.sql
2021-09-22 11:53:11.401285 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:53:11.412258 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:53:11.415174 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:53:11.469749 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:53:11.515504 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:53:11.545356 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:53:11.548518 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:53:11.557343 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:53:11.575219 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:53:11.583728 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:53:11.591869 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:53:11.597833 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:53:11.599169 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:53:11.600650 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:53:11.602985 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:53:11.613081 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:53:11.615319 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:53:11.617648 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:53:11.660811 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:53:11.662962 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:53:11.664864 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:53:11.666872 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:53:11.675476 (MainThread): Partial parsing not enabled
2021-09-22 11:53:11.715636 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:53:11.737652 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:53:11.801234 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109056940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109250940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10925efa0>]}
2021-09-22 11:53:11.801515 (MainThread): Flushing usage events
2021-09-22 11:53:13.063056 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 11:53:13.063272 (MainThread): Encountered an error:
2021-09-22 11:53:13.063441 (MainThread): Compilation Error
  Invalid test config given in models/example/schema.yml:
  	test definition dictionary must have exactly one key, got [('accepted_values', None), ('values', [1, 2]), ('quote', False)] instead (3 keys)
  	@: UnparsedNodeUpdate(original_file_path='model...ne)
2021-09-22 11:53:13.095468 (MainThread): Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/parser/schemas.py", line 402, in _parse_generic_test
    builder = TestBuilder(
  File "/Library/Python/3.8/site-packages/dbt/parser/schema_test_builders.py", line 197, in __init__
    test_name, test_args = self.extract_test_args(test, column_name)
  File "/Library/Python/3.8/site-packages/dbt/parser/schema_test_builders.py", line 246, in extract_test_args
    raise_compiler_error(
  File "/Library/Python/3.8/site-packages/dbt/exceptions.py", line 435, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error
  test definition dictionary must have exactly one key, got [('accepted_values', None), ('values', [1, 2]), ('quote', False)] instead (3 keys)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/Library/Python/3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/Library/Python/3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 406, in run
    self._runtime_initialize()
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 122, in _runtime_initialize
    super()._runtime_initialize()
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 79, in _runtime_initialize
    self.load_manifest()
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 66, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/Library/Python/3.8/site-packages/dbt/perf_utils.py", line 28, in get_full_manifest
    return load_manifest(
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 854, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 434, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 282, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 232, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 183, in parse_with_cache
    parser.parse_file(block)
  File "/Library/Python/3.8/site-packages/dbt/parser/schemas.py", line 595, in parse_file
    self.parse_tests(test_block)
  File "/Library/Python/3.8/site-packages/dbt/parser/schemas.py", line 552, in parse_tests
    self.parse_column_tests(block, column)
  File "/Library/Python/3.8/site-packages/dbt/parser/schemas.py", line 249, in parse_column_tests
    self.parse_test(block, test, column)
  File "/Library/Python/3.8/site-packages/dbt/parser/schemas.py", line 548, in parse_test
    self.parse_node(block)
  File "/Library/Python/3.8/site-packages/dbt/parser/schemas.py", line 494, in parse_node
    node = self._parse_generic_test(
  File "/Library/Python/3.8/site-packages/dbt/parser/schemas.py", line 416, in _parse_generic_test
    raise CompilationException(msg) from exc
dbt.exceptions.CompilationException: Compilation Error
  Invalid test config given in models/example/schema.yml:
  	test definition dictionary must have exactly one key, got [('accepted_values', None), ('values', [1, 2]), ('quote', False)] instead (3 keys)
  	@: UnparsedNodeUpdate(original_file_path='model...ne)

2021-09-22 11:54:39.322389 (MainThread): Running with dbt=0.19.0
2021-09-22 11:54:39.624061 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 11:54:39.625065 (MainThread): Tracking: tracking
2021-09-22 11:54:39.634965 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104edfd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ef2670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ef2610>]}
2021-09-22 11:54:39.657723 (MainThread): Partial parsing not enabled
2021-09-22 11:54:39.659993 (MainThread): Parsing macros/etc.sql
2021-09-22 11:54:39.663663 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:54:39.670090 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:54:39.688323 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:54:39.691334 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:54:39.694462 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:54:39.704075 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:54:39.708442 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:54:39.720618 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:54:39.723878 (MainThread): Parsing macros/core.sql
2021-09-22 11:54:39.728481 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:54:39.737328 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:54:39.739639 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:54:39.785982 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:54:39.829077 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:54:39.855706 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:54:39.857823 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:54:39.864448 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:54:39.878598 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:54:39.889586 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:54:39.898011 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:54:39.904074 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:54:39.905384 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:54:39.906759 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:54:39.908831 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:54:39.918995 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:54:39.921369 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:54:39.923861 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:54:39.967024 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:54:39.969350 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:54:39.971006 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:54:39.972858 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:54:39.980661 (MainThread): Partial parsing not enabled
2021-09-22 11:54:40.022266 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:54:40.045800 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:54:40.245802 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cfbb6ec6-6fb1-4d11-badc-81ba5f8e2a26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051f7dc0>]}
2021-09-22 11:54:40.279931 (MainThread): Found 2 models, 5 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:54:40.280619 (MainThread): 
2021-09-22 11:54:40.280872 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:54:40.283385 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 11:54:40.283513 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 11:54:41.957987 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 11:54:41.958155 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 11:54:41.964270 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:54:43.499851 (MainThread): 17:24:43 | Concurrency: 1 threads (target='dev')
2021-09-22 11:54:43.500043 (MainThread): 17:24:43 | 
2021-09-22 11:54:43.502892 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 11:54:43.504363 (Thread-1): 17:24:43 | 1 of 2 START table model test.my_first_dbt_model..................... [RUN]
2021-09-22 11:54:43.504693 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:54:43.504832 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 11:54:43.528127 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 11:54:43.528625 (Thread-1): finished collecting timing info
2021-09-22 11:54:43.554697 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:54:43.561086 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:54:45.112536 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 11:54:45.113044 (Thread-1): On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */


  create or replace table `unique-arbor-326717`.`test`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

 

-- , alias='first_model', schema='dbt_test'  , database='ivory-mountain-326811'


with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id


)

select * 
-- , True as first_variable
from source_data
where id is not null
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-09-22 11:54:48.435638 (Thread-1): finished collecting timing info
2021-09-22 11:54:48.436383 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfbb6ec6-6fb1-4d11-badc-81ba5f8e2a26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050b8640>]}
2021-09-22 11:54:48.437621 (Thread-1): 17:24:48 | 1 of 2 OK created table model test.my_first_dbt_model................ [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 4.93s]
2021-09-22 11:54:48.437786 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 11:54:48.438359 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 11:54:48.439463 (Thread-1): 17:24:48 | 2 of 2 START view model test.my_second_dbt_model..................... [RUN]
2021-09-22 11:54:48.439820 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:54:48.439951 (Thread-1): Compiling model.dbt_project.my_second_dbt_model
2021-09-22 11:54:48.448621 (Thread-1): Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 11:54:48.449055 (Thread-1): finished collecting timing info
2021-09-22 11:54:48.470201 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 11:54:48.470621 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:54:48.476304 (Thread-1): On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
where id = 1;


2021-09-22 11:54:51.475174 (Thread-1): finished collecting timing info
2021-09-22 11:54:51.475909 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfbb6ec6-6fb1-4d11-badc-81ba5f8e2a26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050f4850>]}
2021-09-22 11:54:51.477130 (Thread-1): 17:24:51 | 2 of 2 OK created view model test.my_second_dbt_model................ [OK in 3.04s]
2021-09-22 11:54:51.477284 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 11:54:51.478392 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:54:51.478710 (MainThread): 17:24:51 | 
2021-09-22 11:54:51.478850 (MainThread): 17:24:51 | Finished running 1 table model, 1 view model in 11.20s.
2021-09-22 11:54:51.478968 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:54:51.479057 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 11:54:51.504922 (MainThread): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61111), raddr=('142.250.71.10', 443)>
2021-09-22 11:54:51.505142 (MainThread): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61112), raddr=('142.250.182.106', 443)>
2021-09-22 11:54:51.505299 (MainThread): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61114), raddr=('142.250.182.106', 443)>
2021-09-22 11:54:51.505445 (MainThread): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61113), raddr=('142.250.71.10', 443)>
2021-09-22 11:54:51.505589 (MainThread): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61115), raddr=('142.250.71.10', 443)>
2021-09-22 11:54:51.505729 (MainThread): unclosed <socket.socket fd=23, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61116), raddr=('142.250.182.106', 443)>
2021-09-22 11:54:51.523304 (MainThread): 
2021-09-22 11:54:51.523452 (MainThread): Completed successfully
2021-09-22 11:54:51.523571 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-09-22 11:54:51.523739 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053361f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050b1910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105260cd0>]}
2021-09-22 11:54:51.523925 (MainThread): Flushing usage events
2021-09-22 11:55:17.187540 (MainThread): Running with dbt=0.19.0
2021-09-22 11:55:17.389165 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-09-22 11:55:17.389924 (MainThread): Tracking: tracking
2021-09-22 11:55:17.398034 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110332d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110345670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110345610>]}
2021-09-22 11:55:17.420251 (MainThread): Partial parsing not enabled
2021-09-22 11:55:17.421329 (MainThread): Parsing macros/etc.sql
2021-09-22 11:55:17.424174 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:55:17.430412 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:55:17.449292 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:55:17.452031 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:55:17.454824 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:55:17.464667 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:55:17.469124 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:55:17.481854 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:55:17.484821 (MainThread): Parsing macros/core.sql
2021-09-22 11:55:17.488590 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:55:17.497387 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:55:17.499132 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:55:17.542951 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:55:17.583301 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:55:17.605137 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:55:17.606946 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:55:17.612969 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:55:17.626414 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:55:17.632826 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:55:17.638683 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:55:17.643586 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:55:17.644456 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:55:17.645424 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:55:17.646938 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:55:17.655086 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:55:17.657061 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:55:17.658647 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:55:17.699140 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:55:17.700880 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:55:17.702282 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:55:17.703850 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:55:17.710992 (MainThread): Partial parsing not enabled
2021-09-22 11:55:17.756697 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:55:17.780698 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:55:17.986127 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '965ee334-2254-44ab-9132-5d88c83cb970', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110669970>]}
2021-09-22 11:55:18.021704 (MainThread): Found 2 models, 5 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:55:18.022444 (MainThread): 
2021-09-22 11:55:18.022717 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:55:18.031584 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 11:55:18.031810 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-09-22 11:55:18.037766 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:55:19.535926 (MainThread): 17:25:19 | Concurrency: 1 threads (target='dev')
2021-09-22 11:55:19.536969 (MainThread): 17:25:19 | 
2021-09-22 11:55:19.540082 (Thread-1): Began running node test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__2
2021-09-22 11:55:19.540408 (Thread-1): 17:25:19 | 1 of 5 START test accepted_values_my_first_dbt_model_id__False__1__2. [RUN]
2021-09-22 11:55:19.540841 (Thread-1): Acquiring new bigquery connection "test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__2".
2021-09-22 11:55:19.541010 (Thread-1): Compiling test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__2
2021-09-22 11:55:19.564226 (Thread-1): Writing injected SQL for node "test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__2"
2021-09-22 11:55:19.565127 (Thread-1): finished collecting timing info
2021-09-22 11:55:19.565471 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:55:19.571762 (Thread-1): On test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__2: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__2"} */

    
    




with all_values as (

    select distinct
        id as value_field

    from `unique-arbor-326717`.`test`.`my_first_dbt_model`

),

validation_errors as (

    select
        value_field

    from all_values
    where value_field not in (
        1,2
    )
)

select count(*) as validation_errors
from validation_errors



2021-09-22 11:55:23.624572 (Thread-1): finished collecting timing info
2021-09-22 11:55:23.625282 (Thread-1): 17:25:23 | 1 of 5 FAIL 1 accepted_values_my_first_dbt_model_id__False__1__2..... [FAIL 1 in 4.08s]
2021-09-22 11:55:23.625470 (Thread-1): Finished running node test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__2
2021-09-22 11:55:23.625649 (Thread-1): Began running node test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 11:55:23.626105 (Thread-1): 17:25:23 | 2 of 5 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-09-22 11:55:23.626647 (Thread-1): Acquiring new bigquery connection "test.dbt_project.not_null_my_first_dbt_model_id".
2021-09-22 11:55:23.626789 (Thread-1): Compiling test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 11:55:23.636048 (Thread-1): Writing injected SQL for node "test.dbt_project.not_null_my_first_dbt_model_id"
2021-09-22 11:55:23.636639 (Thread-1): finished collecting timing info
2021-09-22 11:55:23.637263 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:55:23.643974 (Thread-1): On test.dbt_project.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
where id is null



2021-09-22 11:55:27.310505 (Thread-1): finished collecting timing info
2021-09-22 11:55:27.311291 (Thread-1): 17:25:27 | 2 of 5 PASS not_null_my_first_dbt_model_id........................... [PASS in 3.68s]
2021-09-22 11:55:27.311475 (Thread-1): Finished running node test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 11:55:27.311650 (Thread-1): Began running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 11:55:27.311818 (Thread-1): 17:25:27 | 3 of 5 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-09-22 11:55:27.312270 (Thread-1): Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id".
2021-09-22 11:55:27.312413 (Thread-1): Compiling test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 11:55:27.316249 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61128), raddr=('142.250.71.10', 443)>
2021-09-22 11:55:27.316433 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61129), raddr=('142.250.182.106', 443)>
2021-09-22 11:55:27.322981 (Thread-1): Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id"
2021-09-22 11:55:27.323494 (Thread-1): finished collecting timing info
2021-09-22 11:55:27.323796 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:55:27.330134 (Thread-1): On test.dbt_project.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_second_dbt_model`
where id is null



2021-09-22 11:55:30.807412 (Thread-1): finished collecting timing info
2021-09-22 11:55:30.808103 (Thread-1): 17:25:30 | 3 of 5 PASS not_null_my_second_dbt_model_id.......................... [PASS in 3.50s]
2021-09-22 11:55:30.808289 (Thread-1): Finished running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 11:55:30.808469 (Thread-1): Began running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 11:55:30.808813 (Thread-1): 17:25:30 | 4 of 5 START test unique_my_first_dbt_model_id....................... [RUN]
2021-09-22 11:55:30.809189 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id".
2021-09-22 11:55:30.809339 (Thread-1): Compiling test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 11:55:30.818530 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id"
2021-09-22 11:55:30.819072 (Thread-1): finished collecting timing info
2021-09-22 11:55:30.819401 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:55:30.825802 (Thread-1): On test.dbt_project.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_first_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 11:55:34.684178 (Thread-1): finished collecting timing info
2021-09-22 11:55:34.685014 (Thread-1): 17:25:34 | 4 of 5 PASS unique_my_first_dbt_model_id............................. [PASS in 3.88s]
2021-09-22 11:55:34.685247 (Thread-1): Finished running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 11:55:34.685476 (Thread-1): Began running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 11:55:34.686006 (Thread-1): 17:25:34 | 5 of 5 START test unique_my_second_dbt_model_id...................... [RUN]
2021-09-22 11:55:34.686528 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id".
2021-09-22 11:55:34.686710 (Thread-1): Compiling test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 11:55:34.690035 (Thread-1): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61132), raddr=('142.250.71.10', 443)>
2021-09-22 11:55:34.690254 (Thread-1): unclosed <socket.socket fd=23, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61133), raddr=('142.250.182.106', 443)>
2021-09-22 11:55:34.697563 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id"
2021-09-22 11:55:34.698062 (Thread-1): finished collecting timing info
2021-09-22 11:55:34.698372 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:55:34.704753 (Thread-1): On test.dbt_project.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_second_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 11:55:38.473200 (Thread-1): finished collecting timing info
2021-09-22 11:55:38.474003 (Thread-1): 17:25:38 | 5 of 5 PASS unique_my_second_dbt_model_id............................ [PASS in 3.79s]
2021-09-22 11:55:38.474234 (Thread-1): Finished running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 11:55:38.475624 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:55:38.475994 (MainThread): 17:25:38 | 
2021-09-22 11:55:38.476157 (MainThread): 17:25:38 | Finished running 5 tests in 20.45s.
2021-09-22 11:55:38.476302 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:55:38.476408 (MainThread): Connection 'test.dbt_project.unique_my_second_dbt_model_id' was properly closed.
2021-09-22 11:55:38.501198 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61124), raddr=('142.250.71.10', 443)>
2021-09-22 11:55:38.501495 (MainThread): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61125), raddr=('142.250.182.106', 443)>
2021-09-22 11:55:38.501683 (MainThread): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61127), raddr=('142.250.182.106', 443)>
2021-09-22 11:55:38.501848 (MainThread): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61126), raddr=('142.250.71.10', 443)>
2021-09-22 11:55:38.505335 (MainThread): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61130), raddr=('142.250.71.10', 443)>
2021-09-22 11:55:38.505499 (MainThread): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61131), raddr=('142.250.182.106', 443)>
2021-09-22 11:55:38.508780 (MainThread): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61134), raddr=('142.250.71.10', 443)>
2021-09-22 11:55:38.508955 (MainThread): unclosed <socket.socket fd=23, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61135), raddr=('142.250.182.106', 443)>
2021-09-22 11:55:38.529545 (MainThread): 
2021-09-22 11:55:38.529704 (MainThread): Completed with 1 error and 0 warnings:
2021-09-22 11:55:38.529814 (MainThread): 
2021-09-22 11:55:38.529924 (MainThread): Failure in test accepted_values_my_first_dbt_model_id__False__1__2 (models/example/schema.yml)
2021-09-22 11:55:38.530069 (MainThread):   Got 1 result, expected 0.
2021-09-22 11:55:38.530200 (MainThread): 
2021-09-22 11:55:38.530309 (MainThread):   compiled SQL at target/compiled/dbt_project/models/example/schema.yml/schema_test/accepted_values_my_first_dbt_model_id__False__1__2.sql
2021-09-22 11:55:38.530424 (MainThread): 
Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
2021-09-22 11:55:38.530588 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107d98e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110509fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fa97f40>]}
2021-09-22 11:55:38.530780 (MainThread): Flushing usage events
2021-09-22 11:57:03.599397 (MainThread): Running with dbt=0.19.0
2021-09-22 11:57:03.814118 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 11:57:03.815731 (MainThread): Tracking: tracking
2021-09-22 11:57:03.825632 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b57ce80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b58e820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b58e7c0>]}
2021-09-22 11:57:03.848161 (MainThread): Partial parsing not enabled
2021-09-22 11:57:03.849142 (MainThread): Parsing macros/etc.sql
2021-09-22 11:57:03.851965 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:57:03.857879 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:57:03.876074 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:57:03.878735 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:57:03.881433 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:57:03.891038 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:57:03.895251 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:57:03.907428 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:57:03.910083 (MainThread): Parsing macros/core.sql
2021-09-22 11:57:03.913817 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:57:03.922362 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:57:03.924041 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:57:03.967320 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:57:04.009159 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:57:04.031700 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:57:04.033446 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:57:04.039384 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:57:04.052508 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:57:04.059044 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:57:04.064980 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:57:04.069888 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:57:04.070775 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:57:04.071760 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:57:04.073284 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:57:04.081722 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:57:04.083562 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:57:04.085227 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:57:04.125699 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:57:04.127474 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:57:04.128906 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:57:04.130506 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:57:04.137720 (MainThread): Partial parsing not enabled
2021-09-22 11:57:04.175671 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:57:04.195716 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:57:04.388754 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9af6d393-e408-4963-a09d-a00836127606', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b8d4a60>]}
2021-09-22 11:57:04.422888 (MainThread): Found 2 models, 5 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:57:04.423717 (MainThread): 
2021-09-22 11:57:04.424086 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:57:04.426294 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 11:57:04.426420 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 11:57:05.975038 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 11:57:05.975294 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 11:57:05.981780 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:57:07.569072 (MainThread): 17:27:07 | Concurrency: 1 threads (target='dev')
2021-09-22 11:57:07.569300 (MainThread): 17:27:07 | 
2021-09-22 11:57:07.571896 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 11:57:07.573350 (Thread-1): 17:27:07 | 1 of 2 START table model test.my_first_dbt_model..................... [RUN]
2021-09-22 11:57:07.573649 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:57:07.573780 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 11:57:07.596456 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 11:57:07.597020 (Thread-1): finished collecting timing info
2021-09-22 11:57:07.621159 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:57:07.626646 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:57:09.249651 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 11:57:09.250173 (Thread-1): On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */


  create or replace table `unique-arbor-326717`.`test`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

 

-- , alias='first_model', schema='dbt_test'  , database='ivory-mountain-326811'


with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id
    union all
    select accepted as id


)

select * 
-- , True as first_variable
from source_data
where id is not null
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-09-22 11:57:10.533057 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/ed063d64-86d3-4192-b1dd-9144d569b1d7?maxResults=0&location=US&prettyPrint=false: Unrecognized name: accepted at [30:12]')
2021-09-22 11:57:11.967246 (Thread-1): finished collecting timing info
2021-09-22 11:57:11.968002 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Unrecognized name: accepted at [30:12]
  compiled SQL at target/run/dbt_project/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/375d3b46-5821-48cd-b48a-3ba1e1c7107f?maxResults=0&location=US&prettyPrint=false: Unrecognized name: accepted at [30:12]

(job ID: 375d3b46-5821-48cd-b48a-3ba1e1c7107f)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */
   2:
   3:
   4:  create or replace table `unique-arbor-326717`.`test`.`my_first_dbt_model`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    /*
  10:    Welcome to your first dbt model!
  11:    Did you know that you can also configure models directly within SQL files?
  12:    This will override configurations stated in dbt_project.yml
  13:
  14:    Try changing "table" to "view" below
  15:*/
  16:
  17: 
  18:
  19:-- , alias='first_model', schema='dbt_test'  , database='ivory-mountain-326811'
  20:
  21:
  22:with source_data as (
  23:
  24:    select 1 as id
  25:    union all
  26:    select null as id
  27:    union all
  28:    select 3 as id
  29:    union all
  30:    select accepted as id
  31:
  32:
  33:)
  34:
  35:select * 
  36:-- , True as first_variable
  37:from source_data
  38:where id is not null
  39:-- where id >= 1
  40:
  41:/*
  42:    Uncomment the line below to remove records with null `id` values
  43:*/
  44:  );
  45:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 128, in macro
  File "/Library/Python/3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/Library/Python/3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Unrecognized name: accepted at [30:12]
  compiled SQL at target/run/dbt_project/models/example/my_first_dbt_model.sql
2021-09-22 11:57:12.042958 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9af6d393-e408-4963-a09d-a00836127606', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b9ce460>]}
2021-09-22 11:57:12.044671 (Thread-1): 17:27:12 | 1 of 2 ERROR creating table model test.my_first_dbt_model............ [ERROR in 4.47s]
2021-09-22 11:57:12.044877 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 11:57:12.045612 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 11:57:12.045849 (Thread-1): 17:27:12 | 2 of 2 SKIP relation test.my_second_dbt_model........................ [SKIP]
2021-09-22 11:57:12.045998 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 11:57:12.046860 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:57:12.047164 (MainThread): 17:27:12 | 
2021-09-22 11:57:12.047292 (MainThread): 17:27:12 | Finished running 1 table model, 1 view model in 7.62s.
2021-09-22 11:57:12.047405 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:57:12.047489 (MainThread): Connection 'model.dbt_project.my_first_dbt_model' was properly closed.
2021-09-22 11:57:12.086991 (MainThread): 
2021-09-22 11:57:12.087148 (MainThread): Completed with 1 error and 0 warnings:
2021-09-22 11:57:12.087257 (MainThread): 
2021-09-22 11:57:12.087360 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-09-22 11:57:12.087454 (MainThread):   Unrecognized name: accepted at [30:12]
2021-09-22 11:57:12.087541 (MainThread):   compiled SQL at target/run/dbt_project/models/example/my_first_dbt_model.sql
2021-09-22 11:57:12.087634 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-09-22 11:57:12.087784 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b76c130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b784160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7994f0>]}
2021-09-22 11:57:12.087965 (MainThread): Flushing usage events
2021-09-22 11:57:26.866942 (MainThread): Running with dbt=0.19.0
2021-09-22 11:57:27.067735 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 11:57:27.068410 (MainThread): Tracking: tracking
2021-09-22 11:57:27.076920 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd21c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd33790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd33730>]}
2021-09-22 11:57:27.098219 (MainThread): Partial parsing not enabled
2021-09-22 11:57:27.099225 (MainThread): Parsing macros/etc.sql
2021-09-22 11:57:27.101949 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:57:27.108047 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:57:27.126175 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:57:27.128782 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:57:27.131517 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:57:27.141048 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:57:27.145236 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:57:27.157390 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:57:27.160052 (MainThread): Parsing macros/core.sql
2021-09-22 11:57:27.163723 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:57:27.172112 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:57:27.173802 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:57:27.216975 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:57:27.257716 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:57:27.278741 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:57:27.280429 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:57:27.286364 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:57:27.299210 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:57:27.305759 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:57:27.311637 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:57:27.316174 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:57:27.317035 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:57:27.318192 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:57:27.319771 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:57:27.327882 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:57:27.329690 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:57:27.331316 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:57:27.371522 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:57:27.373270 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:57:27.374658 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:57:27.376370 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:57:27.383361 (MainThread): Partial parsing not enabled
2021-09-22 11:57:27.419325 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:57:27.440624 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:57:27.631545 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3144520c-091d-4b8c-8ee0-ecf50f01460a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11018d5e0>]}
2021-09-22 11:57:27.667609 (MainThread): Found 2 models, 5 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:57:27.668489 (MainThread): 
2021-09-22 11:57:27.668761 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:57:27.671143 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 11:57:27.671369 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 11:57:29.283769 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 11:57:29.284031 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 11:57:29.290320 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:57:29.995222 (MainThread): 17:27:29 | Concurrency: 1 threads (target='dev')
2021-09-22 11:57:29.995454 (MainThread): 17:27:29 | 
2021-09-22 11:57:29.997227 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 11:57:29.998586 (Thread-1): 17:27:29 | 1 of 2 START table model test.my_first_dbt_model..................... [RUN]
2021-09-22 11:57:29.998883 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:57:29.999025 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 11:57:30.022210 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 11:57:30.022720 (Thread-1): finished collecting timing info
2021-09-22 11:57:30.045858 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:57:30.051697 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:57:31.653095 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 11:57:31.653625 (Thread-1): On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */


  create or replace table `unique-arbor-326717`.`test`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

 

-- , alias='first_model', schema='dbt_test'  , database='ivory-mountain-326811'


with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id
    union all
    select 'accepted' as id


)

select * 
-- , True as first_variable
from source_data
where id is not null
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-09-22 11:57:32.960007 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/b3f3d6b7-7e7d-439e-b265-86ded7a57e25?maxResults=0&location=US&prettyPrint=false: Column 1 in UNION ALL has incompatible types: INT64, NULL, INT64, STRING at [26:5]')
2021-09-22 11:57:35.100121 (Thread-1): finished collecting timing info
2021-09-22 11:57:35.100739 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Column 1 in UNION ALL has incompatible types: INT64, NULL, INT64, STRING at [26:5]
  compiled SQL at target/run/dbt_project/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/c0b5860e-f9a8-4ae4-9efc-341e6d2ecdaf?maxResults=0&location=US&prettyPrint=false: Column 1 in UNION ALL has incompatible types: INT64, NULL, INT64, STRING at [26:5]

(job ID: c0b5860e-f9a8-4ae4-9efc-341e6d2ecdaf)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */
   2:
   3:
   4:  create or replace table `unique-arbor-326717`.`test`.`my_first_dbt_model`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    /*
  10:    Welcome to your first dbt model!
  11:    Did you know that you can also configure models directly within SQL files?
  12:    This will override configurations stated in dbt_project.yml
  13:
  14:    Try changing "table" to "view" below
  15:*/
  16:
  17: 
  18:
  19:-- , alias='first_model', schema='dbt_test'  , database='ivory-mountain-326811'
  20:
  21:
  22:with source_data as (
  23:
  24:    select 1 as id
  25:    union all
  26:    select null as id
  27:    union all
  28:    select 3 as id
  29:    union all
  30:    select 'accepted' as id
  31:
  32:
  33:)
  34:
  35:select * 
  36:-- , True as first_variable
  37:from source_data
  38:where id is not null
  39:-- where id >= 1
  40:
  41:/*
  42:    Uncomment the line below to remove records with null `id` values
  43:*/
  44:  );
  45:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 128, in macro
  File "/Library/Python/3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/Library/Python/3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Column 1 in UNION ALL has incompatible types: INT64, NULL, INT64, STRING at [26:5]
  compiled SQL at target/run/dbt_project/models/example/my_first_dbt_model.sql
2021-09-22 11:57:35.150831 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3144520c-091d-4b8c-8ee0-ecf50f01460a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11027acd0>]}
2021-09-22 11:57:35.151850 (Thread-1): 17:27:35 | 1 of 2 ERROR creating table model test.my_first_dbt_model............ [ERROR in 5.15s]
2021-09-22 11:57:35.151964 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 11:57:35.152693 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 11:57:35.152910 (Thread-1): 17:27:35 | 2 of 2 SKIP relation test.my_second_dbt_model........................ [SKIP]
2021-09-22 11:57:35.153085 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 11:57:35.153903 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:57:35.154135 (MainThread): 17:27:35 | 
2021-09-22 11:57:35.154228 (MainThread): 17:27:35 | Finished running 1 table model, 1 view model in 7.49s.
2021-09-22 11:57:35.154342 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:57:35.154455 (MainThread): Connection 'model.dbt_project.my_first_dbt_model' was properly closed.
2021-09-22 11:57:35.186909 (MainThread): 
2021-09-22 11:57:35.187043 (MainThread): Completed with 1 error and 0 warnings:
2021-09-22 11:57:35.187169 (MainThread): 
2021-09-22 11:57:35.187313 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-09-22 11:57:35.187466 (MainThread):   Column 1 in UNION ALL has incompatible types: INT64, NULL, INT64, STRING at [26:5]
2021-09-22 11:57:35.187566 (MainThread):   compiled SQL at target/run/dbt_project/models/example/my_first_dbt_model.sql
2021-09-22 11:57:35.187753 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-09-22 11:57:35.188067 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fff9670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11005de50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110031a00>]}
2021-09-22 11:57:35.188288 (MainThread): Flushing usage events
2021-09-22 11:58:06.128075 (MainThread): Running with dbt=0.19.0
2021-09-22 11:58:06.340408 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 11:58:06.341567 (MainThread): Tracking: tracking
2021-09-22 11:58:06.349402 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e2ec40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e40730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e406d0>]}
2021-09-22 11:58:06.371493 (MainThread): Partial parsing not enabled
2021-09-22 11:58:06.372851 (MainThread): Parsing macros/etc.sql
2021-09-22 11:58:06.375654 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:58:06.381963 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:58:06.401015 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:58:06.404266 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:58:06.407034 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:58:06.417126 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:58:06.421731 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:58:06.434498 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:58:06.437464 (MainThread): Parsing macros/core.sql
2021-09-22 11:58:06.441263 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:58:06.449998 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:58:06.451729 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:58:06.496107 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:58:06.537178 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:58:06.559691 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:58:06.561469 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:58:06.567562 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:58:06.580952 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:58:06.587595 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:58:06.593648 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:58:06.598417 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:58:06.599319 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:58:06.600320 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:58:06.601874 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:58:06.610291 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:58:06.612172 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:58:06.613768 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:58:06.654581 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:58:06.656348 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:58:06.657771 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:58:06.659360 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:58:06.666854 (MainThread): Partial parsing not enabled
2021-09-22 11:58:06.719618 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:58:06.761779 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:58:06.988041 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ad9ab3f9-c714-48a0-9c0a-f0535b5eadca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108110c70>]}
2021-09-22 11:58:07.024061 (MainThread): Found 2 models, 5 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:58:07.024733 (MainThread): 
2021-09-22 11:58:07.025050 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:58:07.027347 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 11:58:07.027468 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 11:58:08.608407 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 11:58:08.608653 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 11:58:08.615048 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:58:10.096047 (MainThread): 17:28:10 | Concurrency: 1 threads (target='dev')
2021-09-22 11:58:10.096230 (MainThread): 17:28:10 | 
2021-09-22 11:58:10.098012 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 11:58:10.099323 (Thread-1): 17:28:10 | 1 of 2 START table model test.my_first_dbt_model..................... [RUN]
2021-09-22 11:58:10.099635 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:58:10.099761 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 11:58:10.121412 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 11:58:10.122127 (Thread-1): finished collecting timing info
2021-09-22 11:58:10.148686 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:58:10.155100 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:58:11.643231 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 11:58:11.643749 (Thread-1): On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */


  create or replace table `unique-arbor-326717`.`test`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

 

-- , alias='first_model', schema='dbt_test'  , database='ivory-mountain-326811'


with source_data as (

    select 'accepted' as id
    union all
    select null as id
    union all
    select 'denied' as id
    union all
    select 'accepted' as id


)

select * 
-- , True as first_variable
from source_data
where id is not null
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-09-22 11:58:15.574374 (Thread-1): finished collecting timing info
2021-09-22 11:58:15.575903 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad9ab3f9-c714-48a0-9c0a-f0535b5eadca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108185c70>]}
2021-09-22 11:58:15.577137 (Thread-1): 17:28:15 | 1 of 2 OK created table model test.my_first_dbt_model................ [CREATE TABLE (3.0 rows, 0.0 Bytes processed) in 5.48s]
2021-09-22 11:58:15.577293 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 11:58:15.577823 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 11:58:15.579171 (Thread-1): 17:28:15 | 2 of 2 START view model test.my_second_dbt_model..................... [RUN]
2021-09-22 11:58:15.579476 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:58:15.579601 (Thread-1): Compiling model.dbt_project.my_second_dbt_model
2021-09-22 11:58:15.588424 (Thread-1): Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 11:58:15.588962 (Thread-1): finished collecting timing info
2021-09-22 11:58:15.610724 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 11:58:15.611217 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:58:15.616814 (Thread-1): On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
where id = 1;


2021-09-22 11:58:17.197661 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/e1f7a800-bd07-4bab-9a60-d4a492f121e8?maxResults=0&location=US&prettyPrint=false: No matching signature for operator = for argument types: STRING, INT64. Supported signature: ANY = ANY at [10:7]')
2021-09-22 11:58:19.040726 (Thread-1): finished collecting timing info
2021-09-22 11:58:19.041510 (Thread-1): Database Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)
  No matching signature for operator = for argument types: STRING, INT64. Supported signature: ANY = ANY at [10:7]
  compiled SQL at target/run/dbt_project/models/example/my_second_dbt_model.sql
Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/f8085b8f-3f02-498c-9bd7-f77f533034f7?maxResults=0&location=US&prettyPrint=false: No matching signature for operator = for argument types: STRING, INT64. Supported signature: ANY = ANY at [10:7]

(job ID: f8085b8f-3f02-498c-9bd7-f77f533034f7)

                                                               -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */
   2:
   3:
   4:  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
   5:  OPTIONS()
   6:  as -- Use the `ref` function to select from other models
   7:
   8:select *
   9:from `unique-arbor-326717`.`test`.`my_first_dbt_model`
  10:where id = 1;
  11:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/Library/Python/3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/Library/Python/3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/Library/Python/3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)
  No matching signature for operator = for argument types: STRING, INT64. Supported signature: ANY = ANY at [10:7]
  compiled SQL at target/run/dbt_project/models/example/my_second_dbt_model.sql
2021-09-22 11:58:19.096549 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad9ab3f9-c714-48a0-9c0a-f0535b5eadca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082e3250>]}
2021-09-22 11:58:19.097675 (Thread-1): 17:28:19 | 2 of 2 ERROR creating view model test.my_second_dbt_model............ [ERROR in 3.52s]
2021-09-22 11:58:19.097808 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 11:58:19.098853 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:58:19.099132 (MainThread): 17:28:19 | 
2021-09-22 11:58:19.099251 (MainThread): 17:28:19 | Finished running 1 table model, 1 view model in 12.07s.
2021-09-22 11:58:19.099350 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:58:19.099424 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 11:58:19.118081 (MainThread): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61179), raddr=('142.250.182.74', 443)>
2021-09-22 11:58:19.118222 (MainThread): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61180), raddr=('142.250.182.106', 443)>
2021-09-22 11:58:19.118412 (MainThread): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61185), raddr=('142.250.182.106', 443)>
2021-09-22 11:58:19.118529 (MainThread): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61183), raddr=('142.250.182.74', 443)>
2021-09-22 11:58:19.133952 (MainThread): 
2021-09-22 11:58:19.134164 (MainThread): Completed with 1 error and 0 warnings:
2021-09-22 11:58:19.134385 (MainThread): 
2021-09-22 11:58:19.134571 (MainThread): Database Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)
2021-09-22 11:58:19.134773 (MainThread):   No matching signature for operator = for argument types: STRING, INT64. Supported signature: ANY = ANY at [10:7]
2021-09-22 11:58:19.134909 (MainThread):   compiled SQL at target/run/dbt_project/models/example/my_second_dbt_model.sql
2021-09-22 11:58:19.135078 (MainThread): 
Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
2021-09-22 11:58:19.135345 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ea9130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081a46a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10827ec10>]}
2021-09-22 11:58:19.135496 (MainThread): Flushing usage events
2021-09-22 11:58:40.186964 (MainThread): Running with dbt=0.19.0
2021-09-22 11:58:40.387182 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 11:58:40.387842 (MainThread): Tracking: tracking
2021-09-22 11:58:40.396928 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110780e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107927c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110792760>]}
2021-09-22 11:58:40.418618 (MainThread): Partial parsing not enabled
2021-09-22 11:58:40.419589 (MainThread): Parsing macros/etc.sql
2021-09-22 11:58:40.422237 (MainThread): Parsing macros/catalog.sql
2021-09-22 11:58:40.428129 (MainThread): Parsing macros/adapters.sql
2021-09-22 11:58:40.446222 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 11:58:40.448847 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 11:58:40.451466 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 11:58:40.460833 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 11:58:40.465024 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 11:58:40.477036 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 11:58:40.479714 (MainThread): Parsing macros/core.sql
2021-09-22 11:58:40.483313 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 11:58:40.491822 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 11:58:40.493488 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 11:58:40.537720 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 11:58:40.578203 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 11:58:40.600014 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 11:58:40.601937 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 11:58:40.607891 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 11:58:40.621348 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 11:58:40.628021 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 11:58:40.633950 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 11:58:40.638650 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 11:58:40.639540 (MainThread): Parsing macros/etc/query.sql
2021-09-22 11:58:40.640523 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 11:58:40.642045 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 11:58:40.650349 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 11:58:40.652198 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 11:58:40.653767 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 11:58:40.694349 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 11:58:40.696100 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 11:58:40.697504 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 11:58:40.699081 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 11:58:40.707015 (MainThread): Partial parsing not enabled
2021-09-22 11:58:40.743916 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:58:40.763940 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:58:40.952786 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b07a8533-0dbb-41de-ab98-b1ff7798fb7f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109373d0>]}
2021-09-22 11:58:40.986552 (MainThread): Found 2 models, 5 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 11:58:40.987351 (MainThread): 
2021-09-22 11:58:40.987605 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:58:40.989817 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 11:58:40.989931 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 11:58:42.456640 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 11:58:42.456883 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 11:58:42.463302 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:58:44.032753 (MainThread): 17:28:44 | Concurrency: 1 threads (target='dev')
2021-09-22 11:58:44.032983 (MainThread): 17:28:44 | 
2021-09-22 11:58:44.035246 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 11:58:44.036731 (Thread-1): 17:28:44 | 1 of 2 START table model test.my_first_dbt_model..................... [RUN]
2021-09-22 11:58:44.037043 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 11:58:44.037180 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 11:58:44.060091 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 11:58:44.060619 (Thread-1): finished collecting timing info
2021-09-22 11:58:44.084034 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:58:44.089599 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 11:58:45.623810 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 11:58:45.624329 (Thread-1): On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */


  create or replace table `unique-arbor-326717`.`test`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

 

-- , alias='first_model', schema='dbt_test'  , database='ivory-mountain-326811'


with source_data as (

    select 'accepted' as id
    union all
    select null as id
    union all
    select 'denied' as id
    union all
    select 'accepted' as id


)

select * 
-- , True as first_variable
from source_data
where id is not null
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-09-22 11:58:48.951169 (Thread-1): finished collecting timing info
2021-09-22 11:58:48.952013 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b07a8533-0dbb-41de-ab98-b1ff7798fb7f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11075d070>]}
2021-09-22 11:58:48.953257 (Thread-1): 17:28:48 | 1 of 2 OK created table model test.my_first_dbt_model................ [CREATE TABLE (3.0 rows, 0.0 Bytes processed) in 4.91s]
2021-09-22 11:58:48.953413 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 11:58:48.953942 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 11:58:48.955415 (Thread-1): 17:28:48 | 2 of 2 START view model test.my_second_dbt_model..................... [RUN]
2021-09-22 11:58:48.955727 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 11:58:48.955858 (Thread-1): Compiling model.dbt_project.my_second_dbt_model
2021-09-22 11:58:48.964594 (Thread-1): Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 11:58:48.965039 (Thread-1): finished collecting timing info
2021-09-22 11:58:48.987596 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 11:58:48.988091 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 11:58:48.993849 (Thread-1): On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
where id = 'accepted';


2021-09-22 11:58:52.020904 (Thread-1): finished collecting timing info
2021-09-22 11:58:52.021616 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b07a8533-0dbb-41de-ab98-b1ff7798fb7f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11098a1c0>]}
2021-09-22 11:58:52.022842 (Thread-1): 17:28:52 | 2 of 2 OK created view model test.my_second_dbt_model................ [OK in 3.07s]
2021-09-22 11:58:52.022992 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 11:58:52.024040 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 11:58:52.024364 (MainThread): 17:28:52 | 
2021-09-22 11:58:52.024503 (MainThread): 17:28:52 | Finished running 1 table model, 1 view model in 11.04s.
2021-09-22 11:58:52.024620 (MainThread): Connection 'master' was properly closed.
2021-09-22 11:58:52.024708 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 11:58:52.051847 (MainThread): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61206), raddr=('142.250.182.74', 443)>
2021-09-22 11:58:52.052112 (MainThread): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61207), raddr=('142.250.182.106', 443)>
2021-09-22 11:58:52.052289 (MainThread): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61209), raddr=('142.250.182.106', 443)>
2021-09-22 11:58:52.052446 (MainThread): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61208), raddr=('142.250.182.74', 443)>
2021-09-22 11:58:52.052600 (MainThread): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61210), raddr=('142.250.182.74', 443)>
2021-09-22 11:58:52.052749 (MainThread): unclosed <socket.socket fd=23, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61211), raddr=('142.250.182.106', 443)>
2021-09-22 11:58:52.072034 (MainThread): 
2021-09-22 11:58:52.072201 (MainThread): Completed successfully
2021-09-22 11:58:52.072318 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-09-22 11:58:52.072483 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110bb83a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a32df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a327c0>]}
2021-09-22 11:58:52.072672 (MainThread): Flushing usage events
2021-09-22 12:02:19.255961 (MainThread): Running with dbt=0.19.0
2021-09-22 12:02:19.593153 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 12:02:19.594305 (MainThread): Tracking: tracking
2021-09-22 12:02:19.604206 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11031cdc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11032f6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11032f670>]}
2021-09-22 12:02:19.627255 (MainThread): Partial parsing not enabled
2021-09-22 12:02:19.628487 (MainThread): Parsing macros/etc.sql
2021-09-22 12:02:19.631576 (MainThread): Parsing macros/catalog.sql
2021-09-22 12:02:19.637850 (MainThread): Parsing macros/adapters.sql
2021-09-22 12:02:19.656416 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 12:02:19.659612 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 12:02:19.662509 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 12:02:19.672263 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 12:02:19.676602 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 12:02:19.689033 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 12:02:19.692679 (MainThread): Parsing macros/core.sql
2021-09-22 12:02:19.697008 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 12:02:19.706319 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 12:02:19.708350 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 12:02:19.754379 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 12:02:19.798358 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 12:02:19.821664 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 12:02:19.823564 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 12:02:19.832491 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 12:02:19.848365 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 12:02:19.855902 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 12:02:19.863521 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 12:02:19.869629 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 12:02:19.871339 (MainThread): Parsing macros/etc/query.sql
2021-09-22 12:02:19.872794 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 12:02:19.875481 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 12:02:19.885931 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 12:02:19.888371 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 12:02:19.891319 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 12:02:19.936347 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 12:02:19.938566 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 12:02:19.940492 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 12:02:19.942634 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 12:02:19.950896 (MainThread): Partial parsing not enabled
2021-09-22 12:02:19.989754 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:02:20.019511 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:02:20.251142 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f56df193-2650-4a69-9bae-a0f4c12461ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110633df0>]}
2021-09-22 12:02:20.286716 (MainThread): Found 2 models, 5 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 12:02:20.287557 (MainThread): 
2021-09-22 12:02:20.287866 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:02:20.290274 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 12:02:20.290414 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 12:02:21.850764 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 12:02:21.851026 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 12:02:21.857400 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:02:23.482484 (MainThread): 17:32:23 | Concurrency: 1 threads (target='dev')
2021-09-22 12:02:23.482715 (MainThread): 17:32:23 | 
2021-09-22 12:02:23.485312 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 12:02:23.486722 (Thread-1): 17:32:23 | 1 of 2 START table model test.my_first_dbt_model..................... [RUN]
2021-09-22 12:02:23.487023 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:02:23.487159 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 12:02:23.510702 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 12:02:23.511240 (Thread-1): finished collecting timing info
2021-09-22 12:02:23.534769 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:02:23.540358 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:02:25.041308 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 12:02:25.041828 (Thread-1): On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */


  create or replace table `unique-arbor-326717`.`test`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

 

-- , alias='first_model', schema='dbt_test'  , database='ivory-mountain-326811'


with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id



)

select * 
-- , True as first_variable
from source_data
where id is not null
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-09-22 12:02:28.810176 (Thread-1): finished collecting timing info
2021-09-22 12:02:28.810934 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56df193-2650-4a69-9bae-a0f4c12461ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106883a0>]}
2021-09-22 12:02:28.812177 (Thread-1): 17:32:28 | 1 of 2 OK created table model test.my_first_dbt_model................ [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 5.32s]
2021-09-22 12:02:28.812337 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 12:02:28.812990 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 12:02:28.814209 (Thread-1): 17:32:28 | 2 of 2 START view model test.my_second_dbt_model..................... [RUN]
2021-09-22 12:02:28.814521 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:02:28.814649 (Thread-1): Compiling model.dbt_project.my_second_dbt_model
2021-09-22 12:02:28.823674 (Thread-1): Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 12:02:28.824125 (Thread-1): finished collecting timing info
2021-09-22 12:02:28.846567 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 12:02:28.847108 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:02:28.852696 (Thread-1): On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
where id = 'accepted';


2021-09-22 12:02:30.818191 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/60703d17-2a1c-4ff2-9267-2633bb9f4639?maxResults=0&location=US&prettyPrint=false: No matching signature for operator = for argument types: INT64, STRING. Supported signature: ANY = ANY at [10:7]')
2021-09-22 12:02:33.205268 (Thread-1): finished collecting timing info
2021-09-22 12:02:33.206022 (Thread-1): Database Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)
  No matching signature for operator = for argument types: INT64, STRING. Supported signature: ANY = ANY at [10:7]
  compiled SQL at target/run/dbt_project/models/example/my_second_dbt_model.sql
Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/9a21a621-d1e3-4e1b-9f79-46f47765c643?maxResults=0&location=US&prettyPrint=false: No matching signature for operator = for argument types: INT64, STRING. Supported signature: ANY = ANY at [10:7]

(job ID: 9a21a621-d1e3-4e1b-9f79-46f47765c643)

                                                               -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */
   2:
   3:
   4:  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
   5:  OPTIONS()
   6:  as -- Use the `ref` function to select from other models
   7:
   8:select *
   9:from `unique-arbor-326717`.`test`.`my_first_dbt_model`
  10:where id = 'accepted';
  11:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/Library/Python/3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/Library/Python/3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/Library/Python/3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)
  No matching signature for operator = for argument types: INT64, STRING. Supported signature: ANY = ANY at [10:7]
  compiled SQL at target/run/dbt_project/models/example/my_second_dbt_model.sql
2021-09-22 12:02:33.286743 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56df193-2650-4a69-9bae-a0f4c12461ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107c0970>]}
2021-09-22 12:02:33.288066 (Thread-1): 17:32:33 | 2 of 2 ERROR creating view model test.my_second_dbt_model............ [ERROR in 4.47s]
2021-09-22 12:02:33.288220 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 12:02:33.289240 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:02:33.289543 (MainThread): 17:32:33 | 
2021-09-22 12:02:33.289671 (MainThread): 17:32:33 | Finished running 1 table model, 1 view model in 13.00s.
2021-09-22 12:02:33.289777 (MainThread): Connection 'master' was properly closed.
2021-09-22 12:02:33.289858 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 12:02:33.311280 (MainThread): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61250), raddr=('142.250.182.74', 443)>
2021-09-22 12:02:33.311515 (MainThread): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61251), raddr=('142.250.182.106', 443)>
2021-09-22 12:02:33.311678 (MainThread): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61253), raddr=('142.250.182.106', 443)>
2021-09-22 12:02:33.311819 (MainThread): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61252), raddr=('142.250.182.74', 443)>
2021-09-22 12:02:33.330303 (MainThread): 
2021-09-22 12:02:33.330457 (MainThread): Completed with 1 error and 0 warnings:
2021-09-22 12:02:33.330572 (MainThread): 
2021-09-22 12:02:33.330678 (MainThread): Database Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)
2021-09-22 12:02:33.330773 (MainThread):   No matching signature for operator = for argument types: INT64, STRING. Supported signature: ANY = ANY at [10:7]
2021-09-22 12:02:33.330860 (MainThread):   compiled SQL at target/run/dbt_project/models/example/my_second_dbt_model.sql
2021-09-22 12:02:33.330956 (MainThread): 
Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
2021-09-22 12:02:33.331110 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107b3eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11053e430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104f29d0>]}
2021-09-22 12:02:33.331298 (MainThread): Flushing usage events
2021-09-22 12:04:18.177565 (MainThread): Running with dbt=0.19.0
2021-09-22 12:04:18.375885 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 12:04:18.376762 (MainThread): Tracking: tracking
2021-09-22 12:04:18.384267 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd38c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd4b760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd4b700>]}
2021-09-22 12:04:18.404720 (MainThread): Partial parsing not enabled
2021-09-22 12:04:18.405688 (MainThread): Parsing macros/etc.sql
2021-09-22 12:04:18.408439 (MainThread): Parsing macros/catalog.sql
2021-09-22 12:04:18.414392 (MainThread): Parsing macros/adapters.sql
2021-09-22 12:04:18.432668 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 12:04:18.435326 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 12:04:18.438268 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 12:04:18.447913 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 12:04:18.452240 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 12:04:18.464821 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 12:04:18.467527 (MainThread): Parsing macros/core.sql
2021-09-22 12:04:18.471289 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 12:04:18.479735 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 12:04:18.481425 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 12:04:18.524441 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 12:04:18.564001 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 12:04:18.585231 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 12:04:18.587137 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 12:04:18.593066 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 12:04:18.607374 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 12:04:18.614436 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 12:04:18.620573 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 12:04:18.625334 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 12:04:18.626237 (MainThread): Parsing macros/etc/query.sql
2021-09-22 12:04:18.627249 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 12:04:18.628818 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 12:04:18.637363 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 12:04:18.639252 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 12:04:18.640869 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 12:04:18.682545 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 12:04:18.684402 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 12:04:18.685876 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 12:04:18.687569 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 12:04:18.696172 (MainThread): Partial parsing not enabled
2021-09-22 12:04:18.733904 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:04:18.753889 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:04:18.942807 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '17ee2dba-29e2-40cc-84ee-58db8fa8a24e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d04fe20>]}
2021-09-22 12:04:18.977185 (MainThread): Found 2 models, 5 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 12:04:18.977896 (MainThread): 
2021-09-22 12:04:18.978183 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:04:18.980541 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 12:04:18.980663 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 12:04:20.109265 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 12:04:20.109514 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 12:04:20.115770 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:04:21.054941 (MainThread): 17:34:21 | Concurrency: 1 threads (target='dev')
2021-09-22 12:04:21.055168 (MainThread): 17:34:21 | 
2021-09-22 12:04:21.056877 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 12:04:21.058290 (Thread-1): 17:34:21 | 1 of 2 START table model test.my_first_dbt_model..................... [RUN]
2021-09-22 12:04:21.058602 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:04:21.058741 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 12:04:21.081387 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 12:04:21.081892 (Thread-1): finished collecting timing info
2021-09-22 12:04:21.105028 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:04:21.110532 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:04:22.099572 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 12:04:22.100074 (Thread-1): On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */


  create or replace table `unique-arbor-326717`.`test`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

 

-- , alias='first_model', schema='dbt_test'  , database='ivory-mountain-326811'


with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id



)

select * 
-- , True as first_variable
from source_data
where id is not null
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-09-22 12:04:25.531379 (Thread-1): finished collecting timing info
2021-09-22 12:04:25.532170 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '17ee2dba-29e2-40cc-84ee-58db8fa8a24e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cf27c40>]}
2021-09-22 12:04:25.533378 (Thread-1): 17:34:25 | 1 of 2 OK created table model test.my_first_dbt_model................ [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 4.47s]
2021-09-22 12:04:25.533533 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 12:04:25.534236 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 12:04:25.535573 (Thread-1): 17:34:25 | 2 of 2 START view model test.my_second_dbt_model..................... [RUN]
2021-09-22 12:04:25.536121 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:04:25.536321 (Thread-1): Compiling model.dbt_project.my_second_dbt_model
2021-09-22 12:04:25.545501 (Thread-1): Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 12:04:25.545979 (Thread-1): finished collecting timing info
2021-09-22 12:04:25.567404 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 12:04:25.567849 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:04:25.573620 (Thread-1): On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
where id = 'accepted';


2021-09-22 12:04:27.161369 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/d5397cac-7ea4-4c76-b396-4cd6c4ba95e7?maxResults=0&location=US&prettyPrint=false: No matching signature for operator = for argument types: INT64, STRING. Supported signature: ANY = ANY at [10:7]')
2021-09-22 12:04:28.492491 (Thread-1): finished collecting timing info
2021-09-22 12:04:28.493270 (Thread-1): Database Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)
  No matching signature for operator = for argument types: INT64, STRING. Supported signature: ANY = ANY at [10:7]
  compiled SQL at target/run/dbt_project/models/example/my_second_dbt_model.sql
Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/Library/Python/3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Python/3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Python/3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/unique-arbor-326717/queries/b7fcf8dd-8059-4b0e-b5a0-5cf3d3db80d1?maxResults=0&location=US&prettyPrint=false: No matching signature for operator = for argument types: INT64, STRING. Supported signature: ANY = ANY at [10:7]

(job ID: b7fcf8dd-8059-4b0e-b5a0-5cf3d3db80d1)

                                                               -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */
   2:
   3:
   4:  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
   5:  OPTIONS()
   6:  as -- Use the `ref` function to select from other models
   7:
   8:select *
   9:from `unique-arbor-326717`.`test`.`my_first_dbt_model`
  10:where id = 'accepted';
  11:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/Library/Python/3.8/site-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/Library/Python/3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/Library/Python/3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/Library/Python/3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Library/Python/3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Library/Python/3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/Library/Python/3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)
  No matching signature for operator = for argument types: INT64, STRING. Supported signature: ANY = ANY at [10:7]
  compiled SQL at target/run/dbt_project/models/example/my_second_dbt_model.sql
2021-09-22 12:04:28.549394 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '17ee2dba-29e2-40cc-84ee-58db8fa8a24e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea2ae50>]}
2021-09-22 12:04:28.550531 (Thread-1): 17:34:28 | 2 of 2 ERROR creating view model test.my_second_dbt_model............ [ERROR in 3.01s]
2021-09-22 12:04:28.550666 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 12:04:28.551625 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:04:28.551907 (MainThread): 17:34:28 | 
2021-09-22 12:04:28.552025 (MainThread): 17:34:28 | Finished running 1 table model, 1 view model in 9.57s.
2021-09-22 12:04:28.552122 (MainThread): Connection 'master' was properly closed.
2021-09-22 12:04:28.552195 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 12:04:28.571709 (MainThread): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61274), raddr=('142.250.196.170', 443)>
2021-09-22 12:04:28.571935 (MainThread): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61275), raddr=('142.250.182.106', 443)>
2021-09-22 12:04:28.572059 (MainThread): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61278), raddr=('142.250.182.106', 443)>
2021-09-22 12:04:28.572174 (MainThread): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61277), raddr=('142.250.196.170', 443)>
2021-09-22 12:04:28.589777 (MainThread): 
2021-09-22 12:04:28.589908 (MainThread): Completed with 1 error and 0 warnings:
2021-09-22 12:04:28.589995 (MainThread): 
2021-09-22 12:04:28.590116 (MainThread): Database Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)
2021-09-22 12:04:28.590217 (MainThread):   No matching signature for operator = for argument types: INT64, STRING. Supported signature: ANY = ANY at [10:7]
2021-09-22 12:04:28.590302 (MainThread):   compiled SQL at target/run/dbt_project/models/example/my_second_dbt_model.sql
2021-09-22 12:04:28.590422 (MainThread): 
Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
2021-09-22 12:04:28.590590 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cf17730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d19f9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d18cc40>]}
2021-09-22 12:04:28.590734 (MainThread): Flushing usage events
2021-09-22 12:04:47.800677 (MainThread): Running with dbt=0.19.0
2021-09-22 12:04:48.016695 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 12:04:48.017598 (MainThread): Tracking: tracking
2021-09-22 12:04:48.025327 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042aec40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042c0730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042c06d0>]}
2021-09-22 12:04:48.049302 (MainThread): Partial parsing not enabled
2021-09-22 12:04:48.050353 (MainThread): Parsing macros/etc.sql
2021-09-22 12:04:48.053187 (MainThread): Parsing macros/catalog.sql
2021-09-22 12:04:48.059289 (MainThread): Parsing macros/adapters.sql
2021-09-22 12:04:48.078331 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 12:04:48.081132 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 12:04:48.083944 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 12:04:48.093981 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 12:04:48.098457 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 12:04:48.111140 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 12:04:48.113985 (MainThread): Parsing macros/core.sql
2021-09-22 12:04:48.117788 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 12:04:48.126416 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 12:04:48.128298 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 12:04:48.173638 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 12:04:48.215117 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 12:04:48.237479 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 12:04:48.239248 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 12:04:48.245172 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 12:04:48.258571 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 12:04:48.265173 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 12:04:48.271327 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 12:04:48.276039 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 12:04:48.276938 (MainThread): Parsing macros/etc/query.sql
2021-09-22 12:04:48.277932 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 12:04:48.279492 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 12:04:48.288268 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 12:04:48.290228 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 12:04:48.291858 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 12:04:48.332617 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 12:04:48.334423 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 12:04:48.335895 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 12:04:48.337472 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 12:04:48.344614 (MainThread): Partial parsing not enabled
2021-09-22 12:04:48.381509 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:04:48.402600 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:04:48.592361 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8794a2ea-1ab1-42aa-bf6a-5e60484fa14b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1045c5ee0>]}
2021-09-22 12:04:48.626508 (MainThread): Found 2 models, 5 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 12:04:48.627275 (MainThread): 
2021-09-22 12:04:48.627557 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:04:48.629823 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 12:04:48.629946 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 12:04:49.699696 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 12:04:49.699937 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 12:04:49.706203 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:04:50.718609 (MainThread): 17:34:50 | Concurrency: 1 threads (target='dev')
2021-09-22 12:04:50.718835 (MainThread): 17:34:50 | 
2021-09-22 12:04:50.720622 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 12:04:50.722032 (Thread-1): 17:34:50 | 1 of 2 START table model test.my_first_dbt_model..................... [RUN]
2021-09-22 12:04:50.722343 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:04:50.722504 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 12:04:50.745682 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 12:04:50.746193 (Thread-1): finished collecting timing info
2021-09-22 12:04:50.769084 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:04:50.774667 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:04:51.759173 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 12:04:51.759666 (Thread-1): On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */


  create or replace table `unique-arbor-326717`.`test`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

 

-- , alias='first_model', schema='dbt_test'  , database='ivory-mountain-326811'


with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id



)

select * 
-- , True as first_variable
from source_data
where id is not null
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-09-22 12:04:54.817637 (Thread-1): finished collecting timing info
2021-09-22 12:04:54.818357 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8794a2ea-1ab1-42aa-bf6a-5e60484fa14b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1044817c0>]}
2021-09-22 12:04:54.819545 (Thread-1): 17:34:54 | 1 of 2 OK created table model test.my_first_dbt_model................ [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 4.10s]
2021-09-22 12:04:54.819696 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 12:04:54.820159 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 12:04:54.821266 (Thread-1): 17:34:54 | 2 of 2 START view model test.my_second_dbt_model..................... [RUN]
2021-09-22 12:04:54.821767 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:04:54.822026 (Thread-1): Compiling model.dbt_project.my_second_dbt_model
2021-09-22 12:04:54.830949 (Thread-1): Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 12:04:54.831403 (Thread-1): finished collecting timing info
2021-09-22 12:04:54.853737 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 12:04:54.854237 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:04:54.859900 (Thread-1): On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
where id = 1;


2021-09-22 12:04:56.667690 (Thread-1): finished collecting timing info
2021-09-22 12:04:56.668395 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8794a2ea-1ab1-42aa-bf6a-5e60484fa14b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1044bc9d0>]}
2021-09-22 12:04:56.669572 (Thread-1): 17:34:56 | 2 of 2 OK created view model test.my_second_dbt_model................ [OK in 1.85s]
2021-09-22 12:04:56.669721 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 12:04:56.670786 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:04:56.671095 (MainThread): 17:34:56 | 
2021-09-22 12:04:56.671231 (MainThread): 17:34:56 | Finished running 1 table model, 1 view model in 8.04s.
2021-09-22 12:04:56.671345 (MainThread): Connection 'master' was properly closed.
2021-09-22 12:04:56.671432 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 12:04:56.696230 (MainThread): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61285), raddr=('142.250.196.170', 443)>
2021-09-22 12:04:56.696463 (MainThread): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61286), raddr=('142.250.182.106', 443)>
2021-09-22 12:04:56.696609 (MainThread): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61288), raddr=('142.250.182.106', 443)>
2021-09-22 12:04:56.696745 (MainThread): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61287), raddr=('142.250.196.170', 443)>
2021-09-22 12:04:56.696884 (MainThread): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61289), raddr=('142.250.196.170', 443)>
2021-09-22 12:04:56.697015 (MainThread): unclosed <socket.socket fd=23, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61290), raddr=('142.250.182.106', 443)>
2021-09-22 12:04:56.713924 (MainThread): 
2021-09-22 12:04:56.714070 (MainThread): Completed successfully
2021-09-22 12:04:56.714184 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-09-22 12:04:56.714342 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10462f4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10448eee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1044b07f0>]}
2021-09-22 12:04:56.714524 (MainThread): Flushing usage events
2021-09-22 12:05:02.680994 (MainThread): Running with dbt=0.19.0
2021-09-22 12:05:02.886731 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-09-22 12:05:02.887486 (MainThread): Tracking: tracking
2021-09-22 12:05:02.895303 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f43d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f566a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f56640>]}
2021-09-22 12:05:02.917329 (MainThread): Partial parsing not enabled
2021-09-22 12:05:02.918361 (MainThread): Parsing macros/etc.sql
2021-09-22 12:05:02.921091 (MainThread): Parsing macros/catalog.sql
2021-09-22 12:05:02.927264 (MainThread): Parsing macros/adapters.sql
2021-09-22 12:05:02.946227 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 12:05:02.949162 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 12:05:02.951967 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 12:05:02.962023 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 12:05:02.966551 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 12:05:02.979459 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 12:05:02.982268 (MainThread): Parsing macros/core.sql
2021-09-22 12:05:02.986081 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 12:05:02.994927 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 12:05:02.996742 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 12:05:03.042241 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 12:05:03.083592 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 12:05:03.106094 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 12:05:03.108123 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 12:05:03.114254 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 12:05:03.128294 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 12:05:03.135299 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 12:05:03.141701 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 12:05:03.146671 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 12:05:03.147655 (MainThread): Parsing macros/etc/query.sql
2021-09-22 12:05:03.148846 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 12:05:03.150503 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 12:05:03.159283 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 12:05:03.161251 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 12:05:03.162852 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 12:05:03.205458 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 12:05:03.207322 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 12:05:03.208801 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 12:05:03.210473 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 12:05:03.217965 (MainThread): Partial parsing not enabled
2021-09-22 12:05:03.256127 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:05:03.276076 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:05:03.504801 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0deae175-804f-41db-98da-87b9c9aef099', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11125aa60>]}
2021-09-22 12:05:03.543351 (MainThread): Found 2 models, 5 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 12:05:03.544090 (MainThread): 
2021-09-22 12:05:03.544362 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:05:03.552565 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 12:05:03.552682 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-09-22 12:05:03.557666 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:05:04.542550 (MainThread): 17:35:04 | Concurrency: 1 threads (target='dev')
2021-09-22 12:05:04.542785 (MainThread): 17:35:04 | 
2021-09-22 12:05:04.544917 (Thread-1): Began running node test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__2
2021-09-22 12:05:04.545121 (Thread-1): 17:35:04 | 1 of 5 START test accepted_values_my_first_dbt_model_id__False__1__2. [RUN]
2021-09-22 12:05:04.545432 (Thread-1): Acquiring new bigquery connection "test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__2".
2021-09-22 12:05:04.545572 (Thread-1): Compiling test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__2
2021-09-22 12:05:04.569098 (Thread-1): Writing injected SQL for node "test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__2"
2021-09-22 12:05:04.569688 (Thread-1): finished collecting timing info
2021-09-22 12:05:04.570006 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:05:04.575956 (Thread-1): On test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__2: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__2"} */

    
    




with all_values as (

    select distinct
        id as value_field

    from `unique-arbor-326717`.`test`.`my_first_dbt_model`

),

validation_errors as (

    select
        value_field

    from all_values
    where value_field not in (
        1,2
    )
)

select count(*) as validation_errors
from validation_errors



2021-09-22 12:05:07.855366 (Thread-1): finished collecting timing info
2021-09-22 12:05:07.855883 (Thread-1): 17:35:07 | 1 of 5 FAIL 1 accepted_values_my_first_dbt_model_id__False__1__2..... [FAIL 1 in 3.31s]
2021-09-22 12:05:07.856026 (Thread-1): Finished running node test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__2
2021-09-22 12:05:07.856162 (Thread-1): Began running node test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 12:05:07.856340 (Thread-1): 17:35:07 | 2 of 5 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-09-22 12:05:07.856908 (Thread-1): Acquiring new bigquery connection "test.dbt_project.not_null_my_first_dbt_model_id".
2021-09-22 12:05:07.857026 (Thread-1): Compiling test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 12:05:07.865018 (Thread-1): Writing injected SQL for node "test.dbt_project.not_null_my_first_dbt_model_id"
2021-09-22 12:05:07.865496 (Thread-1): finished collecting timing info
2021-09-22 12:05:07.865760 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:05:07.871285 (Thread-1): On test.dbt_project.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
where id is null



2021-09-22 12:05:10.374541 (Thread-1): finished collecting timing info
2021-09-22 12:05:10.375342 (Thread-1): 17:35:10 | 2 of 5 PASS not_null_my_first_dbt_model_id........................... [PASS in 2.52s]
2021-09-22 12:05:10.375572 (Thread-1): Finished running node test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 12:05:10.375797 (Thread-1): Began running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 12:05:10.376006 (Thread-1): 17:35:10 | 3 of 5 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-09-22 12:05:10.376619 (Thread-1): Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id".
2021-09-22 12:05:10.376790 (Thread-1): Compiling test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 12:05:10.381146 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61298), raddr=('142.250.196.170', 443)>
2021-09-22 12:05:10.381385 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61299), raddr=('142.250.182.106', 443)>
2021-09-22 12:05:10.387659 (Thread-1): Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id"
2021-09-22 12:05:10.388136 (Thread-1): finished collecting timing info
2021-09-22 12:05:10.388434 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:05:10.394807 (Thread-1): On test.dbt_project.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_second_dbt_model`
where id is null



2021-09-22 12:05:12.825558 (Thread-1): finished collecting timing info
2021-09-22 12:05:12.826400 (Thread-1): 17:35:12 | 3 of 5 PASS not_null_my_second_dbt_model_id.......................... [PASS in 2.45s]
2021-09-22 12:05:12.826553 (Thread-1): Finished running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 12:05:12.826691 (Thread-1): Began running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 12:05:12.826972 (Thread-1): 17:35:12 | 4 of 5 START test unique_my_first_dbt_model_id....................... [RUN]
2021-09-22 12:05:12.827390 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id".
2021-09-22 12:05:12.827515 (Thread-1): Compiling test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 12:05:12.836623 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id"
2021-09-22 12:05:12.837831 (Thread-1): finished collecting timing info
2021-09-22 12:05:12.838253 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:05:12.844300 (Thread-1): On test.dbt_project.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_first_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 12:05:16.763818 (Thread-1): finished collecting timing info
2021-09-22 12:05:16.764601 (Thread-1): 17:35:16 | 4 of 5 PASS unique_my_first_dbt_model_id............................. [PASS in 3.94s]
2021-09-22 12:05:16.764969 (Thread-1): Finished running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 12:05:16.765492 (Thread-1): Began running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 12:05:16.765941 (Thread-1): 17:35:16 | 5 of 5 START test unique_my_second_dbt_model_id...................... [RUN]
2021-09-22 12:05:16.766324 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id".
2021-09-22 12:05:16.766469 (Thread-1): Compiling test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 12:05:16.769303 (Thread-1): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61303), raddr=('142.250.196.170', 443)>
2021-09-22 12:05:16.769512 (Thread-1): unclosed <socket.socket fd=23, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61304), raddr=('142.250.182.106', 443)>
2021-09-22 12:05:16.776688 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id"
2021-09-22 12:05:16.777206 (Thread-1): finished collecting timing info
2021-09-22 12:05:16.777519 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:05:16.784009 (Thread-1): On test.dbt_project.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_second_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 12:05:19.477614 (Thread-1): finished collecting timing info
2021-09-22 12:05:19.478443 (Thread-1): 17:35:19 | 5 of 5 PASS unique_my_second_dbt_model_id............................ [PASS in 2.71s]
2021-09-22 12:05:19.478678 (Thread-1): Finished running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 12:05:19.480121 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:05:19.480487 (MainThread): 17:35:19 | 
2021-09-22 12:05:19.480652 (MainThread): 17:35:19 | Finished running 5 tests in 15.94s.
2021-09-22 12:05:19.480791 (MainThread): Connection 'master' was properly closed.
2021-09-22 12:05:19.480896 (MainThread): Connection 'test.dbt_project.unique_my_second_dbt_model_id' was properly closed.
2021-09-22 12:05:19.506437 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61294), raddr=('142.250.196.170', 443)>
2021-09-22 12:05:19.506699 (MainThread): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61295), raddr=('142.250.182.106', 443)>
2021-09-22 12:05:19.506856 (MainThread): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61297), raddr=('142.250.182.106', 443)>
2021-09-22 12:05:19.507010 (MainThread): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61296), raddr=('142.250.196.170', 443)>
2021-09-22 12:05:19.510473 (MainThread): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61300), raddr=('142.250.196.170', 443)>
2021-09-22 12:05:19.510651 (MainThread): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61301), raddr=('142.250.182.106', 443)>
2021-09-22 12:05:19.514052 (MainThread): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61305), raddr=('142.250.196.170', 443)>
2021-09-22 12:05:19.514242 (MainThread): unclosed <socket.socket fd=23, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61306), raddr=('142.250.182.106', 443)>
2021-09-22 12:05:19.537219 (MainThread): 
2021-09-22 12:05:19.537386 (MainThread): Completed with 1 error and 0 warnings:
2021-09-22 12:05:19.537504 (MainThread): 
2021-09-22 12:05:19.537637 (MainThread): Failure in test accepted_values_my_first_dbt_model_id__False__1__2 (models/example/schema.yml)
2021-09-22 12:05:19.537743 (MainThread):   Got 1 result, expected 0.
2021-09-22 12:05:19.537844 (MainThread): 
2021-09-22 12:05:19.537947 (MainThread):   compiled SQL at target/compiled/dbt_project/models/example/schema.yml/schema_test/accepted_values_my_first_dbt_model_id__False__1__2.sql
2021-09-22 12:05:19.538061 (MainThread): 
Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
2021-09-22 12:05:19.538225 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11115e8b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111525d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11152a340>]}
2021-09-22 12:05:19.538421 (MainThread): Flushing usage events
2021-09-22 12:08:54.471399 (MainThread): Running with dbt=0.19.0
2021-09-22 12:08:54.702445 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 12:08:54.703622 (MainThread): Tracking: tracking
2021-09-22 12:08:54.713298 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11285dbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11286f730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11286f6d0>]}
2021-09-22 12:08:54.738222 (MainThread): Partial parsing not enabled
2021-09-22 12:08:54.739385 (MainThread): Parsing macros/etc.sql
2021-09-22 12:08:54.742904 (MainThread): Parsing macros/catalog.sql
2021-09-22 12:08:54.750314 (MainThread): Parsing macros/adapters.sql
2021-09-22 12:08:54.770989 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 12:08:54.773948 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 12:08:54.776758 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 12:08:54.786939 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 12:08:54.791273 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 12:08:54.804090 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 12:08:54.806883 (MainThread): Parsing macros/core.sql
2021-09-22 12:08:54.810813 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 12:08:54.819794 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 12:08:54.821541 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 12:08:54.867885 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 12:08:54.910943 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 12:08:54.935826 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 12:08:54.938040 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 12:08:54.944700 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 12:08:54.958519 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 12:08:54.966588 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 12:08:54.974068 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 12:08:54.979517 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 12:08:54.980509 (MainThread): Parsing macros/etc/query.sql
2021-09-22 12:08:54.981593 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 12:08:54.983166 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 12:08:54.991991 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 12:08:54.993911 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 12:08:54.995560 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 12:08:55.039116 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 12:08:55.041059 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 12:08:55.042893 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 12:08:55.045178 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 12:08:55.053564 (MainThread): Partial parsing not enabled
2021-09-22 12:08:55.095110 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:08:55.117524 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:08:55.129064 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1128d6d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a3aa00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a3a910>]}
2021-09-22 12:08:55.129328 (MainThread): Flushing usage events
2021-09-22 12:08:56.276084 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 12:08:56.276279 (MainThread): Encountered an error:
2021-09-22 12:08:56.276430 (MainThread): Compilation Error
  Error reading dbt_project: example/schema.yml - Runtime Error
    Syntax error near line 26
    ------------------------------
    23 |                 - unique
    24 |                 - not_null
    25 |                 - relationships
    26 |                   to: ref('my_first_dbt_model')
    27 |                   field: id
    
    Raw Error:
    ------------------------------
    mapping values are not allowed in this context
      in "<unicode string>", line 26, column 21
2021-09-22 12:08:56.362875 (MainThread): Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/clients/yaml_helper.py", line 62, in load_yaml_text
    return safe_load(contents)
  File "/Library/Python/3.8/site-packages/dbt/clients/yaml_helper.py", line 57, in safe_load
    return yaml.load(contents, Loader=YamlLoader)
  File "/Library/Python/3.8/site-packages/yaml/__init__.py", line 114, in load
    return loader.get_single_data()
  File "/Library/Python/3.8/site-packages/yaml/constructor.py", line 49, in get_single_data
    node = self.get_single_node()
  File "yaml/_yaml.pyx", line 707, in yaml._yaml.CParser.get_single_node
  File "yaml/_yaml.pyx", line 725, in yaml._yaml.CParser._compose_document
  File "yaml/_yaml.pyx", line 776, in yaml._yaml.CParser._compose_node
  File "yaml/_yaml.pyx", line 890, in yaml._yaml.CParser._compose_mapping_node
  File "yaml/_yaml.pyx", line 774, in yaml._yaml.CParser._compose_node
  File "yaml/_yaml.pyx", line 851, in yaml._yaml.CParser._compose_sequence_node
  File "yaml/_yaml.pyx", line 776, in yaml._yaml.CParser._compose_node
  File "yaml/_yaml.pyx", line 890, in yaml._yaml.CParser._compose_mapping_node
  File "yaml/_yaml.pyx", line 774, in yaml._yaml.CParser._compose_node
  File "yaml/_yaml.pyx", line 851, in yaml._yaml.CParser._compose_sequence_node
  File "yaml/_yaml.pyx", line 776, in yaml._yaml.CParser._compose_node
  File "yaml/_yaml.pyx", line 890, in yaml._yaml.CParser._compose_mapping_node
  File "yaml/_yaml.pyx", line 774, in yaml._yaml.CParser._compose_node
  File "yaml/_yaml.pyx", line 853, in yaml._yaml.CParser._compose_sequence_node
  File "yaml/_yaml.pyx", line 905, in yaml._yaml.CParser._parse_next_event
yaml.scanner.ScannerError: mapping values are not allowed in this context
  in "<unicode string>", line 26, column 21

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/parser/schemas.py", line 233, in _yaml_from_file
    return load_yaml_text(source_file.contents)
  File "/Library/Python/3.8/site-packages/dbt/clients/yaml_helper.py", line 69, in load_yaml_text
    raise dbt.exceptions.ValidationException(error)
dbt.exceptions.ValidationException: Runtime Error
  Syntax error near line 26
  ------------------------------
  23 |                 - unique
  24 |                 - not_null
  25 |                 - relationships
  26 |                   to: ref('my_first_dbt_model')
  27 |                   field: id
  
  Raw Error:
  ------------------------------
  mapping values are not allowed in this context
    in "<unicode string>", line 26, column 21

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Python/3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/Library/Python/3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/Library/Python/3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 406, in run
    self._runtime_initialize()
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 122, in _runtime_initialize
    super()._runtime_initialize()
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 79, in _runtime_initialize
    self.load_manifest()
  File "/Library/Python/3.8/site-packages/dbt/task/runnable.py", line 66, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/Library/Python/3.8/site-packages/dbt/perf_utils.py", line 28, in get_full_manifest
    return load_manifest(
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 854, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 434, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 282, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 232, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/Library/Python/3.8/site-packages/dbt/parser/manifest.py", line 183, in parse_with_cache
    parser.parse_file(block)
  File "/Library/Python/3.8/site-packages/dbt/parser/schemas.py", line 563, in parse_file
    dct = self._yaml_from_file(block.file)
  File "/Library/Python/3.8/site-packages/dbt/parser/schemas.py", line 236, in _yaml_from_file
    raise CompilationException(
dbt.exceptions.CompilationException: Compilation Error
  Error reading dbt_project: example/schema.yml - Runtime Error
    Syntax error near line 26
    ------------------------------
    23 |                 - unique
    24 |                 - not_null
    25 |                 - relationships
    26 |                   to: ref('my_first_dbt_model')
    27 |                   field: id
    
    Raw Error:
    ------------------------------
    mapping values are not allowed in this context
      in "<unicode string>", line 26, column 21

2021-09-22 12:09:20.160096 (MainThread): Running with dbt=0.19.0
2021-09-22 12:09:20.375512 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 12:09:20.376244 (MainThread): Tracking: tracking
2021-09-22 12:09:20.384739 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109247ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109259760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109259700>]}
2021-09-22 12:09:20.409913 (MainThread): Partial parsing not enabled
2021-09-22 12:09:20.411161 (MainThread): Parsing macros/etc.sql
2021-09-22 12:09:20.414449 (MainThread): Parsing macros/catalog.sql
2021-09-22 12:09:20.421908 (MainThread): Parsing macros/adapters.sql
2021-09-22 12:09:20.442439 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 12:09:20.445206 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 12:09:20.448224 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 12:09:20.458583 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 12:09:20.462985 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 12:09:20.476460 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 12:09:20.479422 (MainThread): Parsing macros/core.sql
2021-09-22 12:09:20.483946 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 12:09:20.492921 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 12:09:20.494693 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 12:09:20.543583 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 12:09:20.587435 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 12:09:20.612814 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 12:09:20.615110 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 12:09:20.622922 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 12:09:20.639888 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 12:09:20.647888 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 12:09:20.655289 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 12:09:20.660576 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 12:09:20.661523 (MainThread): Parsing macros/etc/query.sql
2021-09-22 12:09:20.662560 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 12:09:20.664205 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 12:09:20.673490 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 12:09:20.675478 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 12:09:20.677140 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 12:09:20.721016 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 12:09:20.723059 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 12:09:20.724852 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 12:09:20.727948 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 12:09:20.741846 (MainThread): Partial parsing not enabled
2021-09-22 12:09:20.808620 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:09:20.841433 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:09:21.087760 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '76cc9360-17a6-4b1f-9197-2b55ea8785db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109443eb0>]}
2021-09-22 12:09:21.128152 (MainThread): Found 2 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 12:09:21.128891 (MainThread): 
2021-09-22 12:09:21.129165 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:09:21.131610 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 12:09:21.131743 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 12:09:22.812702 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 12:09:22.813569 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 12:09:22.820108 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:09:24.290091 (MainThread): 17:39:24 | Concurrency: 1 threads (target='dev')
2021-09-22 12:09:24.290322 (MainThread): 17:39:24 | 
2021-09-22 12:09:24.293400 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 12:09:24.294640 (Thread-1): 17:39:24 | 1 of 2 START table model test.my_first_dbt_model..................... [RUN]
2021-09-22 12:09:24.294954 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:09:24.295091 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 12:09:24.318638 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 12:09:24.319182 (Thread-1): finished collecting timing info
2021-09-22 12:09:24.343936 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:09:24.349779 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:09:25.863882 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 12:09:25.864418 (Thread-1): On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */


  create or replace table `unique-arbor-326717`.`test`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

 

-- , alias='first_model', schema='dbt_test'  , database='ivory-mountain-326811'


with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id



)

select * 
-- , True as first_variable
from source_data
where id is not null
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-09-22 12:09:29.634302 (Thread-1): finished collecting timing info
2021-09-22 12:09:29.635199 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '76cc9360-17a6-4b1f-9197-2b55ea8785db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094589d0>]}
2021-09-22 12:09:29.636524 (Thread-1): 17:39:29 | 1 of 2 OK created table model test.my_first_dbt_model................ [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 5.34s]
2021-09-22 12:09:29.636681 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 12:09:29.637305 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 12:09:29.638496 (Thread-1): 17:39:29 | 2 of 2 START view model test.my_second_dbt_model..................... [RUN]
2021-09-22 12:09:29.638805 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:09:29.638925 (Thread-1): Compiling model.dbt_project.my_second_dbt_model
2021-09-22 12:09:29.647742 (Thread-1): Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 12:09:29.648223 (Thread-1): finished collecting timing info
2021-09-22 12:09:29.670866 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 12:09:29.671398 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:09:29.677525 (Thread-1): On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
-- where id = 1;


2021-09-22 12:09:29.762395 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61338), raddr=('142.250.195.170', 443)>
2021-09-22 12:09:29.762661 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61339), raddr=('142.250.182.106', 443)>
2021-09-22 12:09:29.762839 (Thread-1): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61341), raddr=('142.250.182.106', 443)>
2021-09-22 12:09:29.763154 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61340), raddr=('142.250.195.170', 443)>
2021-09-22 12:09:29.763388 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61343), raddr=('142.250.182.106', 443)>
2021-09-22 12:09:29.763624 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61342), raddr=('142.250.195.170', 443)>
2021-09-22 12:09:32.608132 (Thread-1): finished collecting timing info
2021-09-22 12:09:32.609111 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '76cc9360-17a6-4b1f-9197-2b55ea8785db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094912e0>]}
2021-09-22 12:09:32.610335 (Thread-1): 17:39:32 | 2 of 2 OK created view model test.my_second_dbt_model................ [OK in 2.97s]
2021-09-22 12:09:32.610482 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 12:09:32.611450 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:09:32.611758 (MainThread): 17:39:32 | 
2021-09-22 12:09:32.611895 (MainThread): 17:39:32 | Finished running 1 table model, 1 view model in 11.48s.
2021-09-22 12:09:32.612010 (MainThread): Connection 'master' was properly closed.
2021-09-22 12:09:32.612096 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 12:09:32.657233 (MainThread): 
2021-09-22 12:09:32.657403 (MainThread): Completed successfully
2021-09-22 12:09:32.657524 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-09-22 12:09:32.657686 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10948bca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10944ca00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094634f0>]}
2021-09-22 12:09:32.657875 (MainThread): Flushing usage events
2021-09-22 12:09:42.483982 (MainThread): Running with dbt=0.19.0
2021-09-22 12:09:42.741294 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-09-22 12:09:42.742656 (MainThread): Tracking: tracking
2021-09-22 12:09:42.753954 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110103dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101156a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110115640>]}
2021-09-22 12:09:42.779570 (MainThread): Partial parsing not enabled
2021-09-22 12:09:42.781312 (MainThread): Parsing macros/etc.sql
2021-09-22 12:09:42.785614 (MainThread): Parsing macros/catalog.sql
2021-09-22 12:09:42.793576 (MainThread): Parsing macros/adapters.sql
2021-09-22 12:09:42.815928 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 12:09:42.819596 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 12:09:42.823122 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 12:09:42.834362 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 12:09:42.839125 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 12:09:42.852284 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 12:09:42.855695 (MainThread): Parsing macros/core.sql
2021-09-22 12:09:42.860017 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 12:09:42.869086 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 12:09:42.871242 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 12:09:42.919731 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 12:09:42.964409 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 12:09:42.990316 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 12:09:42.992692 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 12:09:43.002375 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 12:09:43.019457 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 12:09:43.027387 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 12:09:43.034528 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 12:09:43.039638 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 12:09:43.040790 (MainThread): Parsing macros/etc/query.sql
2021-09-22 12:09:43.042112 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 12:09:43.044322 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 12:09:43.054875 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 12:09:43.057309 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 12:09:43.059833 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 12:09:43.104966 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 12:09:43.107084 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 12:09:43.108768 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 12:09:43.110686 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 12:09:43.118726 (MainThread): Partial parsing not enabled
2021-09-22 12:09:43.158336 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:09:43.180043 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:09:43.410885 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e61abafb-859f-4d22-b574-f1525d4c6c1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110303f70>]}
2021-09-22 12:09:43.449286 (MainThread): Found 2 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 12:09:43.450759 (MainThread): 
2021-09-22 12:09:43.451272 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:09:43.460244 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 12:09:43.460357 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-09-22 12:09:43.466479 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:09:44.410471 (MainThread): 17:39:44 | Concurrency: 1 threads (target='dev')
2021-09-22 12:09:44.410693 (MainThread): 17:39:44 | 
2021-09-22 12:09:44.413544 (Thread-1): Began running node test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3
2021-09-22 12:09:44.413761 (Thread-1): 17:39:44 | 1 of 6 START test accepted_values_my_first_dbt_model_id__False__1__3. [RUN]
2021-09-22 12:09:44.414098 (Thread-1): Acquiring new bigquery connection "test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3".
2021-09-22 12:09:44.414241 (Thread-1): Compiling test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3
2021-09-22 12:09:44.437536 (Thread-1): Writing injected SQL for node "test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3"
2021-09-22 12:09:44.438092 (Thread-1): finished collecting timing info
2021-09-22 12:09:44.438405 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:09:44.444705 (Thread-1): On test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3"} */

    
    




with all_values as (

    select distinct
        id as value_field

    from `unique-arbor-326717`.`test`.`my_first_dbt_model`

),

validation_errors as (

    select
        value_field

    from all_values
    where value_field not in (
        1,3
    )
)

select count(*) as validation_errors
from validation_errors



2021-09-22 12:09:48.911061 (Thread-1): finished collecting timing info
2021-09-22 12:09:48.911932 (Thread-1): 17:39:48 | 1 of 6 PASS accepted_values_my_first_dbt_model_id__False__1__3....... [PASS in 4.50s]
2021-09-22 12:09:48.912178 (Thread-1): Finished running node test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3
2021-09-22 12:09:48.912410 (Thread-1): Began running node test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 12:09:48.912633 (Thread-1): 17:39:48 | 2 of 6 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-09-22 12:09:48.913494 (Thread-1): Acquiring new bigquery connection "test.dbt_project.not_null_my_first_dbt_model_id".
2021-09-22 12:09:48.913655 (Thread-1): Compiling test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 12:09:48.923654 (Thread-1): Writing injected SQL for node "test.dbt_project.not_null_my_first_dbt_model_id"
2021-09-22 12:09:48.924175 (Thread-1): finished collecting timing info
2021-09-22 12:09:48.924475 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:09:48.930761 (Thread-1): On test.dbt_project.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
where id is null



2021-09-22 12:09:53.023683 (Thread-1): finished collecting timing info
2021-09-22 12:09:53.024410 (Thread-1): 17:39:53 | 2 of 6 PASS not_null_my_first_dbt_model_id........................... [PASS in 4.11s]
2021-09-22 12:09:53.024594 (Thread-1): Finished running node test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 12:09:53.024773 (Thread-1): Began running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 12:09:53.024937 (Thread-1): 17:39:53 | 3 of 6 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-09-22 12:09:53.025336 (Thread-1): Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id".
2021-09-22 12:09:53.025612 (Thread-1): Compiling test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 12:09:53.029425 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61352), raddr=('142.250.195.170', 443)>
2021-09-22 12:09:53.029617 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61353), raddr=('142.250.182.106', 443)>
2021-09-22 12:09:53.035784 (Thread-1): Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id"
2021-09-22 12:09:53.036267 (Thread-1): finished collecting timing info
2021-09-22 12:09:53.036572 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:09:53.043025 (Thread-1): On test.dbt_project.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_second_dbt_model`
where id is null



2021-09-22 12:09:57.307362 (Thread-1): finished collecting timing info
2021-09-22 12:09:57.308169 (Thread-1): 17:39:57 | 3 of 6 PASS not_null_my_second_dbt_model_id.......................... [PASS in 4.28s]
2021-09-22 12:09:57.308405 (Thread-1): Finished running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 12:09:57.308629 (Thread-1): Began running node test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_
2021-09-22 12:09:57.308961 (Thread-1): 17:39:57 | 4 of 6 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
2021-09-22 12:09:57.309329 (Thread-1): Acquiring new bigquery connection "test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_".
2021-09-22 12:09:57.309473 (Thread-1): Compiling test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_
2021-09-22 12:09:57.321752 (Thread-1): Writing injected SQL for node "test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_"
2021-09-22 12:09:57.322276 (Thread-1): finished collecting timing info
2021-09-22 12:09:57.322581 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:09:57.328769 (Thread-1): On test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_"} */

    
    




select count(*) as validation_errors
from (
    select id as id from `unique-arbor-326717`.`test`.`my_second_dbt_model`
) as child
left join (
    select id as id from `unique-arbor-326717`.`test`.`my_first_dbt_model`
) as parent on parent.id = child.id
where child.id is not null
  and parent.id is null



2021-09-22 12:10:01.160676 (Thread-1): finished collecting timing info
2021-09-22 12:10:01.161473 (Thread-1): 17:40:01 | 4 of 6 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [PASS in 3.85s]
2021-09-22 12:10:01.161656 (Thread-1): Finished running node test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_
2021-09-22 12:10:01.161838 (Thread-1): Began running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 12:10:01.162015 (Thread-1): 17:40:01 | 5 of 6 START test unique_my_first_dbt_model_id....................... [RUN]
2021-09-22 12:10:01.162616 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id".
2021-09-22 12:10:01.162788 (Thread-1): Compiling test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 12:10:01.169827 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61348), raddr=('142.250.195.170', 443)>
2021-09-22 12:10:01.170043 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61349), raddr=('142.250.182.106', 443)>
2021-09-22 12:10:01.170205 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61351), raddr=('142.250.182.106', 443)>
2021-09-22 12:10:01.170362 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61350), raddr=('142.250.195.170', 443)>
2021-09-22 12:10:01.173822 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61354), raddr=('142.250.195.170', 443)>
2021-09-22 12:10:01.173973 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61355), raddr=('142.250.182.106', 443)>
2021-09-22 12:10:01.174116 (Thread-1): unclosed <socket.socket fd=23, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61357), raddr=('142.250.182.106', 443)>
2021-09-22 12:10:01.174269 (Thread-1): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61356), raddr=('142.250.195.170', 443)>
2021-09-22 12:10:01.178058 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id"
2021-09-22 12:10:01.178561 (Thread-1): finished collecting timing info
2021-09-22 12:10:01.178873 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:10:01.185590 (Thread-1): On test.dbt_project.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_first_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 12:10:06.308465 (Thread-1): finished collecting timing info
2021-09-22 12:10:06.309121 (Thread-1): 17:40:06 | 5 of 6 PASS unique_my_first_dbt_model_id............................. [PASS in 5.15s]
2021-09-22 12:10:06.309307 (Thread-1): Finished running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 12:10:06.309490 (Thread-1): Began running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 12:10:06.309802 (Thread-1): 17:40:06 | 6 of 6 START test unique_my_second_dbt_model_id...................... [RUN]
2021-09-22 12:10:06.310210 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id".
2021-09-22 12:10:06.310372 (Thread-1): Compiling test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 12:10:06.312631 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61358), raddr=('142.250.195.170', 443)>
2021-09-22 12:10:06.312806 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61359), raddr=('142.250.182.106', 443)>
2021-09-22 12:10:06.320424 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id"
2021-09-22 12:10:06.320957 (Thread-1): finished collecting timing info
2021-09-22 12:10:06.321251 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:10:06.327480 (Thread-1): On test.dbt_project.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_second_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 12:10:10.620263 (Thread-1): finished collecting timing info
2021-09-22 12:10:10.620923 (Thread-1): 17:40:10 | 6 of 6 PASS unique_my_second_dbt_model_id............................ [PASS in 4.31s]
2021-09-22 12:10:10.621111 (Thread-1): Finished running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 12:10:10.622254 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:10:10.622610 (MainThread): 17:40:10 | 
2021-09-22 12:10:10.622769 (MainThread): 17:40:10 | Finished running 6 tests in 27.17s.
2021-09-22 12:10:10.622904 (MainThread): Connection 'master' was properly closed.
2021-09-22 12:10:10.623005 (MainThread): Connection 'test.dbt_project.unique_my_second_dbt_model_id' was properly closed.
2021-09-22 12:10:10.647690 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61360), raddr=('142.250.195.170', 443)>
2021-09-22 12:10:10.647948 (MainThread): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61361), raddr=('142.250.182.106', 443)>
2021-09-22 12:10:10.671062 (MainThread): 
2021-09-22 12:10:10.671225 (MainThread): Completed successfully
2021-09-22 12:10:10.671350 (MainThread): 
Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
2021-09-22 12:10:10.671512 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105ba0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103deac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103dec70>]}
2021-09-22 12:10:10.671704 (MainThread): Flushing usage events
2021-09-22 12:10:34.431060 (MainThread): Running with dbt=0.19.0
2021-09-22 12:10:34.674115 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 12:10:34.674747 (MainThread): Tracking: tracking
2021-09-22 12:10:34.685102 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a336ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a347790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a347730>]}
2021-09-22 12:10:34.709916 (MainThread): Partial parsing not enabled
2021-09-22 12:10:34.711490 (MainThread): Parsing macros/etc.sql
2021-09-22 12:10:34.715471 (MainThread): Parsing macros/catalog.sql
2021-09-22 12:10:34.723675 (MainThread): Parsing macros/adapters.sql
2021-09-22 12:10:34.746052 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 12:10:34.749471 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 12:10:34.752686 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 12:10:34.763761 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 12:10:34.769502 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 12:10:34.784110 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 12:10:34.787826 (MainThread): Parsing macros/core.sql
2021-09-22 12:10:34.792545 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 12:10:34.803106 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 12:10:34.805569 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 12:10:34.855453 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 12:10:34.897977 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 12:10:34.922520 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 12:10:34.924768 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 12:10:34.932307 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 12:10:34.948275 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 12:10:34.956478 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 12:10:34.963809 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 12:10:34.969896 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 12:10:34.971104 (MainThread): Parsing macros/etc/query.sql
2021-09-22 12:10:34.972334 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 12:10:34.974203 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 12:10:34.983870 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 12:10:34.986515 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 12:10:34.988642 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 12:10:35.034196 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 12:10:35.036390 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 12:10:35.038100 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 12:10:35.040066 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 12:10:35.048847 (MainThread): Partial parsing not enabled
2021-09-22 12:10:35.092836 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:10:35.113884 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:10:35.372262 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5e18d998-50c0-414f-8151-e2a924c5efd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a682e20>]}
2021-09-22 12:10:35.416885 (MainThread): Found 2 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 12:10:35.417963 (MainThread): 
2021-09-22 12:10:35.418342 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:10:35.421099 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 12:10:35.421246 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 12:10:36.949532 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 12:10:36.949777 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 12:10:36.956419 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:10:38.476624 (MainThread): 17:40:38 | Concurrency: 1 threads (target='dev')
2021-09-22 12:10:38.476828 (MainThread): 17:40:38 | 
2021-09-22 12:10:38.479714 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 12:10:38.480948 (Thread-1): 17:40:38 | 1 of 2 START table model test.my_first_dbt_model..................... [RUN]
2021-09-22 12:10:38.481258 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:10:38.481396 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 12:10:38.506739 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 12:10:38.507265 (Thread-1): finished collecting timing info
2021-09-22 12:10:38.532809 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:10:38.539067 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:10:40.137588 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 12:10:40.138143 (Thread-1): On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */


  create or replace table `unique-arbor-326717`.`test`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

 

-- , alias='first_model', schema='dbt_test'  , database='ivory-mountain-326811'


with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id



)

select * 
-- , True as first_variable
from source_data
where id is not null
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-09-22 12:10:43.396950 (Thread-1): finished collecting timing info
2021-09-22 12:10:43.397719 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e18d998-50c0-414f-8151-e2a924c5efd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a698190>]}
2021-09-22 12:10:43.398970 (Thread-1): 17:40:43 | 1 of 2 OK created table model test.my_first_dbt_model................ [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 4.92s]
2021-09-22 12:10:43.399129 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 12:10:43.399878 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 12:10:43.401280 (Thread-1): 17:40:43 | 2 of 2 START view model test.my_second_dbt_model..................... [RUN]
2021-09-22 12:10:43.401650 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:10:43.401787 (Thread-1): Compiling model.dbt_project.my_second_dbt_model
2021-09-22 12:10:43.410614 (Thread-1): Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 12:10:43.411060 (Thread-1): finished collecting timing info
2021-09-22 12:10:43.434257 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 12:10:43.434808 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:10:43.441016 (Thread-1): On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
-- where id = 1
union all
select 7 as id;


2021-09-22 12:10:43.530718 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61367), raddr=('142.250.195.170', 443)>
2021-09-22 12:10:43.530982 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61368), raddr=('142.250.182.106', 443)>
2021-09-22 12:10:43.531180 (Thread-1): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61370), raddr=('142.250.182.106', 443)>
2021-09-22 12:10:43.531348 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61369), raddr=('142.250.195.170', 443)>
2021-09-22 12:10:43.531522 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61372), raddr=('142.250.182.106', 443)>
2021-09-22 12:10:43.531700 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61371), raddr=('142.250.195.170', 443)>
2021-09-22 12:10:45.442497 (Thread-1): finished collecting timing info
2021-09-22 12:10:45.443501 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e18d998-50c0-414f-8151-e2a924c5efd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a578cd0>]}
2021-09-22 12:10:45.444727 (Thread-1): 17:40:45 | 2 of 2 OK created view model test.my_second_dbt_model................ [OK in 2.04s]
2021-09-22 12:10:45.444882 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 12:10:45.445989 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:10:45.446294 (MainThread): 17:40:45 | 
2021-09-22 12:10:45.446429 (MainThread): 17:40:45 | Finished running 1 table model, 1 view model in 10.03s.
2021-09-22 12:10:45.446543 (MainThread): Connection 'master' was properly closed.
2021-09-22 12:10:45.446629 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 12:10:45.491712 (MainThread): 
2021-09-22 12:10:45.491874 (MainThread): Completed successfully
2021-09-22 12:10:45.491989 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-09-22 12:10:45.492148 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a293b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a55c130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a578cd0>]}
2021-09-22 12:10:45.492335 (MainThread): Flushing usage events
2021-09-22 12:11:09.421503 (MainThread): Running with dbt=0.19.0
2021-09-22 12:11:09.633523 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-09-22 12:11:09.634493 (MainThread): Tracking: tracking
2021-09-22 12:11:09.642351 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f65ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f77790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f77730>]}
2021-09-22 12:11:09.663440 (MainThread): Partial parsing not enabled
2021-09-22 12:11:09.664437 (MainThread): Parsing macros/etc.sql
2021-09-22 12:11:09.667422 (MainThread): Parsing macros/catalog.sql
2021-09-22 12:11:09.673434 (MainThread): Parsing macros/adapters.sql
2021-09-22 12:11:09.691878 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 12:11:09.694821 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 12:11:09.697502 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 12:11:09.707227 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 12:11:09.711674 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 12:11:09.724688 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 12:11:09.727463 (MainThread): Parsing macros/core.sql
2021-09-22 12:11:09.731147 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 12:11:09.740767 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 12:11:09.742525 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 12:11:09.788338 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 12:11:09.828745 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 12:11:09.850415 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 12:11:09.852262 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 12:11:09.858425 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 12:11:09.872301 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 12:11:09.879188 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 12:11:09.885414 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 12:11:09.890223 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 12:11:09.891137 (MainThread): Parsing macros/etc/query.sql
2021-09-22 12:11:09.892151 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 12:11:09.893766 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 12:11:09.902459 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 12:11:09.904379 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 12:11:09.906020 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 12:11:09.947545 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 12:11:09.949334 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 12:11:09.950785 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 12:11:09.952407 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 12:11:09.959685 (MainThread): Partial parsing not enabled
2021-09-22 12:11:09.998037 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:11:10.018239 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:11:10.238402 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2b3dd920-8865-4769-ae20-86c0d01a4d2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11229e640>]}
2021-09-22 12:11:10.276881 (MainThread): Found 2 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 12:11:10.277648 (MainThread): 
2021-09-22 12:11:10.277912 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:11:10.286710 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 12:11:10.286888 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-09-22 12:11:10.291875 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:11:11.269410 (MainThread): 17:41:11 | Concurrency: 1 threads (target='dev')
2021-09-22 12:11:11.270087 (MainThread): 17:41:11 | 
2021-09-22 12:11:11.272576 (Thread-1): Began running node test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3
2021-09-22 12:11:11.272763 (Thread-1): 17:41:11 | 1 of 6 START test accepted_values_my_first_dbt_model_id__False__1__3. [RUN]
2021-09-22 12:11:11.273058 (Thread-1): Acquiring new bigquery connection "test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3".
2021-09-22 12:11:11.273192 (Thread-1): Compiling test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3
2021-09-22 12:11:11.295609 (Thread-1): Writing injected SQL for node "test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3"
2021-09-22 12:11:11.296143 (Thread-1): finished collecting timing info
2021-09-22 12:11:11.296446 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:11:11.302691 (Thread-1): On test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3"} */

    
    




with all_values as (

    select distinct
        id as value_field

    from `unique-arbor-326717`.`test`.`my_first_dbt_model`

),

validation_errors as (

    select
        value_field

    from all_values
    where value_field not in (
        1,3
    )
)

select count(*) as validation_errors
from validation_errors



2021-09-22 12:11:14.437871 (Thread-1): finished collecting timing info
2021-09-22 12:11:14.438555 (Thread-1): 17:41:14 | 1 of 6 PASS accepted_values_my_first_dbt_model_id__False__1__3....... [PASS in 3.17s]
2021-09-22 12:11:14.438746 (Thread-1): Finished running node test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3
2021-09-22 12:11:14.438929 (Thread-1): Began running node test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 12:11:14.439239 (Thread-1): 17:41:14 | 2 of 6 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-09-22 12:11:14.439916 (Thread-1): Acquiring new bigquery connection "test.dbt_project.not_null_my_first_dbt_model_id".
2021-09-22 12:11:14.440091 (Thread-1): Compiling test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 12:11:14.449509 (Thread-1): Writing injected SQL for node "test.dbt_project.not_null_my_first_dbt_model_id"
2021-09-22 12:11:14.450004 (Thread-1): finished collecting timing info
2021-09-22 12:11:14.450290 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:11:14.456678 (Thread-1): On test.dbt_project.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
where id is null



2021-09-22 12:11:16.977246 (Thread-1): finished collecting timing info
2021-09-22 12:11:16.978056 (Thread-1): 17:41:16 | 2 of 6 PASS not_null_my_first_dbt_model_id........................... [PASS in 2.54s]
2021-09-22 12:11:16.978316 (Thread-1): Finished running node test.dbt_project.not_null_my_first_dbt_model_id
2021-09-22 12:11:16.978573 (Thread-1): Began running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 12:11:16.978802 (Thread-1): 17:41:16 | 3 of 6 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-09-22 12:11:16.979327 (Thread-1): Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id".
2021-09-22 12:11:16.979482 (Thread-1): Compiling test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 12:11:16.983424 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61381), raddr=('142.250.182.106', 443)>
2021-09-22 12:11:16.983623 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61382), raddr=('142.250.182.106', 443)>
2021-09-22 12:11:16.990924 (Thread-1): Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id"
2021-09-22 12:11:16.991453 (Thread-1): finished collecting timing info
2021-09-22 12:11:16.991767 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:11:16.997991 (Thread-1): On test.dbt_project.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_second_dbt_model`
where id is null



2021-09-22 12:11:19.582065 (Thread-1): finished collecting timing info
2021-09-22 12:11:19.582883 (Thread-1): 17:41:19 | 3 of 6 PASS not_null_my_second_dbt_model_id.......................... [PASS in 2.60s]
2021-09-22 12:11:19.583115 (Thread-1): Finished running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 12:11:19.583390 (Thread-1): Began running node test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_
2021-09-22 12:11:19.583607 (Thread-1): 17:41:19 | 4 of 6 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
2021-09-22 12:11:19.584089 (Thread-1): Acquiring new bigquery connection "test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_".
2021-09-22 12:11:19.584424 (Thread-1): Compiling test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_
2021-09-22 12:11:19.596861 (Thread-1): Writing injected SQL for node "test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_"
2021-09-22 12:11:19.597446 (Thread-1): finished collecting timing info
2021-09-22 12:11:19.597752 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:11:19.604198 (Thread-1): On test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_"} */

    
    




select count(*) as validation_errors
from (
    select id as id from `unique-arbor-326717`.`test`.`my_second_dbt_model`
) as child
left join (
    select id as id from `unique-arbor-326717`.`test`.`my_first_dbt_model`
) as parent on parent.id = child.id
where child.id is not null
  and parent.id is null



2021-09-22 12:11:22.616782 (Thread-1): finished collecting timing info
2021-09-22 12:11:22.617707 (Thread-1): 17:41:22 | 4 of 6 FAIL 1 relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [FAIL 1 in 3.03s]
2021-09-22 12:11:22.617960 (Thread-1): Finished running node test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_
2021-09-22 12:11:22.618214 (Thread-1): Began running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 12:11:22.618633 (Thread-1): 17:41:22 | 5 of 6 START test unique_my_first_dbt_model_id....................... [RUN]
2021-09-22 12:11:22.619257 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id".
2021-09-22 12:11:22.619421 (Thread-1): Compiling test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 12:11:22.626210 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61377), raddr=('142.250.195.170', 443)>
2021-09-22 12:11:22.626408 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61378), raddr=('142.250.182.106', 443)>
2021-09-22 12:11:22.626583 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61380), raddr=('142.250.182.106', 443)>
2021-09-22 12:11:22.626745 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61379), raddr=('142.250.195.170', 443)>
2021-09-22 12:11:22.630233 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61383), raddr=('142.250.182.106', 443)>
2021-09-22 12:11:22.630387 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61384), raddr=('142.250.182.106', 443)>
2021-09-22 12:11:22.630531 (Thread-1): unclosed <socket.socket fd=23, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61386), raddr=('142.250.182.106', 443)>
2021-09-22 12:11:22.630685 (Thread-1): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61385), raddr=('142.250.182.106', 443)>
2021-09-22 12:11:22.634632 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id"
2021-09-22 12:11:22.635119 (Thread-1): finished collecting timing info
2021-09-22 12:11:22.635412 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:11:22.641928 (Thread-1): On test.dbt_project.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_first_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 12:11:25.478556 (Thread-1): finished collecting timing info
2021-09-22 12:11:25.479370 (Thread-1): 17:41:25 | 5 of 6 PASS unique_my_first_dbt_model_id............................. [PASS in 2.86s]
2021-09-22 12:11:25.479597 (Thread-1): Finished running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 12:11:25.479825 (Thread-1): Began running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 12:11:25.480044 (Thread-1): 17:41:25 | 6 of 6 START test unique_my_second_dbt_model_id...................... [RUN]
2021-09-22 12:11:25.480587 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id".
2021-09-22 12:11:25.480748 (Thread-1): Compiling test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 12:11:25.483279 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61388), raddr=('142.250.182.106', 443)>
2021-09-22 12:11:25.483491 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61389), raddr=('142.250.182.106', 443)>
2021-09-22 12:11:25.491166 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id"
2021-09-22 12:11:25.491694 (Thread-1): finished collecting timing info
2021-09-22 12:11:25.491997 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:11:25.498206 (Thread-1): On test.dbt_project.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_second_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 12:11:28.652015 (Thread-1): finished collecting timing info
2021-09-22 12:11:28.652866 (Thread-1): 17:41:28 | 6 of 6 PASS unique_my_second_dbt_model_id............................ [PASS in 3.17s]
2021-09-22 12:11:28.653106 (Thread-1): Finished running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 12:11:28.654692 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:11:28.655070 (MainThread): 17:41:28 | 
2021-09-22 12:11:28.655233 (MainThread): 17:41:28 | Finished running 6 tests in 18.38s.
2021-09-22 12:11:28.655367 (MainThread): Connection 'master' was properly closed.
2021-09-22 12:11:28.655467 (MainThread): Connection 'test.dbt_project.unique_my_second_dbt_model_id' was properly closed.
2021-09-22 12:11:28.680233 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61390), raddr=('142.250.182.106', 443)>
2021-09-22 12:11:28.680484 (MainThread): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61391), raddr=('142.250.182.106', 443)>
2021-09-22 12:11:28.703722 (MainThread): 
2021-09-22 12:11:28.703958 (MainThread): Completed with 1 error and 0 warnings:
2021-09-22 12:11:28.704076 (MainThread): 
2021-09-22 12:11:28.704189 (MainThread): Failure in test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ (models/example/schema.yml)
2021-09-22 12:11:28.704294 (MainThread):   Got 1 result, expected 0.
2021-09-22 12:11:28.704389 (MainThread): 
2021-09-22 12:11:28.704486 (MainThread):   compiled SQL at target/compiled/dbt_project/models/example/schema.yml/schema_test/relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.sql
2021-09-22 12:11:28.704595 (MainThread): 
Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
2021-09-22 12:11:28.704757 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1122c8d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112187e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120f9be0>]}
2021-09-22 12:11:28.704950 (MainThread): Flushing usage events
2021-09-22 12:20:33.462713 (MainThread): Running with dbt=0.19.0
2021-09-22 12:20:33.834096 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 12:20:33.835639 (MainThread): Tracking: tracking
2021-09-22 12:20:33.846092 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113316ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113328790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113328730>]}
2021-09-22 12:20:33.871928 (MainThread): Partial parsing not enabled
2021-09-22 12:20:33.873472 (MainThread): Parsing macros/etc.sql
2021-09-22 12:20:33.877427 (MainThread): Parsing macros/catalog.sql
2021-09-22 12:20:33.884691 (MainThread): Parsing macros/adapters.sql
2021-09-22 12:20:33.904691 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 12:20:33.908020 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 12:20:33.911038 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 12:20:33.921326 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 12:20:33.925918 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 12:20:33.939232 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 12:20:33.943207 (MainThread): Parsing macros/core.sql
2021-09-22 12:20:33.948145 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 12:20:33.958536 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 12:20:33.961081 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 12:20:34.008968 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 12:20:34.052594 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 12:20:34.079066 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 12:20:34.081577 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 12:20:34.089272 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 12:20:34.104393 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 12:20:34.111672 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 12:20:34.118332 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 12:20:34.124224 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 12:20:34.125464 (MainThread): Parsing macros/etc/query.sql
2021-09-22 12:20:34.126858 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 12:20:34.128866 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 12:20:34.138970 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 12:20:34.141136 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 12:20:34.143485 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 12:20:34.187755 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 12:20:34.190224 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 12:20:34.191857 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 12:20:34.193673 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 12:20:34.201232 (MainThread): Partial parsing not enabled
2021-09-22 12:20:34.241374 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:20:34.263781 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:20:34.285118 (MainThread): Acquiring new bigquery connection "test.dbt_project.assert_under_10_percent_null".
2021-09-22 12:20:34.495140 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '64842145-6d89-4278-86f1-29230de60e90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1135f9cd0>]}
2021-09-22 12:20:34.535216 (MainThread): Found 2 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 12:20:34.535941 (MainThread): 
2021-09-22 12:20:34.536240 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:20:34.538568 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 12:20:34.538699 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 12:20:36.203430 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 12:20:36.203673 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 12:20:36.210028 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:20:37.832241 (MainThread): 17:50:37 | Concurrency: 1 threads (target='dev')
2021-09-22 12:20:37.832444 (MainThread): 17:50:37 | 
2021-09-22 12:20:37.835549 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 12:20:37.836849 (Thread-1): 17:50:37 | 1 of 2 START table model test.my_first_dbt_model..................... [RUN]
2021-09-22 12:20:37.837196 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:20:37.837342 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 12:20:37.861200 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 12:20:37.861712 (Thread-1): finished collecting timing info
2021-09-22 12:20:37.887328 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:20:37.893166 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:20:39.388613 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 12:20:39.389153 (Thread-1): On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */


  create or replace table `unique-arbor-326717`.`test`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

 

-- , alias='first_model', schema='dbt_test'  , database='ivory-mountain-326811'


with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id



)

select * 
-- , True as first_variable
from source_data
-- where id is not null
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-09-22 12:20:43.162883 (Thread-1): finished collecting timing info
2021-09-22 12:20:43.163625 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64842145-6d89-4278-86f1-29230de60e90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132f4f10>]}
2021-09-22 12:20:43.164914 (Thread-1): 17:50:43 | 1 of 2 OK created table model test.my_first_dbt_model................ [CREATE TABLE (3.0 rows, 0.0 Bytes processed) in 5.33s]
2021-09-22 12:20:43.165075 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 12:20:43.165684 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 12:20:43.167072 (Thread-1): 17:50:43 | 2 of 2 START view model test.my_second_dbt_model..................... [RUN]
2021-09-22 12:20:43.167371 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:20:43.167494 (Thread-1): Compiling model.dbt_project.my_second_dbt_model
2021-09-22 12:20:43.176312 (Thread-1): Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 12:20:43.176751 (Thread-1): finished collecting timing info
2021-09-22 12:20:43.198924 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 12:20:43.199391 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:20:43.205347 (Thread-1): On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
-- where id = 1
-- union all
-- select 7 as id;


2021-09-22 12:20:43.293055 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61463), raddr=('142.250.77.138', 443)>
2021-09-22 12:20:43.293328 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61464), raddr=('142.250.182.106', 443)>
2021-09-22 12:20:43.293593 (Thread-1): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61466), raddr=('142.250.182.106', 443)>
2021-09-22 12:20:43.293773 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61465), raddr=('142.250.77.138', 443)>
2021-09-22 12:20:43.293956 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61468), raddr=('142.250.182.106', 443)>
2021-09-22 12:20:43.294135 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61467), raddr=('142.250.77.138', 443)>
2021-09-22 12:20:46.128174 (Thread-1): finished collecting timing info
2021-09-22 12:20:46.129146 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64842145-6d89-4278-86f1-29230de60e90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1135e70a0>]}
2021-09-22 12:20:46.130442 (Thread-1): 17:50:46 | 2 of 2 OK created view model test.my_second_dbt_model................ [OK in 2.96s]
2021-09-22 12:20:46.130606 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 12:20:46.131685 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:20:46.132007 (MainThread): 17:50:46 | 
2021-09-22 12:20:46.132145 (MainThread): 17:50:46 | Finished running 1 table model, 1 view model in 11.60s.
2021-09-22 12:20:46.132260 (MainThread): Connection 'master' was properly closed.
2021-09-22 12:20:46.132346 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 12:20:46.179112 (MainThread): 
2021-09-22 12:20:46.179281 (MainThread): Completed successfully
2021-09-22 12:20:46.179402 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-09-22 12:20:46.179619 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1135430d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113679af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113679490>]}
2021-09-22 12:20:46.179830 (MainThread): Flushing usage events
2021-09-22 12:21:27.821736 (MainThread): Running with dbt=0.19.0
2021-09-22 12:21:28.119660 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-09-22 12:21:28.122075 (MainThread): Tracking: tracking
2021-09-22 12:21:28.132906 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b374e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b386820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b3867c0>]}
2021-09-22 12:21:28.159211 (MainThread): Partial parsing not enabled
2021-09-22 12:21:28.160766 (MainThread): Parsing macros/etc.sql
2021-09-22 12:21:28.164430 (MainThread): Parsing macros/catalog.sql
2021-09-22 12:21:28.172306 (MainThread): Parsing macros/adapters.sql
2021-09-22 12:21:28.195774 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 12:21:28.199446 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 12:21:28.202944 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 12:21:28.215418 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 12:21:28.220830 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 12:21:28.234919 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 12:21:28.238563 (MainThread): Parsing macros/core.sql
2021-09-22 12:21:28.243138 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 12:21:28.252021 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 12:21:28.254227 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 12:21:28.301447 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 12:21:28.350245 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 12:21:28.376482 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 12:21:28.378920 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 12:21:28.386273 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 12:21:28.400281 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 12:21:28.408625 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 12:21:28.416648 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 12:21:28.422299 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 12:21:28.423437 (MainThread): Parsing macros/etc/query.sql
2021-09-22 12:21:28.424672 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 12:21:28.426443 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 12:21:28.435586 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 12:21:28.437935 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 12:21:28.440538 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 12:21:28.483827 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 12:21:28.485873 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 12:21:28.487548 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 12:21:28.489587 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 12:21:28.497150 (MainThread): Partial parsing not enabled
2021-09-22 12:21:28.536865 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:21:28.559445 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:21:28.581478 (MainThread): Acquiring new bigquery connection "test.dbt_project.assert_under_10_percent_null".
2021-09-22 12:21:28.793320 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ab4e2552-093b-44fa-92c0-9bd0249ee5ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b658910>]}
2021-09-22 12:21:28.831937 (MainThread): Found 2 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 12:21:28.832680 (MainThread): 
2021-09-22 12:21:28.832935 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:21:28.842122 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 12:21:28.842259 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-09-22 12:21:28.847152 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:21:30.365126 (MainThread): 17:51:30 | Concurrency: 1 threads (target='dev')
2021-09-22 12:21:30.365312 (MainThread): 17:51:30 | 
2021-09-22 12:21:30.367995 (Thread-1): Began running node test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3
2021-09-22 12:21:30.368184 (Thread-1): 17:51:30 | 1 of 6 START test accepted_values_my_first_dbt_model_id__False__1__3. [RUN]
2021-09-22 12:21:30.368478 (Thread-1): Acquiring new bigquery connection "test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3".
2021-09-22 12:21:30.368615 (Thread-1): Compiling test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3
2021-09-22 12:21:30.389750 (Thread-1): Writing injected SQL for node "test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3"
2021-09-22 12:21:30.391498 (Thread-1): finished collecting timing info
2021-09-22 12:21:30.391850 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:21:30.397817 (Thread-1): On test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3"} */

    
    




with all_values as (

    select distinct
        id as value_field

    from `unique-arbor-326717`.`test`.`my_first_dbt_model`

),

validation_errors as (

    select
        value_field

    from all_values
    where value_field not in (
        1,3
    )
)

select count(*) as validation_errors
from validation_errors



2021-09-22 12:21:34.253097 (Thread-1): finished collecting timing info
2021-09-22 12:21:34.253699 (Thread-1): 17:51:34 | 1 of 6 PASS accepted_values_my_first_dbt_model_id__False__1__3....... [PASS in 3.89s]
2021-09-22 12:21:34.253849 (Thread-1): Finished running node test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3
2021-09-22 12:21:34.253988 (Thread-1): Began running node test.dbt_project.assert_under_10_percent_null
2021-09-22 12:21:34.254122 (Thread-1): 17:51:34 | 2 of 6 START test assert_under_10_percent_null....................... [RUN]
2021-09-22 12:21:34.254576 (Thread-1): Acquiring new bigquery connection "test.dbt_project.assert_under_10_percent_null".
2021-09-22 12:21:34.254691 (Thread-1): Compiling test.dbt_project.assert_under_10_percent_null
2021-09-22 12:21:34.270263 (Thread-1): Writing injected SQL for node "test.dbt_project.assert_under_10_percent_null"
2021-09-22 12:21:34.270884 (Thread-1): finished collecting timing info
2021-09-22 12:21:34.271188 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:21:34.277078 (Thread-1): On test.dbt_project.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.assert_under_10_percent_null"} */

with dbt__CTE__INTERNAL_test as (
select 
    sum(case when id is null then 1 else 0 end) / count(*) as total_nulls
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
having sum(case when id is null then 1 else 0 end) / count(*) <= .1
)select count(*) from dbt__CTE__INTERNAL_test
2021-09-22 12:21:37.876070 (Thread-1): finished collecting timing info
2021-09-22 12:21:37.876714 (Thread-1): 17:51:37 | 2 of 6 PASS assert_under_10_percent_null............................. [PASS in 3.62s]
2021-09-22 12:21:37.876894 (Thread-1): Finished running node test.dbt_project.assert_under_10_percent_null
2021-09-22 12:21:37.877088 (Thread-1): Began running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 12:21:37.877239 (Thread-1): 17:51:37 | 3 of 6 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-09-22 12:21:37.877722 (Thread-1): Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id".
2021-09-22 12:21:37.877871 (Thread-1): Compiling test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 12:21:37.880028 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61484), raddr=('142.250.77.138', 443)>
2021-09-22 12:21:37.880232 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61485), raddr=('142.250.182.106', 443)>
2021-09-22 12:21:37.888193 (Thread-1): Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id"
2021-09-22 12:21:37.889758 (Thread-1): finished collecting timing info
2021-09-22 12:21:37.890177 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:21:37.896694 (Thread-1): On test.dbt_project.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_second_dbt_model`
where id is null



2021-09-22 12:21:41.962411 (Thread-1): finished collecting timing info
2021-09-22 12:21:41.963244 (Thread-1): 17:51:41 | 3 of 6 FAIL 1 not_null_my_second_dbt_model_id........................ [FAIL 1 in 4.09s]
2021-09-22 12:21:41.963461 (Thread-1): Finished running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 12:21:41.963680 (Thread-1): Began running node test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_
2021-09-22 12:21:41.963886 (Thread-1): 17:51:41 | 4 of 6 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
2021-09-22 12:21:41.964552 (Thread-1): Acquiring new bigquery connection "test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_".
2021-09-22 12:21:41.964722 (Thread-1): Compiling test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_
2021-09-22 12:21:41.968668 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61487), raddr=('142.250.77.138', 443)>
2021-09-22 12:21:41.968849 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61488), raddr=('142.250.182.106', 443)>
2021-09-22 12:21:41.977537 (Thread-1): Writing injected SQL for node "test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_"
2021-09-22 12:21:41.978043 (Thread-1): finished collecting timing info
2021-09-22 12:21:41.978345 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:21:41.984660 (Thread-1): On test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_"} */

    
    




select count(*) as validation_errors
from (
    select id as id from `unique-arbor-326717`.`test`.`my_second_dbt_model`
) as child
left join (
    select id as id from `unique-arbor-326717`.`test`.`my_first_dbt_model`
) as parent on parent.id = child.id
where child.id is not null
  and parent.id is null



2021-09-22 12:21:45.758622 (Thread-1): finished collecting timing info
2021-09-22 12:21:45.759396 (Thread-1): 17:51:45 | 4 of 6 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [PASS in 3.80s]
2021-09-22 12:21:45.759612 (Thread-1): Finished running node test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_
2021-09-22 12:21:45.759832 (Thread-1): Began running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 12:21:45.760040 (Thread-1): 17:51:45 | 5 of 6 START test unique_my_first_dbt_model_id....................... [RUN]
2021-09-22 12:21:45.760573 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id".
2021-09-22 12:21:45.760731 (Thread-1): Compiling test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 12:21:45.765400 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61480), raddr=('142.250.77.138', 443)>
2021-09-22 12:21:45.765571 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61481), raddr=('142.250.182.106', 443)>
2021-09-22 12:21:45.765725 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61483), raddr=('142.250.182.106', 443)>
2021-09-22 12:21:45.765874 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61482), raddr=('142.250.77.138', 443)>
2021-09-22 12:21:45.772802 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61489), raddr=('142.250.77.138', 443)>
2021-09-22 12:21:45.773060 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61490), raddr=('142.250.182.106', 443)>
2021-09-22 12:21:45.779182 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id"
2021-09-22 12:21:45.779661 (Thread-1): finished collecting timing info
2021-09-22 12:21:45.779949 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:21:45.786545 (Thread-1): On test.dbt_project.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_first_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 12:21:49.204354 (Thread-1): finished collecting timing info
2021-09-22 12:21:49.205392 (Thread-1): 17:51:49 | 5 of 6 PASS unique_my_first_dbt_model_id............................. [PASS in 3.44s]
2021-09-22 12:21:49.205620 (Thread-1): Finished running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 12:21:49.205814 (Thread-1): Began running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 12:21:49.206274 (Thread-1): 17:51:49 | 6 of 6 START test unique_my_second_dbt_model_id...................... [RUN]
2021-09-22 12:21:49.206664 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id".
2021-09-22 12:21:49.206794 (Thread-1): Compiling test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 12:21:49.215839 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id"
2021-09-22 12:21:49.217968 (Thread-1): finished collecting timing info
2021-09-22 12:21:49.218358 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:21:49.225201 (Thread-1): On test.dbt_project.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_second_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 12:21:53.029085 (Thread-1): finished collecting timing info
2021-09-22 12:21:53.029832 (Thread-1): 17:51:53 | 6 of 6 PASS unique_my_second_dbt_model_id............................ [PASS in 3.82s]
2021-09-22 12:21:53.030026 (Thread-1): Finished running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 12:21:53.031359 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:21:53.031740 (MainThread): 17:51:53 | 
2021-09-22 12:21:53.031904 (MainThread): 17:51:53 | Finished running 6 tests in 24.20s.
2021-09-22 12:21:53.032041 (MainThread): Connection 'master' was properly closed.
2021-09-22 12:21:53.032144 (MainThread): Connection 'test.dbt_project.unique_my_second_dbt_model_id' was properly closed.
2021-09-22 12:21:53.056017 (MainThread): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61493), raddr=('142.250.77.138', 443)>
2021-09-22 12:21:53.056288 (MainThread): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61494), raddr=('142.250.182.106', 443)>
2021-09-22 12:21:53.081084 (MainThread): 
2021-09-22 12:21:53.081256 (MainThread): Completed with 1 error and 0 warnings:
2021-09-22 12:21:53.081379 (MainThread): 
2021-09-22 12:21:53.081497 (MainThread): Failure in test not_null_my_second_dbt_model_id (models/example/schema.yml)
2021-09-22 12:21:53.081615 (MainThread):   Got 1 result, expected 0.
2021-09-22 12:21:53.081712 (MainThread): 
2021-09-22 12:21:53.081810 (MainThread):   compiled SQL at target/compiled/dbt_project/models/example/schema.yml/schema_test/not_null_my_second_dbt_model_id.sql
2021-09-22 12:21:53.081920 (MainThread): 
Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
2021-09-22 12:21:53.082083 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b6c7eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b57bfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b3ee430>]}
2021-09-22 12:21:53.082275 (MainThread): Flushing usage events
2021-09-22 12:22:35.650567 (MainThread): Running with dbt=0.19.0
2021-09-22 12:22:35.850354 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 12:22:35.851142 (MainThread): Tracking: tracking
2021-09-22 12:22:35.859194 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aaf1d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ab046a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ab04640>]}
2021-09-22 12:22:35.881913 (MainThread): Partial parsing not enabled
2021-09-22 12:22:35.882919 (MainThread): Parsing macros/etc.sql
2021-09-22 12:22:35.885584 (MainThread): Parsing macros/catalog.sql
2021-09-22 12:22:35.892175 (MainThread): Parsing macros/adapters.sql
2021-09-22 12:22:35.910868 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 12:22:35.913551 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 12:22:35.916310 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 12:22:35.926272 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 12:22:35.930766 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 12:22:35.943234 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 12:22:35.946380 (MainThread): Parsing macros/core.sql
2021-09-22 12:22:35.950155 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 12:22:35.958679 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 12:22:35.960403 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 12:22:36.003626 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 12:22:36.045457 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 12:22:36.068465 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 12:22:36.070272 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 12:22:36.081788 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 12:22:36.107361 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 12:22:36.116891 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 12:22:36.126248 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 12:22:36.132894 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 12:22:36.134105 (MainThread): Parsing macros/etc/query.sql
2021-09-22 12:22:36.135397 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 12:22:36.137413 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 12:22:36.148440 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 12:22:36.150798 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 12:22:36.152772 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 12:22:36.201423 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 12:22:36.203404 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 12:22:36.204946 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 12:22:36.207211 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 12:22:36.215756 (MainThread): Partial parsing not enabled
2021-09-22 12:22:36.262981 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:22:36.283676 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:22:36.301404 (MainThread): Acquiring new bigquery connection "test.dbt_project.assert_under_10_percent_null".
2021-09-22 12:22:36.504067 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '103dda81-406b-4eff-908b-c84087064c26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae4b880>]}
2021-09-22 12:22:36.542091 (MainThread): Found 2 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 12:22:36.542834 (MainThread): 
2021-09-22 12:22:36.543107 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:22:36.545333 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 12:22:36.545451 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 12:22:38.165930 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 12:22:38.166180 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 12:22:38.172518 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:22:39.675696 (MainThread): 17:52:39 | Concurrency: 1 threads (target='dev')
2021-09-22 12:22:39.675926 (MainThread): 17:52:39 | 
2021-09-22 12:22:39.677959 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 12:22:39.679176 (Thread-1): 17:52:39 | 1 of 2 START table model test.my_first_dbt_model..................... [RUN]
2021-09-22 12:22:39.679492 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:22:39.679636 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 12:22:39.702169 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 12:22:39.702701 (Thread-1): finished collecting timing info
2021-09-22 12:22:39.726584 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:22:39.732432 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:22:41.659307 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 12:22:41.659838 (Thread-1): On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */


  create or replace table `unique-arbor-326717`.`test`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

 

-- , alias='first_model', schema='dbt_test'  , database='ivory-mountain-326811'


with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id



)

select * 
-- , True as first_variable
from source_data
-- where id is not null
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-09-22 12:22:45.123527 (Thread-1): finished collecting timing info
2021-09-22 12:22:45.125300 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '103dda81-406b-4eff-908b-c84087064c26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae45fa0>]}
2021-09-22 12:22:45.126641 (Thread-1): 17:52:45 | 1 of 2 OK created table model test.my_first_dbt_model................ [CREATE TABLE (3.0 rows, 0.0 Bytes processed) in 5.45s]
2021-09-22 12:22:45.126808 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 12:22:45.127353 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 12:22:45.128810 (Thread-1): 17:52:45 | 2 of 2 START view model test.my_second_dbt_model..................... [RUN]
2021-09-22 12:22:45.129117 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:22:45.129245 (Thread-1): Compiling model.dbt_project.my_second_dbt_model
2021-09-22 12:22:45.137872 (Thread-1): Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 12:22:45.138264 (Thread-1): finished collecting timing info
2021-09-22 12:22:45.159336 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 12:22:45.159809 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:22:45.165352 (Thread-1): On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
-- where id = 1
-- union all
-- select 7 as id;


2021-09-22 12:22:45.251372 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61504), raddr=('142.250.77.138', 443)>
2021-09-22 12:22:45.251596 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61505), raddr=('142.250.182.106', 443)>
2021-09-22 12:22:45.251762 (Thread-1): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61507), raddr=('142.250.182.106', 443)>
2021-09-22 12:22:45.251905 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61506), raddr=('142.250.77.138', 443)>
2021-09-22 12:22:45.252049 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61509), raddr=('142.250.182.106', 443)>
2021-09-22 12:22:45.252198 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61508), raddr=('142.250.77.138', 443)>
2021-09-22 12:22:48.092782 (Thread-1): finished collecting timing info
2021-09-22 12:22:48.093777 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '103dda81-406b-4eff-908b-c84087064c26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10adc5a90>]}
2021-09-22 12:22:48.095612 (Thread-1): 17:52:48 | 2 of 2 OK created view model test.my_second_dbt_model................ [OK in 2.96s]
2021-09-22 12:22:48.095813 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 12:22:48.097041 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:22:48.097357 (MainThread): 17:52:48 | 
2021-09-22 12:22:48.097495 (MainThread): 17:52:48 | Finished running 1 table model, 1 view model in 11.55s.
2021-09-22 12:22:48.097613 (MainThread): Connection 'master' was properly closed.
2021-09-22 12:22:48.097702 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 12:22:48.141507 (MainThread): 
2021-09-22 12:22:48.141686 (MainThread): Completed successfully
2021-09-22 12:22:48.141802 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-09-22 12:22:48.141963 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ad0dd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10adc5a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae02400>]}
2021-09-22 12:22:48.142148 (MainThread): Flushing usage events
2021-09-22 12:22:57.867799 (MainThread): Running with dbt=0.19.0
2021-09-22 12:22:58.068484 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-09-22 12:22:58.069267 (MainThread): Tracking: tracking
2021-09-22 12:22:58.079053 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065d1c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065e3730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065e36d0>]}
2021-09-22 12:22:58.101434 (MainThread): Partial parsing not enabled
2021-09-22 12:22:58.102383 (MainThread): Parsing macros/etc.sql
2021-09-22 12:22:58.104925 (MainThread): Parsing macros/catalog.sql
2021-09-22 12:22:58.110774 (MainThread): Parsing macros/adapters.sql
2021-09-22 12:22:58.130133 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 12:22:58.132757 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 12:22:58.135402 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 12:22:58.145002 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 12:22:58.149235 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 12:22:58.161782 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 12:22:58.164482 (MainThread): Parsing macros/core.sql
2021-09-22 12:22:58.168229 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 12:22:58.176948 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 12:22:58.178656 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 12:22:58.222511 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 12:22:58.263860 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 12:22:58.286150 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 12:22:58.287950 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 12:22:58.294203 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 12:22:58.307883 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 12:22:58.314331 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 12:22:58.320519 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 12:22:58.325606 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 12:22:58.326498 (MainThread): Parsing macros/etc/query.sql
2021-09-22 12:22:58.327477 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 12:22:58.328988 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 12:22:58.337510 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 12:22:58.340306 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 12:22:58.342071 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 12:22:58.385271 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 12:22:58.387529 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 12:22:58.389024 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 12:22:58.390756 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 12:22:58.398403 (MainThread): Partial parsing not enabled
2021-09-22 12:22:58.437436 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:22:58.458160 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:22:58.475960 (MainThread): Acquiring new bigquery connection "test.dbt_project.assert_under_10_percent_null".
2021-09-22 12:22:58.673821 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd6322ea4-af95-4f3d-89ea-916d50ab133c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10690ba00>]}
2021-09-22 12:22:58.710438 (MainThread): Found 2 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 12:22:58.711240 (MainThread): 
2021-09-22 12:22:58.711484 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:22:58.719901 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 12:22:58.720009 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-09-22 12:22:58.724883 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:22:59.541087 (MainThread): 17:52:59 | Concurrency: 1 threads (target='dev')
2021-09-22 12:22:59.541320 (MainThread): 17:52:59 | 
2021-09-22 12:22:59.543297 (Thread-1): Began running node test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3
2021-09-22 12:22:59.543489 (Thread-1): 17:52:59 | 1 of 6 START test accepted_values_my_first_dbt_model_id__False__1__3. [RUN]
2021-09-22 12:22:59.543778 (Thread-1): Acquiring new bigquery connection "test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3".
2021-09-22 12:22:59.543920 (Thread-1): Compiling test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3
2021-09-22 12:22:59.567050 (Thread-1): Writing injected SQL for node "test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3"
2021-09-22 12:22:59.567648 (Thread-1): finished collecting timing info
2021-09-22 12:22:59.568003 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:22:59.574381 (Thread-1): On test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3"} */

    
    




with all_values as (

    select distinct
        id as value_field

    from `unique-arbor-326717`.`test`.`my_first_dbt_model`

),

validation_errors as (

    select
        value_field

    from all_values
    where value_field not in (
        1,3
    )
)

select count(*) as validation_errors
from validation_errors



2021-09-22 12:23:02.013445 (Thread-1): finished collecting timing info
2021-09-22 12:23:02.014260 (Thread-1): 17:53:02 | 1 of 6 PASS accepted_values_my_first_dbt_model_id__False__1__3....... [PASS in 2.47s]
2021-09-22 12:23:02.014485 (Thread-1): Finished running node test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3
2021-09-22 12:23:02.014705 (Thread-1): Began running node test.dbt_project.assert_under_10_percent_null
2021-09-22 12:23:02.014919 (Thread-1): 17:53:02 | 2 of 6 START test assert_under_10_percent_null....................... [RUN]
2021-09-22 12:23:02.015533 (Thread-1): Acquiring new bigquery connection "test.dbt_project.assert_under_10_percent_null".
2021-09-22 12:23:02.015686 (Thread-1): Compiling test.dbt_project.assert_under_10_percent_null
2021-09-22 12:23:02.033608 (Thread-1): Writing injected SQL for node "test.dbt_project.assert_under_10_percent_null"
2021-09-22 12:23:02.034089 (Thread-1): finished collecting timing info
2021-09-22 12:23:02.034384 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:23:02.040917 (Thread-1): On test.dbt_project.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.assert_under_10_percent_null"} */

with dbt__CTE__INTERNAL_test as (
select 
    sum(case when id is null then 1 else 0 end) / count(*) as total_nulls
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
having sum(case when id is null then 1 else 0 end) / count(*) > .1
)select count(*) from dbt__CTE__INTERNAL_test
2021-09-22 12:23:05.904416 (Thread-1): finished collecting timing info
2021-09-22 12:23:05.905220 (Thread-1): 17:53:05 | 2 of 6 FAIL 1 assert_under_10_percent_null........................... [FAIL 1 in 3.89s]
2021-09-22 12:23:05.905447 (Thread-1): Finished running node test.dbt_project.assert_under_10_percent_null
2021-09-22 12:23:05.905671 (Thread-1): Began running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 12:23:05.905883 (Thread-1): 17:53:05 | 3 of 6 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-09-22 12:23:05.906491 (Thread-1): Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id".
2021-09-22 12:23:05.906663 (Thread-1): Compiling test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 12:23:05.909018 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61519), raddr=('142.250.77.138', 443)>
2021-09-22 12:23:05.909243 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61520), raddr=('142.250.182.106', 443)>
2021-09-22 12:23:05.917038 (Thread-1): Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id"
2021-09-22 12:23:05.917503 (Thread-1): finished collecting timing info
2021-09-22 12:23:05.917794 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:23:05.923994 (Thread-1): On test.dbt_project.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_second_dbt_model`
where id is null



2021-09-22 12:23:09.509349 (Thread-1): finished collecting timing info
2021-09-22 12:23:09.510157 (Thread-1): 17:53:09 | 3 of 6 FAIL 1 not_null_my_second_dbt_model_id........................ [FAIL 1 in 3.60s]
2021-09-22 12:23:09.510382 (Thread-1): Finished running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 12:23:09.510603 (Thread-1): Began running node test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_
2021-09-22 12:23:09.510812 (Thread-1): 17:53:09 | 4 of 6 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
2021-09-22 12:23:09.511369 (Thread-1): Acquiring new bigquery connection "test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_".
2021-09-22 12:23:09.511530 (Thread-1): Compiling test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_
2021-09-22 12:23:09.515506 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61522), raddr=('142.250.77.138', 443)>
2021-09-22 12:23:09.515695 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61523), raddr=('142.250.182.106', 443)>
2021-09-22 12:23:09.523920 (Thread-1): Writing injected SQL for node "test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_"
2021-09-22 12:23:09.524380 (Thread-1): finished collecting timing info
2021-09-22 12:23:09.524672 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:23:09.530927 (Thread-1): On test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_"} */

    
    




select count(*) as validation_errors
from (
    select id as id from `unique-arbor-326717`.`test`.`my_second_dbt_model`
) as child
left join (
    select id as id from `unique-arbor-326717`.`test`.`my_first_dbt_model`
) as parent on parent.id = child.id
where child.id is not null
  and parent.id is null



2021-09-22 12:23:13.277118 (Thread-1): finished collecting timing info
2021-09-22 12:23:13.277784 (Thread-1): 17:53:13 | 4 of 6 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [PASS in 3.77s]
2021-09-22 12:23:13.277968 (Thread-1): Finished running node test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_
2021-09-22 12:23:13.278142 (Thread-1): Began running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 12:23:13.278306 (Thread-1): 17:53:13 | 5 of 6 START test unique_my_first_dbt_model_id....................... [RUN]
2021-09-22 12:23:13.278660 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id".
2021-09-22 12:23:13.278807 (Thread-1): Compiling test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 12:23:13.283181 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61515), raddr=('142.250.77.138', 443)>
2021-09-22 12:23:13.283369 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61516), raddr=('142.250.182.106', 443)>
2021-09-22 12:23:13.283521 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61518), raddr=('142.250.182.106', 443)>
2021-09-22 12:23:13.283668 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61517), raddr=('142.250.77.138', 443)>
2021-09-22 12:23:13.290753 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61525), raddr=('142.250.77.138', 443)>
2021-09-22 12:23:13.290967 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61526), raddr=('142.250.182.106', 443)>
2021-09-22 12:23:13.297082 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id"
2021-09-22 12:23:13.297555 (Thread-1): finished collecting timing info
2021-09-22 12:23:13.297922 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:23:13.304363 (Thread-1): On test.dbt_project.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_first_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 12:23:16.793383 (Thread-1): finished collecting timing info
2021-09-22 12:23:16.794139 (Thread-1): 17:53:16 | 5 of 6 PASS unique_my_first_dbt_model_id............................. [PASS in 3.52s]
2021-09-22 12:23:16.794322 (Thread-1): Finished running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 12:23:16.794499 (Thread-1): Began running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 12:23:16.794668 (Thread-1): 17:53:16 | 6 of 6 START test unique_my_second_dbt_model_id...................... [RUN]
2021-09-22 12:23:16.795103 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id".
2021-09-22 12:23:16.795268 (Thread-1): Compiling test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 12:23:16.804454 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id"
2021-09-22 12:23:16.804901 (Thread-1): finished collecting timing info
2021-09-22 12:23:16.805172 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:23:16.811081 (Thread-1): On test.dbt_project.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_second_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 12:23:20.361002 (Thread-1): finished collecting timing info
2021-09-22 12:23:20.361683 (Thread-1): 17:53:20 | 6 of 6 PASS unique_my_second_dbt_model_id............................ [PASS in 3.57s]
2021-09-22 12:23:20.361869 (Thread-1): Finished running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 12:23:20.363277 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:23:20.363692 (MainThread): 17:53:20 | 
2021-09-22 12:23:20.363870 (MainThread): 17:53:20 | Finished running 6 tests in 21.65s.
2021-09-22 12:23:20.364013 (MainThread): Connection 'master' was properly closed.
2021-09-22 12:23:20.364119 (MainThread): Connection 'test.dbt_project.unique_my_second_dbt_model_id' was properly closed.
2021-09-22 12:23:20.387760 (MainThread): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61529), raddr=('142.250.77.138', 443)>
2021-09-22 12:23:20.388116 (MainThread): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61530), raddr=('142.250.182.106', 443)>
2021-09-22 12:23:20.411477 (MainThread): 
2021-09-22 12:23:20.411642 (MainThread): Completed with 2 errors and 0 warnings:
2021-09-22 12:23:20.411819 (MainThread): 
2021-09-22 12:23:20.411959 (MainThread): Failure in test assert_under_10_percent_null (tests/assert_under_10_percent_null.sql)
2021-09-22 12:23:20.412106 (MainThread):   Got 1 result, expected 0.
2021-09-22 12:23:20.412235 (MainThread): 
2021-09-22 12:23:20.412410 (MainThread):   compiled SQL at target/compiled/dbt_project/tests/assert_under_10_percent_null.sql
2021-09-22 12:23:20.412531 (MainThread): 
2021-09-22 12:23:20.412643 (MainThread): Failure in test not_null_my_second_dbt_model_id (models/example/schema.yml)
2021-09-22 12:23:20.412743 (MainThread):   Got 1 result, expected 0.
2021-09-22 12:23:20.412893 (MainThread): 
2021-09-22 12:23:20.413006 (MainThread):   compiled SQL at target/compiled/dbt_project/models/example/schema.yml/schema_test/not_null_my_second_dbt_model_id.sql
2021-09-22 12:23:20.413121 (MainThread): 
Done. PASS=4 WARN=0 ERROR=2 SKIP=0 TOTAL=6
2021-09-22 12:23:20.413281 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10690e220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b63be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b41400>]}
2021-09-22 12:23:20.413470 (MainThread): Flushing usage events
2021-09-22 12:23:24.406331 (MainThread): Running with dbt=0.19.0
2021-09-22 12:23:24.618238 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 12:23:24.618977 (MainThread): Tracking: tracking
2021-09-22 12:23:24.626936 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10553fac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105552700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055526a0>]}
2021-09-22 12:23:24.650682 (MainThread): Partial parsing not enabled
2021-09-22 12:23:24.651780 (MainThread): Parsing macros/etc.sql
2021-09-22 12:23:24.654573 (MainThread): Parsing macros/catalog.sql
2021-09-22 12:23:24.661120 (MainThread): Parsing macros/adapters.sql
2021-09-22 12:23:24.680794 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 12:23:24.683486 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 12:23:24.686198 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 12:23:24.696412 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 12:23:24.700696 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 12:23:24.713748 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 12:23:24.716577 (MainThread): Parsing macros/core.sql
2021-09-22 12:23:24.720337 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 12:23:24.729237 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 12:23:24.730970 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 12:23:24.776987 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 12:23:24.819580 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 12:23:24.844434 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 12:23:24.846637 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 12:23:24.853636 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 12:23:24.867895 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 12:23:24.874998 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 12:23:24.881285 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 12:23:24.886168 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 12:23:24.887089 (MainThread): Parsing macros/etc/query.sql
2021-09-22 12:23:24.888164 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 12:23:24.889821 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 12:23:24.898657 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 12:23:24.900781 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 12:23:24.902448 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 12:23:24.945543 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 12:23:24.947387 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 12:23:24.948829 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 12:23:24.950584 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 12:23:24.958562 (MainThread): Partial parsing not enabled
2021-09-22 12:23:24.997506 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:23:25.018547 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:23:25.036517 (MainThread): Acquiring new bigquery connection "test.dbt_project.assert_under_10_percent_null".
2021-09-22 12:23:25.242375 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f26dcbfc-8e74-406e-b952-f8e9a50ecaad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105860160>]}
2021-09-22 12:23:25.281759 (MainThread): Found 2 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 12:23:25.282452 (MainThread): 
2021-09-22 12:23:25.282717 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:23:25.285127 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 12:23:25.285254 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 12:23:26.911401 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 12:23:26.911644 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 12:23:26.918073 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:23:28.438514 (MainThread): 17:53:28 | Concurrency: 1 threads (target='dev')
2021-09-22 12:23:28.438743 (MainThread): 17:53:28 | 
2021-09-22 12:23:28.441437 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 12:23:28.442958 (Thread-1): 17:53:28 | 1 of 2 START table model test.my_first_dbt_model..................... [RUN]
2021-09-22 12:23:28.443304 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:23:28.443439 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 12:23:28.466992 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 12:23:28.467480 (Thread-1): finished collecting timing info
2021-09-22 12:23:28.492387 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:23:28.498002 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:23:30.094121 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 12:23:30.094647 (Thread-1): On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */


  create or replace table `unique-arbor-326717`.`test`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

 

-- , alias='first_model', schema='dbt_test'  , database='ivory-mountain-326811'


with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id



)

select * 
-- , True as first_variable
from source_data
-- where id is not null
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-09-22 12:23:33.150675 (Thread-1): finished collecting timing info
2021-09-22 12:23:33.151429 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f26dcbfc-8e74-406e-b952-f8e9a50ecaad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057157c0>]}
2021-09-22 12:23:33.152672 (Thread-1): 17:53:33 | 1 of 2 OK created table model test.my_first_dbt_model................ [CREATE TABLE (3.0 rows, 0.0 Bytes processed) in 4.71s]
2021-09-22 12:23:33.152830 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 12:23:33.153525 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 12:23:33.154932 (Thread-1): 17:53:33 | 2 of 2 START view model test.my_second_dbt_model..................... [RUN]
2021-09-22 12:23:33.155258 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:23:33.155386 (Thread-1): Compiling model.dbt_project.my_second_dbt_model
2021-09-22 12:23:33.164584 (Thread-1): Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 12:23:33.165090 (Thread-1): finished collecting timing info
2021-09-22 12:23:33.189936 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 12:23:33.190482 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:23:33.196575 (Thread-1): On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
-- where id = 1
-- union all
-- select 7 as id;


2021-09-22 12:23:33.282631 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61535), raddr=('142.250.77.138', 443)>
2021-09-22 12:23:33.282895 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61536), raddr=('142.250.182.106', 443)>
2021-09-22 12:23:33.283087 (Thread-1): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61538), raddr=('142.250.182.106', 443)>
2021-09-22 12:23:33.283253 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61537), raddr=('142.250.77.138', 443)>
2021-09-22 12:23:33.283423 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61540), raddr=('142.250.182.106', 443)>
2021-09-22 12:23:33.283597 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61539), raddr=('142.250.77.138', 443)>
2021-09-22 12:23:36.103182 (Thread-1): finished collecting timing info
2021-09-22 12:23:36.104162 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f26dcbfc-8e74-406e-b952-f8e9a50ecaad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105894d90>]}
2021-09-22 12:23:36.105416 (Thread-1): 17:53:36 | 2 of 2 OK created view model test.my_second_dbt_model................ [OK in 2.95s]
2021-09-22 12:23:36.105577 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 12:23:36.106850 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:23:36.107270 (MainThread): 17:53:36 | 
2021-09-22 12:23:36.107423 (MainThread): 17:53:36 | Finished running 1 table model, 1 view model in 10.82s.
2021-09-22 12:23:36.107584 (MainThread): Connection 'master' was properly closed.
2021-09-22 12:23:36.107759 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 12:23:36.152779 (MainThread): 
2021-09-22 12:23:36.152942 (MainThread): Completed successfully
2021-09-22 12:23:36.153060 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-09-22 12:23:36.153222 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105840520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b4d5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105740a60>]}
2021-09-22 12:23:36.153404 (MainThread): Flushing usage events
2021-09-22 12:23:39.951978 (MainThread): Running with dbt=0.19.0
2021-09-22 12:23:40.177211 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-09-22 12:23:40.177951 (MainThread): Tracking: tracking
2021-09-22 12:23:40.185594 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ec4a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ed7700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ed76a0>]}
2021-09-22 12:23:40.210207 (MainThread): Partial parsing not enabled
2021-09-22 12:23:40.211433 (MainThread): Parsing macros/etc.sql
2021-09-22 12:23:40.214577 (MainThread): Parsing macros/catalog.sql
2021-09-22 12:23:40.220841 (MainThread): Parsing macros/adapters.sql
2021-09-22 12:23:40.240045 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 12:23:40.243271 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 12:23:40.246065 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 12:23:40.255955 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 12:23:40.260313 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 12:23:40.272932 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 12:23:40.276205 (MainThread): Parsing macros/core.sql
2021-09-22 12:23:40.280063 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 12:23:40.288943 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 12:23:40.290703 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 12:23:40.336933 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 12:23:40.380283 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 12:23:40.404743 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 12:23:40.406830 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 12:23:40.413827 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 12:23:40.428706 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 12:23:40.435356 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 12:23:40.442643 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 12:23:40.448408 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 12:23:40.449509 (MainThread): Parsing macros/etc/query.sql
2021-09-22 12:23:40.450706 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 12:23:40.452744 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 12:23:40.462600 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 12:23:40.464591 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 12:23:40.466262 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 12:23:40.510477 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 12:23:40.512406 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 12:23:40.513888 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 12:23:40.515554 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 12:23:40.523558 (MainThread): Partial parsing not enabled
2021-09-22 12:23:40.563914 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:23:40.585325 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:23:40.603965 (MainThread): Acquiring new bigquery connection "test.dbt_project.assert_under_10_percent_null".
2021-09-22 12:23:40.809953 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'be91da93-307e-4ddb-9f2d-310dcc29b848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107207490>]}
2021-09-22 12:23:40.848294 (MainThread): Found 2 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 12:23:40.849123 (MainThread): 
2021-09-22 12:23:40.849378 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:23:40.858687 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 12:23:40.858820 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-09-22 12:23:40.863743 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:23:42.570208 (MainThread): 17:53:42 | Concurrency: 1 threads (target='dev')
2021-09-22 12:23:42.570426 (MainThread): 17:53:42 | 
2021-09-22 12:23:42.572386 (Thread-1): Began running node test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3
2021-09-22 12:23:42.572597 (Thread-1): 17:53:42 | 1 of 6 START test accepted_values_my_first_dbt_model_id__False__1__3. [RUN]
2021-09-22 12:23:42.572902 (Thread-1): Acquiring new bigquery connection "test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3".
2021-09-22 12:23:42.573053 (Thread-1): Compiling test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3
2021-09-22 12:23:42.597008 (Thread-1): Writing injected SQL for node "test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3"
2021-09-22 12:23:42.597551 (Thread-1): finished collecting timing info
2021-09-22 12:23:42.597872 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:23:42.604003 (Thread-1): On test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3"} */

    
    




with all_values as (

    select distinct
        id as value_field

    from `unique-arbor-326717`.`test`.`my_first_dbt_model`

),

validation_errors as (

    select
        value_field

    from all_values
    where value_field not in (
        1,3
    )
)

select count(*) as validation_errors
from validation_errors



2021-09-22 12:23:47.104274 (Thread-1): finished collecting timing info
2021-09-22 12:23:47.105089 (Thread-1): 17:53:47 | 1 of 6 PASS accepted_values_my_first_dbt_model_id__False__1__3....... [PASS in 4.53s]
2021-09-22 12:23:47.105318 (Thread-1): Finished running node test.dbt_project.accepted_values_my_first_dbt_model_id__False__1__3
2021-09-22 12:23:47.105624 (Thread-1): Began running node test.dbt_project.assert_under_10_percent_null
2021-09-22 12:23:47.106211 (Thread-1): 17:53:47 | 2 of 6 START test assert_under_10_percent_null....................... [RUN]
2021-09-22 12:23:47.107244 (Thread-1): Acquiring new bigquery connection "test.dbt_project.assert_under_10_percent_null".
2021-09-22 12:23:47.107438 (Thread-1): Compiling test.dbt_project.assert_under_10_percent_null
2021-09-22 12:23:47.125660 (Thread-1): Writing injected SQL for node "test.dbt_project.assert_under_10_percent_null"
2021-09-22 12:23:47.126178 (Thread-1): finished collecting timing info
2021-09-22 12:23:47.126529 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:23:47.132903 (Thread-1): On test.dbt_project.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.assert_under_10_percent_null"} */

with dbt__CTE__INTERNAL_test as (
select 
    sum(case when id is null then 1 else 0 end) / count(*) as total_nulls
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
having sum(case when id is null then 1 else 0 end) / count(*) > .4
)select count(*) from dbt__CTE__INTERNAL_test
2021-09-22 12:23:50.805188 (Thread-1): finished collecting timing info
2021-09-22 12:23:50.806052 (Thread-1): 17:53:50 | 2 of 6 PASS assert_under_10_percent_null............................. [PASS in 3.70s]
2021-09-22 12:23:50.806284 (Thread-1): Finished running node test.dbt_project.assert_under_10_percent_null
2021-09-22 12:23:50.806511 (Thread-1): Began running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 12:23:50.807058 (Thread-1): 17:53:50 | 3 of 6 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-09-22 12:23:50.807729 (Thread-1): Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id".
2021-09-22 12:23:50.807901 (Thread-1): Compiling test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 12:23:50.810306 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61551), raddr=('142.250.77.138', 443)>
2021-09-22 12:23:50.810544 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61552), raddr=('142.250.182.106', 443)>
2021-09-22 12:23:50.818464 (Thread-1): Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id"
2021-09-22 12:23:50.818920 (Thread-1): finished collecting timing info
2021-09-22 12:23:50.819222 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:23:50.825605 (Thread-1): On test.dbt_project.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `unique-arbor-326717`.`test`.`my_second_dbt_model`
where id is null



2021-09-22 12:23:54.544734 (Thread-1): finished collecting timing info
2021-09-22 12:23:54.545397 (Thread-1): 17:53:54 | 3 of 6 FAIL 1 not_null_my_second_dbt_model_id........................ [FAIL 1 in 3.74s]
2021-09-22 12:23:54.545577 (Thread-1): Finished running node test.dbt_project.not_null_my_second_dbt_model_id
2021-09-22 12:23:54.545755 (Thread-1): Began running node test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_
2021-09-22 12:23:54.545922 (Thread-1): 17:53:54 | 4 of 6 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
2021-09-22 12:23:54.546255 (Thread-1): Acquiring new bigquery connection "test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_".
2021-09-22 12:23:54.546523 (Thread-1): Compiling test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_
2021-09-22 12:23:54.550194 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61554), raddr=('142.250.77.138', 443)>
2021-09-22 12:23:54.550386 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61555), raddr=('142.250.182.106', 443)>
2021-09-22 12:23:54.558768 (Thread-1): Writing injected SQL for node "test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_"
2021-09-22 12:23:54.559236 (Thread-1): finished collecting timing info
2021-09-22 12:23:54.559533 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:23:54.565770 (Thread-1): On test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_"} */

    
    




select count(*) as validation_errors
from (
    select id as id from `unique-arbor-326717`.`test`.`my_second_dbt_model`
) as child
left join (
    select id as id from `unique-arbor-326717`.`test`.`my_first_dbt_model`
) as parent on parent.id = child.id
where child.id is not null
  and parent.id is null



2021-09-22 12:23:58.233659 (Thread-1): finished collecting timing info
2021-09-22 12:23:58.234450 (Thread-1): 17:53:58 | 4 of 6 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [PASS in 3.69s]
2021-09-22 12:23:58.234676 (Thread-1): Finished running node test.dbt_project.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_
2021-09-22 12:23:58.234894 (Thread-1): Began running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 12:23:58.235102 (Thread-1): 17:53:58 | 5 of 6 START test unique_my_first_dbt_model_id....................... [RUN]
2021-09-22 12:23:58.235611 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id".
2021-09-22 12:23:58.235752 (Thread-1): Compiling test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 12:23:58.240839 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61547), raddr=('142.250.77.138', 443)>
2021-09-22 12:23:58.241130 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61548), raddr=('142.250.182.106', 443)>
2021-09-22 12:23:58.241326 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61550), raddr=('142.250.182.106', 443)>
2021-09-22 12:23:58.241489 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61549), raddr=('142.250.77.138', 443)>
2021-09-22 12:23:58.248186 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61556), raddr=('142.250.77.138', 443)>
2021-09-22 12:23:58.248379 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61557), raddr=('142.250.182.106', 443)>
2021-09-22 12:23:58.254572 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id"
2021-09-22 12:23:58.255018 (Thread-1): finished collecting timing info
2021-09-22 12:23:58.255400 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:23:58.261785 (Thread-1): On test.dbt_project.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_first_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 12:24:02.532910 (Thread-1): finished collecting timing info
2021-09-22 12:24:02.533721 (Thread-1): 17:54:02 | 5 of 6 PASS unique_my_first_dbt_model_id............................. [PASS in 4.30s]
2021-09-22 12:24:02.533950 (Thread-1): Finished running node test.dbt_project.unique_my_first_dbt_model_id
2021-09-22 12:24:02.534173 (Thread-1): Began running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 12:24:02.534385 (Thread-1): 17:54:02 | 6 of 6 START test unique_my_second_dbt_model_id...................... [RUN]
2021-09-22 12:24:02.534968 (Thread-1): Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id".
2021-09-22 12:24:02.535127 (Thread-1): Compiling test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 12:24:02.545083 (Thread-1): Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id"
2021-09-22 12:24:02.545595 (Thread-1): finished collecting timing info
2021-09-22 12:24:02.545900 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:24:02.552058 (Thread-1): On test.dbt_project.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "test.dbt_project.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `unique-arbor-326717`.`test`.`my_second_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-09-22 12:24:06.526497 (Thread-1): finished collecting timing info
2021-09-22 12:24:06.527195 (Thread-1): 17:54:06 | 6 of 6 PASS unique_my_second_dbt_model_id............................ [PASS in 3.99s]
2021-09-22 12:24:06.527385 (Thread-1): Finished running node test.dbt_project.unique_my_second_dbt_model_id
2021-09-22 12:24:06.528625 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:24:06.528938 (MainThread): 17:54:06 | 
2021-09-22 12:24:06.529077 (MainThread): 17:54:06 | Finished running 6 tests in 25.68s.
2021-09-22 12:24:06.529193 (MainThread): Connection 'master' was properly closed.
2021-09-22 12:24:06.529281 (MainThread): Connection 'test.dbt_project.unique_my_second_dbt_model_id' was properly closed.
2021-09-22 12:24:06.552376 (MainThread): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61560), raddr=('142.250.77.138', 443)>
2021-09-22 12:24:06.552632 (MainThread): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61561), raddr=('142.250.182.106', 443)>
2021-09-22 12:24:06.577854 (MainThread): 
2021-09-22 12:24:06.578018 (MainThread): Completed with 1 error and 0 warnings:
2021-09-22 12:24:06.578133 (MainThread): 
2021-09-22 12:24:06.578242 (MainThread): Failure in test not_null_my_second_dbt_model_id (models/example/schema.yml)
2021-09-22 12:24:06.578344 (MainThread):   Got 1 result, expected 0.
2021-09-22 12:24:06.578437 (MainThread): 
2021-09-22 12:24:06.578534 (MainThread):   compiled SQL at target/compiled/dbt_project/models/example/schema.yml/schema_test/not_null_my_second_dbt_model_id.sql
2021-09-22 12:24:06.578641 (MainThread): 
Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
2021-09-22 12:24:06.578793 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070713d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107071400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107071430>]}
2021-09-22 12:24:06.578977 (MainThread): Flushing usage events
2021-09-22 12:26:16.288978 (MainThread): Running with dbt=0.19.0
2021-09-22 12:26:16.509784 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['example'], partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 12:26:16.511842 (MainThread): Tracking: tracking
2021-09-22 12:26:16.521489 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac60e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac737f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac73790>]}
2021-09-22 12:26:16.546135 (MainThread): Partial parsing not enabled
2021-09-22 12:26:16.547280 (MainThread): Parsing macros/etc.sql
2021-09-22 12:26:16.550361 (MainThread): Parsing macros/catalog.sql
2021-09-22 12:26:16.556899 (MainThread): Parsing macros/adapters.sql
2021-09-22 12:26:16.576329 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 12:26:16.579070 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 12:26:16.581831 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 12:26:16.591630 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 12:26:16.596309 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 12:26:16.609097 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 12:26:16.611897 (MainThread): Parsing macros/core.sql
2021-09-22 12:26:16.615709 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 12:26:16.624510 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 12:26:16.626591 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 12:26:16.672603 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 12:26:16.714752 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 12:26:16.739363 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 12:26:16.741547 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 12:26:16.747916 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 12:26:16.762455 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 12:26:16.769391 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 12:26:16.777726 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 12:26:16.784795 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 12:26:16.785729 (MainThread): Parsing macros/etc/query.sql
2021-09-22 12:26:16.786727 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 12:26:16.788273 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 12:26:16.797569 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 12:26:16.799497 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 12:26:16.801168 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 12:26:16.846700 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 12:26:16.849050 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 12:26:16.850573 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 12:26:16.852253 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 12:26:16.860185 (MainThread): Partial parsing not enabled
2021-09-22 12:26:16.900272 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:26:16.921390 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:26:16.939715 (MainThread): Acquiring new bigquery connection "test.dbt_project.assert_under_10_percent_null".
2021-09-22 12:26:17.146380 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4bb8c31e-2bba-4f5b-a559-011af1a0eb6b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af911c0>]}
2021-09-22 12:26:17.185443 (MainThread): Found 2 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 12:26:17.186083 (MainThread): 
2021-09-22 12:26:17.186395 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:26:17.188689 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 12:26:17.188813 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 12:26:17.820129 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 12:26:17.820373 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 12:26:17.826833 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:26:18.426640 (MainThread): 17:56:18 | Concurrency: 1 threads (target='dev')
2021-09-22 12:26:18.426889 (MainThread): 17:56:18 | 
2021-09-22 12:26:18.429783 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 12:26:18.431231 (Thread-1): 17:56:18 | 1 of 2 START table model test.my_first_dbt_model..................... [RUN]
2021-09-22 12:26:18.431559 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:26:18.431692 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 12:26:18.454130 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 12:26:18.454605 (Thread-1): finished collecting timing info
2021-09-22 12:26:18.478176 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:26:18.483832 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:26:19.161704 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 12:26:19.162244 (Thread-1): On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */


  create or replace table `unique-arbor-326717`.`test`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

 

-- , alias='first_model', schema='dbt_test'  , database='ivory-mountain-326811'


with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id



)

select * 
-- , True as first_variable
from source_data
-- where id is not null
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-09-22 12:26:23.047359 (Thread-1): finished collecting timing info
2021-09-22 12:26:23.048228 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4bb8c31e-2bba-4f5b-a559-011af1a0eb6b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae40100>]}
2021-09-22 12:26:23.049481 (Thread-1): 17:56:23 | 1 of 2 OK created table model test.my_first_dbt_model................ [CREATE TABLE (3.0 rows, 0.0 Bytes processed) in 4.62s]
2021-09-22 12:26:23.049633 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 12:26:23.050255 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 12:26:23.051615 (Thread-1): 17:56:23 | 2 of 2 START view model test.my_second_dbt_model..................... [RUN]
2021-09-22 12:26:23.051904 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:26:23.052025 (Thread-1): Compiling model.dbt_project.my_second_dbt_model
2021-09-22 12:26:23.060643 (Thread-1): Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 12:26:23.061130 (Thread-1): finished collecting timing info
2021-09-22 12:26:23.084537 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 12:26:23.085084 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:26:23.091029 (Thread-1): On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
-- where id = 1
-- union all
-- select 7 as id;


2021-09-22 12:26:23.177482 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61580), raddr=('172.217.31.202', 443)>
2021-09-22 12:26:23.177761 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61581), raddr=('142.250.182.106', 443)>
2021-09-22 12:26:23.177947 (Thread-1): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61583), raddr=('142.250.182.106', 443)>
2021-09-22 12:26:23.178089 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61582), raddr=('172.217.31.202', 443)>
2021-09-22 12:26:23.178232 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61585), raddr=('142.250.182.106', 443)>
2021-09-22 12:26:23.178373 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61584), raddr=('172.217.31.202', 443)>
2021-09-22 12:26:25.997865 (Thread-1): finished collecting timing info
2021-09-22 12:26:25.998879 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4bb8c31e-2bba-4f5b-a559-011af1a0eb6b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae40220>]}
2021-09-22 12:26:26.000195 (Thread-1): 17:56:26 | 2 of 2 OK created view model test.my_second_dbt_model................ [OK in 2.95s]
2021-09-22 12:26:26.000350 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 12:26:26.001720 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:26:26.002043 (MainThread): 17:56:26 | 
2021-09-22 12:26:26.002186 (MainThread): 17:56:26 | Finished running 1 table model, 1 view model in 8.82s.
2021-09-22 12:26:26.002304 (MainThread): Connection 'master' was properly closed.
2021-09-22 12:26:26.002392 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 12:26:26.050649 (MainThread): 
2021-09-22 12:26:26.050825 (MainThread): Completed successfully
2021-09-22 12:26:26.050948 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-09-22 12:26:26.051121 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af40be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae7a4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae28250>]}
2021-09-22 12:26:26.051326 (MainThread): Flushing usage events
2021-09-22 12:26:50.805250 (MainThread): Running with dbt=0.19.0
2021-09-22 12:26:51.129494 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['my_first_dbt_model'], partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 12:26:51.130564 (MainThread): Tracking: tracking
2021-09-22 12:26:51.139809 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc9acd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fcac790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fcac730>]}
2021-09-22 12:26:51.165168 (MainThread): Partial parsing not enabled
2021-09-22 12:26:51.166745 (MainThread): Parsing macros/etc.sql
2021-09-22 12:26:51.170501 (MainThread): Parsing macros/catalog.sql
2021-09-22 12:26:51.178107 (MainThread): Parsing macros/adapters.sql
2021-09-22 12:26:51.198899 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 12:26:51.202330 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 12:26:51.205488 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 12:26:51.216825 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 12:26:51.221865 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 12:26:51.235893 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 12:26:51.238989 (MainThread): Parsing macros/core.sql
2021-09-22 12:26:51.243253 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 12:26:51.252769 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 12:26:51.255311 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 12:26:51.303740 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 12:26:51.347643 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 12:26:51.373280 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 12:26:51.375695 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 12:26:51.383384 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 12:26:51.398471 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 12:26:51.406717 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 12:26:51.414851 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 12:26:51.420753 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 12:26:51.422119 (MainThread): Parsing macros/etc/query.sql
2021-09-22 12:26:51.423356 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 12:26:51.425206 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 12:26:51.435407 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 12:26:51.437805 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 12:26:51.440019 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 12:26:51.483444 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 12:26:51.486287 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 12:26:51.488989 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 12:26:51.491076 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 12:26:51.500097 (MainThread): Partial parsing not enabled
2021-09-22 12:26:51.540189 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:26:51.563041 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:26:51.584918 (MainThread): Acquiring new bigquery connection "test.dbt_project.assert_under_10_percent_null".
2021-09-22 12:26:51.791196 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '33aca7ec-3f9e-4d71-a554-293aa8737ced', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff7ecd0>]}
2021-09-22 12:26:51.830528 (MainThread): Found 2 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 12:26:51.831172 (MainThread): 
2021-09-22 12:26:51.831521 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:26:51.832846 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 12:26:51.832973 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 12:26:53.409485 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 12:26:53.409742 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 12:26:53.416087 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:26:54.063883 (MainThread): 17:56:54 | Concurrency: 1 threads (target='dev')
2021-09-22 12:26:54.064117 (MainThread): 17:56:54 | 
2021-09-22 12:26:54.066866 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 12:26:54.068283 (Thread-1): 17:56:54 | 1 of 1 START table model test.my_first_dbt_model..................... [RUN]
2021-09-22 12:26:54.068595 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:26:54.068734 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 12:26:54.092008 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 12:26:54.092514 (Thread-1): finished collecting timing info
2021-09-22 12:26:54.117250 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:26:54.122966 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:26:55.628611 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 12:26:55.629129 (Thread-1): On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */


  create or replace table `unique-arbor-326717`.`test`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

 

-- , alias='first_model', schema='dbt_test'  , database='ivory-mountain-326811'


with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id



)

select * 
-- , True as first_variable
from source_data
-- where id is not null
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-09-22 12:26:59.069573 (Thread-1): finished collecting timing info
2021-09-22 12:26:59.070323 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33aca7ec-3f9e-4d71-a554-293aa8737ced', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10feb1b80>]}
2021-09-22 12:26:59.071551 (Thread-1): 17:56:59 | 1 of 1 OK created table model test.my_first_dbt_model................ [CREATE TABLE (3.0 rows, 0.0 Bytes processed) in 5.00s]
2021-09-22 12:26:59.071707 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 12:26:59.072863 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:26:59.073176 (MainThread): 17:56:59 | 
2021-09-22 12:26:59.073315 (MainThread): 17:56:59 | Finished running 1 table model in 7.24s.
2021-09-22 12:26:59.073553 (MainThread): Connection 'master' was properly closed.
2021-09-22 12:26:59.073672 (MainThread): Connection 'model.dbt_project.my_first_dbt_model' was properly closed.
2021-09-22 12:26:59.119553 (MainThread): 
2021-09-22 12:26:59.119711 (MainThread): Completed successfully
2021-09-22 12:26:59.119827 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-09-22 12:26:59.119991 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff75f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff6aca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fee2e50>]}
2021-09-22 12:26:59.120178 (MainThread): Flushing usage events
2021-09-22 12:27:27.792559 (MainThread): Running with dbt=0.19.0
2021-09-22 12:27:28.003342 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['example.my_first_dbt_model'], partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 12:27:28.004159 (MainThread): Tracking: tracking
2021-09-22 12:27:28.012496 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b09ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b1a760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b1a700>]}
2021-09-22 12:27:28.036700 (MainThread): Partial parsing not enabled
2021-09-22 12:27:28.037799 (MainThread): Parsing macros/etc.sql
2021-09-22 12:27:28.040636 (MainThread): Parsing macros/catalog.sql
2021-09-22 12:27:28.047029 (MainThread): Parsing macros/adapters.sql
2021-09-22 12:27:28.066343 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 12:27:28.069093 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 12:27:28.071871 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 12:27:28.081965 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 12:27:28.086334 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 12:27:28.099249 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 12:27:28.102110 (MainThread): Parsing macros/core.sql
2021-09-22 12:27:28.105920 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 12:27:28.114733 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 12:27:28.116476 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 12:27:28.162122 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 12:27:28.203645 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 12:27:28.226892 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 12:27:28.229136 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 12:27:28.235203 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 12:27:28.248836 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 12:27:28.255486 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 12:27:28.262232 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 12:27:28.267196 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 12:27:28.268094 (MainThread): Parsing macros/etc/query.sql
2021-09-22 12:27:28.269085 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 12:27:28.270623 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 12:27:28.279277 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 12:27:28.281191 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 12:27:28.282805 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 12:27:28.324762 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 12:27:28.326586 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 12:27:28.328244 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 12:27:28.330324 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 12:27:28.337702 (MainThread): Partial parsing not enabled
2021-09-22 12:27:28.376298 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:27:28.397133 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:27:28.415399 (MainThread): Acquiring new bigquery connection "test.dbt_project.assert_under_10_percent_null".
2021-09-22 12:27:28.620620 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7d11a7d5-f2c4-4a0f-ba38-145524651fdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e2a1c0>]}
2021-09-22 12:27:28.660992 (MainThread): Found 2 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 12:27:28.662068 (MainThread): 
2021-09-22 12:27:28.662370 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:27:28.663735 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 12:27:28.663919 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 12:27:30.322060 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 12:27:30.322325 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 12:27:30.328583 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:27:31.878961 (MainThread): 17:57:31 | Concurrency: 1 threads (target='dev')
2021-09-22 12:27:31.879182 (MainThread): 17:57:31 | 
2021-09-22 12:27:31.881015 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 12:27:31.882370 (Thread-1): 17:57:31 | 1 of 1 START table model test.my_first_dbt_model..................... [RUN]
2021-09-22 12:27:31.882672 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:27:31.882810 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 12:27:31.905012 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 12:27:31.905479 (Thread-1): finished collecting timing info
2021-09-22 12:27:31.929602 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:27:31.935272 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:27:33.504859 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 12:27:33.505358 (Thread-1): On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */


  create or replace table `unique-arbor-326717`.`test`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

 

-- , alias='first_model', schema='dbt_test'  , database='ivory-mountain-326811'


with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id



)

select * 
-- , True as first_variable
from source_data
-- where id is not null
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-09-22 12:27:36.870256 (Thread-1): finished collecting timing info
2021-09-22 12:27:36.871012 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d11a7d5-f2c4-4a0f-ba38-145524651fdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cae370>]}
2021-09-22 12:27:36.872243 (Thread-1): 17:57:36 | 1 of 1 OK created table model test.my_first_dbt_model................ [CREATE TABLE (3.0 rows, 0.0 Bytes processed) in 4.99s]
2021-09-22 12:27:36.872399 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 12:27:36.873414 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:27:36.873722 (MainThread): 17:57:36 | 
2021-09-22 12:27:36.873856 (MainThread): 17:57:36 | Finished running 1 table model in 8.21s.
2021-09-22 12:27:36.873967 (MainThread): Connection 'master' was properly closed.
2021-09-22 12:27:36.874052 (MainThread): Connection 'model.dbt_project.my_first_dbt_model' was properly closed.
2021-09-22 12:27:36.923101 (MainThread): 
2021-09-22 12:27:36.923273 (MainThread): Completed successfully
2021-09-22 12:27:36.923389 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-09-22 12:27:36.923556 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b77a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108dd9a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e5ea30>]}
2021-09-22 12:27:36.923744 (MainThread): Flushing usage events
2021-09-22 12:28:08.023682 (MainThread): Running with dbt=0.19.0
2021-09-22 12:28:08.244805 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['example.my_first_dbt_model', 'example.my_second_dbt_model'], partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 12:28:08.245471 (MainThread): Tracking: tracking
2021-09-22 12:28:08.253224 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e132dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e1436a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e143640>]}
2021-09-22 12:28:08.278117 (MainThread): Partial parsing not enabled
2021-09-22 12:28:08.279430 (MainThread): Parsing macros/etc.sql
2021-09-22 12:28:08.282604 (MainThread): Parsing macros/catalog.sql
2021-09-22 12:28:08.289833 (MainThread): Parsing macros/adapters.sql
2021-09-22 12:28:08.311185 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 12:28:08.313942 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 12:28:08.316829 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 12:28:08.326882 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 12:28:08.331683 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 12:28:08.344383 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 12:28:08.347259 (MainThread): Parsing macros/core.sql
2021-09-22 12:28:08.351090 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 12:28:08.359777 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 12:28:08.361552 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 12:28:08.407403 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 12:28:08.449828 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 12:28:08.474247 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 12:28:08.476288 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 12:28:08.482663 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 12:28:08.496768 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 12:28:08.503507 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 12:28:08.509818 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 12:28:08.515097 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 12:28:08.516012 (MainThread): Parsing macros/etc/query.sql
2021-09-22 12:28:08.517259 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 12:28:08.518820 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 12:28:08.527723 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 12:28:08.530027 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 12:28:08.531741 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 12:28:08.595429 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 12:28:08.597870 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 12:28:08.599802 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 12:28:08.602131 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 12:28:08.611538 (MainThread): Partial parsing not enabled
2021-09-22 12:28:08.658302 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:28:08.684392 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:28:08.705849 (MainThread): Acquiring new bigquery connection "test.dbt_project.assert_under_10_percent_null".
2021-09-22 12:28:08.921516 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1b7324dc-1323-482b-9493-4abb2aa7a35e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e43f430>]}
2021-09-22 12:28:08.965483 (MainThread): Found 2 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 12:28:08.966183 (MainThread): 
2021-09-22 12:28:08.966598 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:28:08.969036 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_unique-arbor-326717".
2021-09-22 12:28:08.969228 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-09-22 12:28:09.642408 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_unique-arbor-326717_test".
2021-09-22 12:28:09.642630 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-09-22 12:28:09.648888 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:28:10.250208 (MainThread): 17:58:10 | Concurrency: 1 threads (target='dev')
2021-09-22 12:28:10.250414 (MainThread): 17:58:10 | 
2021-09-22 12:28:10.252365 (Thread-1): Began running node model.dbt_project.my_first_dbt_model
2021-09-22 12:28:10.253594 (Thread-1): 17:58:10 | 1 of 2 START table model test.my_first_dbt_model..................... [RUN]
2021-09-22 12:28:10.253909 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:28:10.254042 (Thread-1): Compiling model.dbt_project.my_first_dbt_model
2021-09-22 12:28:10.284109 (Thread-1): Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 12:28:10.284716 (Thread-1): finished collecting timing info
2021-09-22 12:28:10.314833 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:28:10.321474 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-09-22 12:28:10.985209 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_first_dbt_model"
2021-09-22 12:28:10.985722 (Thread-1): On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */


  create or replace table `unique-arbor-326717`.`test`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

 

-- , alias='first_model', schema='dbt_test'  , database='ivory-mountain-326811'


with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id



)

select * 
-- , True as first_variable
from source_data
-- where id is not null
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-09-22 12:28:14.738076 (Thread-1): finished collecting timing info
2021-09-22 12:28:14.739224 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1b7324dc-1323-482b-9493-4abb2aa7a35e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e343f70>]}
2021-09-22 12:28:14.740459 (Thread-1): 17:58:14 | 1 of 2 OK created table model test.my_first_dbt_model................ [CREATE TABLE (3.0 rows, 0.0 Bytes processed) in 4.49s]
2021-09-22 12:28:14.740616 (Thread-1): Finished running node model.dbt_project.my_first_dbt_model
2021-09-22 12:28:14.741228 (Thread-1): Began running node model.dbt_project.my_second_dbt_model
2021-09-22 12:28:14.742547 (Thread-1): 17:58:14 | 2 of 2 START view model test.my_second_dbt_model..................... [RUN]
2021-09-22 12:28:14.742871 (Thread-1): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:28:14.743002 (Thread-1): Compiling model.dbt_project.my_second_dbt_model
2021-09-22 12:28:14.752595 (Thread-1): Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 12:28:14.753093 (Thread-1): finished collecting timing info
2021-09-22 12:28:14.782074 (Thread-1): Writing runtime SQL for node "model.dbt_project.my_second_dbt_model"
2021-09-22 12:28:14.782645 (Thread-1): Opening a new connection, currently in state closed
2021-09-22 12:28:14.788833 (Thread-1): On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "my-bigquery-db", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `unique-arbor-326717`.`test`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `unique-arbor-326717`.`test`.`my_first_dbt_model`
-- where id = 1
-- union all
-- select 7 as id;


2021-09-22 12:28:14.874410 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61611), raddr=('172.217.31.202', 443)>
2021-09-22 12:28:14.874671 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61612), raddr=('142.250.182.106', 443)>
2021-09-22 12:28:14.874864 (Thread-1): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61614), raddr=('142.250.182.106', 443)>
2021-09-22 12:28:14.875028 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61613), raddr=('172.217.31.202', 443)>
2021-09-22 12:28:14.875199 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61616), raddr=('142.250.182.106', 443)>
2021-09-22 12:28:14.875371 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.161', 61615), raddr=('172.217.31.202', 443)>
2021-09-22 12:28:17.727497 (Thread-1): finished collecting timing info
2021-09-22 12:28:17.728508 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1b7324dc-1323-482b-9493-4abb2aa7a35e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e43f400>]}
2021-09-22 12:28:17.729919 (Thread-1): 17:58:17 | 2 of 2 OK created view model test.my_second_dbt_model................ [OK in 2.99s]
2021-09-22 12:28:17.730109 (Thread-1): Finished running node model.dbt_project.my_second_dbt_model
2021-09-22 12:28:17.731262 (MainThread): Acquiring new bigquery connection "master".
2021-09-22 12:28:17.731580 (MainThread): 17:58:17 | 
2021-09-22 12:28:17.731716 (MainThread): 17:58:17 | Finished running 1 table model, 1 view model in 8.77s.
2021-09-22 12:28:17.731831 (MainThread): Connection 'master' was properly closed.
2021-09-22 12:28:17.731922 (MainThread): Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
2021-09-22 12:28:17.779864 (MainThread): 
2021-09-22 12:28:17.780062 (MainThread): Completed successfully
2021-09-22 12:28:17.780200 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-09-22 12:28:17.780387 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e37e910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e417640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e343a60>]}
2021-09-22 12:28:17.780599 (MainThread): Flushing usage events
2021-09-22 12:48:21.155395 (MainThread): Running with dbt=0.19.0
2021-09-22 12:48:21.500099 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['new'], partial_parse=None, profile=None, profiles_dir='/Users/kansanja/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-09-22 12:48:21.501385 (MainThread): Tracking: tracking
2021-09-22 12:48:21.512725 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111935a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111947700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119476a0>]}
2021-09-22 12:48:21.538433 (MainThread): Partial parsing not enabled
2021-09-22 12:48:21.539941 (MainThread): Parsing macros/etc.sql
2021-09-22 12:48:21.543800 (MainThread): Parsing macros/catalog.sql
2021-09-22 12:48:21.551044 (MainThread): Parsing macros/adapters.sql
2021-09-22 12:48:21.570323 (MainThread): Parsing macros/materializations/seed.sql
2021-09-22 12:48:21.575003 (MainThread): Parsing macros/materializations/view.sql
2021-09-22 12:48:21.578045 (MainThread): Parsing macros/materializations/table.sql
2021-09-22 12:48:21.589443 (MainThread): Parsing macros/materializations/copy.sql
2021-09-22 12:48:21.594059 (MainThread): Parsing macros/materializations/incremental.sql
2021-09-22 12:48:21.607244 (MainThread): Parsing macros/materializations/snapshot.sql
2021-09-22 12:48:21.610713 (MainThread): Parsing macros/core.sql
2021-09-22 12:48:21.615037 (MainThread): Parsing macros/materializations/helpers.sql
2021-09-22 12:48:21.624310 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-09-22 12:48:21.626721 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-09-22 12:48:21.680487 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-09-22 12:48:21.724916 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-09-22 12:48:21.750107 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-09-22 12:48:21.752582 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-09-22 12:48:21.760226 (MainThread): Parsing macros/materializations/common/merge.sql
2021-09-22 12:48:21.775724 (MainThread): Parsing macros/materializations/table/table.sql
2021-09-22 12:48:21.782832 (MainThread): Parsing macros/materializations/view/view.sql
2021-09-22 12:48:21.790379 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-09-22 12:48:21.795723 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-09-22 12:48:21.796884 (MainThread): Parsing macros/etc/query.sql
2021-09-22 12:48:21.798143 (MainThread): Parsing macros/etc/is_incremental.sql
2021-09-22 12:48:21.799949 (MainThread): Parsing macros/etc/datetime.sql
2021-09-22 12:48:21.810277 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-09-22 12:48:21.812813 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-09-22 12:48:21.815140 (MainThread): Parsing macros/adapters/common.sql
2021-09-22 12:48:21.858605 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-09-22 12:48:21.861412 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-09-22 12:48:21.863599 (MainThread): Parsing macros/schema_tests/unique.sql
2021-09-22 12:48:21.865884 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-09-22 12:48:21.874792 (MainThread): Partial parsing not enabled
2021-09-22 12:48:21.914862 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model".
2021-09-22 12:48:21.935684 (MainThread): Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model".
2021-09-22 12:48:21.956102 (MainThread): Acquiring new bigquery connection "test.dbt_project.assert_under_10_percent_null".
2021-09-22 12:48:22.161465 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'daee18a6-306a-4790-9adb-be9bb923cb2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c8d490>]}
2021-09-22 12:48:22.201312 (MainThread): Found 2 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-09-22 12:48:22.201652 (MainThread): The selector 'new' does not match any nodes and will be ignored
2021-09-22 12:48:22.202039 (MainThread): WARNING: Nothing to do. Try checking your model configs and model specification args
2021-09-22 12:48:22.202213 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c98d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c98400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c98430>]}
2021-09-22 12:48:22.202377 (MainThread): Flushing usage events
2021-09-22 12:48:23.176302 (MainThread): Connection 'test.dbt_project.assert_under_10_percent_null' was properly closed.
